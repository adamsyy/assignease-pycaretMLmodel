2023-06-14 12:37:20,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:37:20,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:37:20,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:37:20,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:37:24,709:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:39:46,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:39:46,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:39:46,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:39:46,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:39:46,874:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:39:49,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:39:49,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:39:49,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:39:49,547:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:39:49,982:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:41:08,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:41:08,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:41:08,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:41:08,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:41:08,968:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:41:13,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:41:13,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:41:13,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:41:13,380:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:41:13,827:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:41:14,536:INFO:PyCaret RegressionExperiment
2023-06-14 12:41:14,536:INFO:Logging name: reg-default-name
2023-06-14 12:41:14,536:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 12:41:14,536:INFO:version 3.0.2
2023-06-14 12:41:14,536:INFO:Initializing setup()
2023-06-14 12:41:14,536:INFO:self.USI: 3e33
2023-06-14 12:41:14,536:INFO:self._variable_keys: {'fold_generator', 'data', 'y_test', 'target_param', 'memory', 'fold_shuffle_param', 'n_jobs_param', 'gpu_n_jobs_param', '_available_plots', 'exp_id', 'log_plots_param', '_ml_usecase', 'exp_name_log', 'logging_param', 'pipeline', 'X_train', 'y_train', 'fold_groups_param', 'transform_target_param', 'idx', 'gpu_param', 'seed', 'USI', 'X_test', 'X', 'y', 'html_param'}
2023-06-14 12:41:14,536:INFO:Checking environment
2023-06-14 12:41:14,536:INFO:python_version: 3.10.11
2023-06-14 12:41:14,536:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-06-14 12:41:14,537:INFO:machine: AMD64
2023-06-14 12:41:14,548:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 12:41:14,553:INFO:Memory: svmem(total=17013329920, available=2571255808, percent=84.9, used=14442074112, free=2571255808)
2023-06-14 12:41:14,553:INFO:Physical Core: 4
2023-06-14 12:41:14,553:INFO:Logical Core: 8
2023-06-14 12:41:14,553:INFO:Checking libraries
2023-06-14 12:41:14,553:INFO:System:
2023-06-14 12:41:14,553:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-06-14 12:41:14,553:INFO:executable: E:\Machine learning\mini\adam\Scripts\python.exe
2023-06-14 12:41:14,553:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 12:41:14,553:INFO:PyCaret required dependencies:
2023-06-14 12:41:14,553:INFO:                 pip: 23.0.1
2023-06-14 12:41:14,554:INFO:          setuptools: 65.5.0
2023-06-14 12:41:14,554:INFO:             pycaret: 3.0.2
2023-06-14 12:41:14,554:INFO:             IPython: 8.14.0
2023-06-14 12:41:14,554:INFO:          ipywidgets: 8.0.6
2023-06-14 12:41:14,554:INFO:                tqdm: 4.65.0
2023-06-14 12:41:14,554:INFO:               numpy: 1.23.5
2023-06-14 12:41:14,554:INFO:              pandas: 1.5.3
2023-06-14 12:41:14,554:INFO:              jinja2: 3.1.2
2023-06-14 12:41:14,554:INFO:               scipy: 1.10.1
2023-06-14 12:41:14,554:INFO:              joblib: 1.2.0
2023-06-14 12:41:14,554:INFO:             sklearn: 1.2.2
2023-06-14 12:41:14,554:INFO:                pyod: 1.0.9
2023-06-14 12:41:14,554:INFO:            imblearn: 0.10.1
2023-06-14 12:41:14,554:INFO:   category_encoders: 2.6.1
2023-06-14 12:41:14,554:INFO:            lightgbm: 3.3.5
2023-06-14 12:41:14,554:INFO:               numba: 0.57.0
2023-06-14 12:41:14,554:INFO:            requests: 2.31.0
2023-06-14 12:41:14,554:INFO:          matplotlib: 3.7.1
2023-06-14 12:41:14,554:INFO:          scikitplot: 0.3.7
2023-06-14 12:41:14,554:INFO:         yellowbrick: 1.5
2023-06-14 12:41:14,554:INFO:              plotly: 5.15.0
2023-06-14 12:41:14,554:INFO:             kaleido: 0.2.1
2023-06-14 12:41:14,554:INFO:         statsmodels: 0.14.0
2023-06-14 12:41:14,554:INFO:              sktime: 0.17.0
2023-06-14 12:41:14,554:INFO:               tbats: 1.1.3
2023-06-14 12:41:14,554:INFO:            pmdarima: 2.0.3
2023-06-14 12:41:14,554:INFO:              psutil: 5.9.5
2023-06-14 12:41:14,555:INFO:PyCaret optional dependencies:
2023-06-14 12:41:14,567:INFO:                shap: Not installed
2023-06-14 12:41:14,567:INFO:           interpret: Not installed
2023-06-14 12:41:14,567:INFO:                umap: Not installed
2023-06-14 12:41:14,567:INFO:    pandas_profiling: Not installed
2023-06-14 12:41:14,567:INFO:  explainerdashboard: Not installed
2023-06-14 12:41:14,567:INFO:             autoviz: Not installed
2023-06-14 12:41:14,567:INFO:           fairlearn: Not installed
2023-06-14 12:41:14,567:INFO:             xgboost: Not installed
2023-06-14 12:41:14,567:INFO:            catboost: Not installed
2023-06-14 12:41:14,567:INFO:              kmodes: Not installed
2023-06-14 12:41:14,567:INFO:             mlxtend: Not installed
2023-06-14 12:41:14,567:INFO:       statsforecast: Not installed
2023-06-14 12:41:14,567:INFO:        tune_sklearn: Not installed
2023-06-14 12:41:14,568:INFO:                 ray: Not installed
2023-06-14 12:41:14,568:INFO:            hyperopt: Not installed
2023-06-14 12:41:14,568:INFO:              optuna: Not installed
2023-06-14 12:41:14,568:INFO:               skopt: Not installed
2023-06-14 12:41:14,568:INFO:              mlflow: Not installed
2023-06-14 12:41:14,568:INFO:              gradio: Not installed
2023-06-14 12:41:14,568:INFO:             fastapi: Not installed
2023-06-14 12:41:14,568:INFO:             uvicorn: Not installed
2023-06-14 12:41:14,568:INFO:              m2cgen: Not installed
2023-06-14 12:41:14,568:INFO:           evidently: Not installed
2023-06-14 12:41:14,568:INFO:               fugue: Not installed
2023-06-14 12:41:14,568:INFO:           streamlit: Not installed
2023-06-14 12:41:14,568:INFO:             prophet: Not installed
2023-06-14 12:41:14,568:INFO:None
2023-06-14 12:41:14,568:INFO:Set up data.
2023-06-14 12:41:14,721:INFO:Set up train/test split.
2023-06-14 12:41:14,729:INFO:Set up index.
2023-06-14 12:41:14,729:INFO:Set up folding strategy.
2023-06-14 12:41:14,729:INFO:Assigning column types.
2023-06-14 12:41:14,733:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 12:41:14,733:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:41:14,737:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:41:14,741:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:41:14,796:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:41:14,835:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:41:14,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:14,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:14,934:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:41:14,938:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:41:14,942:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:41:14,993:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,034:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 12:41:15,038:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,042:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,092:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,140:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,194:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,234:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,235:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 12:41:15,244:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,295:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,343:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,394:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,434:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,435:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 12:41:15,493:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,632:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 12:41:15,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,792:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:41:15,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,833:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 12:41:15,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:15,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:16,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:16,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:16,054:INFO:Preparing preprocessing pipeline...
2023-06-14 12:41:16,054:INFO:Set up simple imputation.
2023-06-14 12:41:16,097:INFO:Finished creating preprocessing pipeline.
2023-06-14 12:41:16,109:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\adamr\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bid_amount', '0', '1', '2', '3',
                                             '4', '5', '6', '7', '8', '9', '10',
                                             '11', '12', '13', '14', '15', '16',
                                             '17', '18', '19', '20', '21', '22',
                                             '23', '24', '25', '26', '27', '28', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-06-14 12:41:16,109:INFO:Creating final display dataframe.
2023-06-14 12:41:16,306:INFO:Setup _display_container:                     Description             Value
0                    Session id              4874
1                        Target    combined_score
2                   Target type        Regression
3           Original data shape        (211, 597)
4        Transformed data shape        (211, 597)
5   Transformed train set shape        (147, 597)
6    Transformed test set shape         (64, 597)
7              Numeric features               596
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              3e33
2023-06-14 12:41:16,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:16,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:16,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:16,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:41:16,522:INFO:setup() successfully completed in 2.14s...............
2023-06-14 12:41:16,522:INFO:Initializing compare_models()
2023-06-14 12:41:16,522:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 12:41:16,522:INFO:Checking exceptions
2023-06-14 12:41:16,524:INFO:Preparing display monitor
2023-06-14 12:41:16,528:INFO:Initializing Linear Regression
2023-06-14 12:41:16,528:INFO:Total runtime is 0.0 minutes
2023-06-14 12:41:16,528:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:16,529:INFO:Initializing create_model()
2023-06-14 12:41:16,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:16,529:INFO:Checking exceptions
2023-06-14 12:41:16,529:INFO:Importing libraries
2023-06-14 12:41:16,529:INFO:Copying training dataset
2023-06-14 12:41:16,533:INFO:Defining folds
2023-06-14 12:41:16,533:INFO:Declaring metric variables
2023-06-14 12:41:16,533:INFO:Importing untrained model
2023-06-14 12:41:16,534:INFO:Linear Regression Imported successfully
2023-06-14 12:41:16,534:INFO:Starting cross validation
2023-06-14 12:41:16,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:23,254:INFO:Calculating mean and std
2023-06-14 12:41:23,255:INFO:Creating metrics dataframe
2023-06-14 12:41:23,496:INFO:Uploading results into container
2023-06-14 12:41:23,496:INFO:Uploading model into container now
2023-06-14 12:41:23,496:INFO:_master_model_container: 1
2023-06-14 12:41:23,497:INFO:_display_container: 2
2023-06-14 12:41:23,497:INFO:LinearRegression(n_jobs=-1)
2023-06-14 12:41:23,497:INFO:create_model() successfully completed......................................
2023-06-14 12:41:23,557:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:23,557:INFO:Creating metrics dataframe
2023-06-14 12:41:23,561:INFO:Initializing Lasso Regression
2023-06-14 12:41:23,561:INFO:Total runtime is 0.11721928119659424 minutes
2023-06-14 12:41:23,562:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:23,562:INFO:Initializing create_model()
2023-06-14 12:41:23,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:23,562:INFO:Checking exceptions
2023-06-14 12:41:23,562:INFO:Importing libraries
2023-06-14 12:41:23,562:INFO:Copying training dataset
2023-06-14 12:41:23,566:INFO:Defining folds
2023-06-14 12:41:23,567:INFO:Declaring metric variables
2023-06-14 12:41:23,567:INFO:Importing untrained model
2023-06-14 12:41:23,567:INFO:Lasso Regression Imported successfully
2023-06-14 12:41:23,567:INFO:Starting cross validation
2023-06-14 12:41:23,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:25,943:INFO:Calculating mean and std
2023-06-14 12:41:25,944:INFO:Creating metrics dataframe
2023-06-14 12:41:26,184:INFO:Uploading results into container
2023-06-14 12:41:26,185:INFO:Uploading model into container now
2023-06-14 12:41:26,185:INFO:_master_model_container: 2
2023-06-14 12:41:26,185:INFO:_display_container: 2
2023-06-14 12:41:26,185:INFO:Lasso(random_state=4874)
2023-06-14 12:41:26,185:INFO:create_model() successfully completed......................................
2023-06-14 12:41:26,244:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:26,244:INFO:Creating metrics dataframe
2023-06-14 12:41:26,248:INFO:Initializing Ridge Regression
2023-06-14 12:41:26,248:INFO:Total runtime is 0.16200690269470214 minutes
2023-06-14 12:41:26,250:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:26,250:INFO:Initializing create_model()
2023-06-14 12:41:26,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:26,250:INFO:Checking exceptions
2023-06-14 12:41:26,250:INFO:Importing libraries
2023-06-14 12:41:26,250:INFO:Copying training dataset
2023-06-14 12:41:26,254:INFO:Defining folds
2023-06-14 12:41:26,254:INFO:Declaring metric variables
2023-06-14 12:41:26,255:INFO:Importing untrained model
2023-06-14 12:41:26,255:INFO:Ridge Regression Imported successfully
2023-06-14 12:41:26,255:INFO:Starting cross validation
2023-06-14 12:41:26,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:28,337:INFO:Calculating mean and std
2023-06-14 12:41:28,338:INFO:Creating metrics dataframe
2023-06-14 12:41:28,585:INFO:Uploading results into container
2023-06-14 12:41:28,585:INFO:Uploading model into container now
2023-06-14 12:41:28,586:INFO:_master_model_container: 3
2023-06-14 12:41:28,586:INFO:_display_container: 2
2023-06-14 12:41:28,586:INFO:Ridge(random_state=4874)
2023-06-14 12:41:28,586:INFO:create_model() successfully completed......................................
2023-06-14 12:41:28,647:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:28,647:INFO:Creating metrics dataframe
2023-06-14 12:41:28,651:INFO:Initializing Elastic Net
2023-06-14 12:41:28,651:INFO:Total runtime is 0.20206152598063148 minutes
2023-06-14 12:41:28,651:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:28,651:INFO:Initializing create_model()
2023-06-14 12:41:28,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:28,651:INFO:Checking exceptions
2023-06-14 12:41:28,651:INFO:Importing libraries
2023-06-14 12:41:28,651:INFO:Copying training dataset
2023-06-14 12:41:28,656:INFO:Defining folds
2023-06-14 12:41:28,656:INFO:Declaring metric variables
2023-06-14 12:41:28,657:INFO:Importing untrained model
2023-06-14 12:41:28,657:INFO:Elastic Net Imported successfully
2023-06-14 12:41:28,657:INFO:Starting cross validation
2023-06-14 12:41:28,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:30,642:INFO:Calculating mean and std
2023-06-14 12:41:30,643:INFO:Creating metrics dataframe
2023-06-14 12:41:30,900:INFO:Uploading results into container
2023-06-14 12:41:30,900:INFO:Uploading model into container now
2023-06-14 12:41:30,901:INFO:_master_model_container: 4
2023-06-14 12:41:30,901:INFO:_display_container: 2
2023-06-14 12:41:30,901:INFO:ElasticNet(random_state=4874)
2023-06-14 12:41:30,901:INFO:create_model() successfully completed......................................
2023-06-14 12:41:30,962:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:30,962:INFO:Creating metrics dataframe
2023-06-14 12:41:30,966:INFO:Initializing Least Angle Regression
2023-06-14 12:41:30,966:INFO:Total runtime is 0.2406484444936116 minutes
2023-06-14 12:41:30,966:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:30,966:INFO:Initializing create_model()
2023-06-14 12:41:30,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:30,966:INFO:Checking exceptions
2023-06-14 12:41:30,966:INFO:Importing libraries
2023-06-14 12:41:30,966:INFO:Copying training dataset
2023-06-14 12:41:30,971:INFO:Defining folds
2023-06-14 12:41:30,971:INFO:Declaring metric variables
2023-06-14 12:41:30,971:INFO:Importing untrained model
2023-06-14 12:41:30,972:INFO:Least Angle Regression Imported successfully
2023-06-14 12:41:30,972:INFO:Starting cross validation
2023-06-14 12:41:30,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:31,175:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.129e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,176:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.680e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,176:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.024e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.482e-01, with an active set of 46 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=9.112e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=8.800e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.071e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,181:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.307e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=7.100e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=5.229e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.744e-01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=4.959e-01, with an active set of 64 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=5.394e-01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=4.945e-01, with an active set of 64 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=5.083e-01, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,190:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.223e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=6.228e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=4.633e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=4.445e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=4.602e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.502e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=4.048e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,197:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=4.385e-01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=4.885e-01, with an active set of 78 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.495e-01, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=4.352e-01, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=6.984e-01, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=3.795e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,206:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=5.444e-01, with an active set of 99 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=3.700e-01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=4.592e-01, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=6.784e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=6.601e-01, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=3.611e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=3.611e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=5.346e-01, with an active set of 111 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=6.755e-01, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=6.770e-01, with an active set of 104 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=6.718e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=7.363e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=6.207e-01, with an active set of 106 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=1.423e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,220:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=6.201e-01, with an active set of 107 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,222:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.422e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,223:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=6.771e-01, with an active set of 115 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,223:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=4.293e-01, with an active set of 109 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,225:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.101e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,226:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.077e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 8.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,226:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.062e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.643e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,226:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=6.747e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,226:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.061e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,227:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.061e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,227:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=9.605e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=9.456e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=9.382e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=9.315e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=8.486e-01, with an active set of 115 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.933e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.913e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.840e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.771e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.680e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.426e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.861e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,231:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=8.651e-01, with an active set of 118 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,231:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.379e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.554e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.370e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.292e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.193e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.136e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=7.147e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.117e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.439e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.953e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.073e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.903e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.940e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.729e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.929e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.716e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.818e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.689e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.770e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.650e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.768e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.559e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.653e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.545e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.290e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.517e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.477e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.795e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.185e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.491e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.890e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.460e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.134e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.238e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.474e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.116e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.414e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.107e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.139e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.404e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.072e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.109e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.143e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.395e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.813e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.031e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.011e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.074e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.264e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.938e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.024e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=7.009e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.246e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.189e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.916e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.192e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 8.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.062e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.781e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.179e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.936e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.738e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.738e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=6.112e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.398e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.644e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.303e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=5.992e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.795e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.146e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.500e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.551e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,242:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.705e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,242:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.427e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,242:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.509e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,242:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.884e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,242:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.508e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.558e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,243:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.406e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.264e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,243:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.872e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,243:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.793e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.914e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,243:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.195e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 7.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,244:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.792e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,244:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.152e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.513e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,244:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.119e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,245:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.118e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,245:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.741e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,245:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=6.060e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,245:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.616e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.813e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,246:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.565e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,246:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.487e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,246:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.999e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,247:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.487e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,247:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.867e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.706e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,247:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.241e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,247:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.769e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.563e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,247:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.054e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,248:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.999e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.341e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,248:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.714e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,248:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.940e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,248:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.666e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,248:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.938e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,250:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.636e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,250:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.886e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,250:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.852e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,250:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.631e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.613e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.794e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.479e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.771e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.478e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.750e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,252:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.451e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,252:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.733e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.450e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,252:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.422e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.726e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.643e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.368e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.319e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.632e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.247e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.278e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.613e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.536e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,254:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.377e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,254:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.252e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,254:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.321e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,254:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.248e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,255:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.239e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,255:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.241e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,255:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.236e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,255:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.100e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.191e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.040e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.185e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.029e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.094e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.957e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.074e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.921e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.061e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.854e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.030e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,258:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.997e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,258:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.631e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,258:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.964e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,258:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.876e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,258:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.592e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,260:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.869e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,260:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.366e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,260:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.817e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,260:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.697e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,261:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.686e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,261:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.273e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,261:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.683e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,262:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.583e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,262:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.232e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,262:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.581e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,263:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.150e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.660e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,263:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.571e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,263:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.122e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,263:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.555e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,263:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.120e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,264:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.542e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,264:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.104e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,264:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.494e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,264:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.096e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,264:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.493e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,265:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.090e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,265:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.429e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,265:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.082e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,265:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.412e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,265:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.031e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,265:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.406e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,266:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.001e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,266:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.979e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,266:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.347e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,266:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.970e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,266:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.295e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,267:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.264e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.889e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,267:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.963e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,267:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.252e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,267:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.812e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,268:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.170e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,268:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.705e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,268:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.121e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.889e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,268:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.636e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,268:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.120e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,268:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.610e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,269:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.053e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,269:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.549e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,269:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.975e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,269:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.536e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,269:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.951e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.533e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.525e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.914e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.492e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.879e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.477e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.831e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.468e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,271:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.798e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.609e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,271:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.398e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,271:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.792e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.763e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,271:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.395e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,271:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.786e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,272:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.361e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,272:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.718e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,272:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.323e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,272:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.664e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,272:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.311e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,273:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.627e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,273:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.206e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.295e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,273:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.625e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.385e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,273:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.164e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,274:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.152e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,274:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.625e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,274:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.146e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,274:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.607e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.189e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,274:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.121e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.091e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,275:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.583e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,275:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.583e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,275:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.112e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,275:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.571e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,276:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.071e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,276:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.527e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,276:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.008e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,276:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.492e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,276:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.961e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,276:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.480e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.226e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,277:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.915e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,277:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.468e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,277:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.835e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,277:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.467e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,277:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.834e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,278:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.756e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,278:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.678e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,278:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.655e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,279:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.648e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.606e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.049e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,278:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.453e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.602e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.543e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.434e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.537e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.366e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.506e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,281:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.494e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.918e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,281:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.365e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.499e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,281:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.451e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,281:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.307e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,282:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.443e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,282:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.295e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,282:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.438e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,282:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.286e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,282:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.402e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,283:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.348e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.853e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,283:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.228e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,283:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.314e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,283:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.304e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,284:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.223e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,284:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.287e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,284:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.219e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.660e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,284:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.287e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.970e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,284:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.210e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,284:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.238e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,285:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.188e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,285:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.111e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.392e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,285:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.179e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,285:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.074e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,286:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.174e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,286:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.977e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.242e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,286:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.172e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,286:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.148e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,287:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.970e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,287:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.138e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,287:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.967e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,287:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.130e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,287:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.951e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.936e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,288:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.106e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,288:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.884e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.608e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,288:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.098e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,288:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.836e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,288:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.064e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,289:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.826e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,290:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.821e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,290:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.026e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,290:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.780e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,290:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.000e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,290:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.998e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,291:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.780e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,291:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.988e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,291:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.760e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,291:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.922e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.139e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,291:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.746e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,292:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.887e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,292:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.744e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,292:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.857e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,292:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.710e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,293:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.847e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,293:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.706e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,293:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.809e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,293:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.702e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,293:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.695e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,294:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.746e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,294:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.592e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,294:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.648e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,294:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.568e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,294:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.632e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,294:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.509e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,295:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.631e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,295:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.478e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,295:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.566e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,295:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.467e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,295:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.556e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,295:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.467e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,296:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.543e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,296:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.346e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,296:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.538e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,296:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.326e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,296:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.526e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,296:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.314e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.554e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,297:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.513e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,297:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.312e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,297:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.494e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,297:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.483e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,297:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.180e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,297:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.482e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,297:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.465e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.547e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,297:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.170e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.006e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,298:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.445e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.894e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,298:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.166e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,298:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.131e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,298:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.422e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,298:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.382e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,299:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.034e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,300:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.993e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,300:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.353e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,300:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.348e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,300:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.943e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,301:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.330e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.047e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,301:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.920e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,301:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.309e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,301:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.293e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,301:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.862e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,302:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.293e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.623e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,302:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.861e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,302:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.289e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,303:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.288e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,303:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.854e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,303:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.211e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,303:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.851e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,303:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.205e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.321e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,303:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.836e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,304:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.192e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,304:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.777e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,304:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.152e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,304:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.747e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,304:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.065e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.439e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,305:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.708e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,305:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.048e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.857e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,305:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.699e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,306:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.014e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,306:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.682e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,306:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.982e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.435e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,306:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.657e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,306:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.975e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,307:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.639e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,307:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.964e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,307:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.610e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,307:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.934e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,307:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.595e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,308:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.507e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,308:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.902e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,308:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.867e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.795e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,308:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.503e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,309:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.857e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,309:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.413e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,309:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.824e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,309:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.805e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,309:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.400e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.756e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,309:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.374e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,310:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.367e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,310:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.759e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,310:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.355e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,310:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.343e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.321e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,311:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.320e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,311:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.690e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.499e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,311:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.239e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,311:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.689e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.095e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,311:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.167e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,311:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.659e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,312:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.151e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.813e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,312:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.655e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,312:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.150e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,312:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.649e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.204e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,312:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.135e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,312:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.615e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,313:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.113e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,313:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.066e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,313:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.609e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,314:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.052e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.949e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,314:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.594e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,314:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.010e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,314:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.510e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.778e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,314:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.004e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,314:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.475e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.500e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,315:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.473e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,315:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.974e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,315:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.470e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,316:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.945e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,316:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.462e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,316:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.936e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,316:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.934e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,316:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.904e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.211e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,318:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.895e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,318:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.891e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,318:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.436e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,319:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.891e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,319:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.431e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.556e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,319:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.873e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,319:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.351e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,319:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.861e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.540e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.260e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.311e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.841e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.795e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.249e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.827e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.820e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.784e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.204e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.778e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.188e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,321:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.758e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,321:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.187e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.538e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,321:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.164e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,321:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.746e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,322:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.109e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,322:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.745e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,323:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.103e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,323:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.744e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.554e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,323:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.098e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.763e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,323:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.728e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,323:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.087e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.330e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,324:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.723e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,324:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.052e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,324:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.715e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,324:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.031e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,324:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.692e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,324:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.019e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,325:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.667e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.767e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,325:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.014e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.435e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,325:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.000e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.247e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,325:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.984e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,326:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.931e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,326:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.653e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,326:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.855e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,327:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.686e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,327:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.618e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,327:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.603e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,327:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.605e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,327:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.585e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,328:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.598e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,328:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.422e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,328:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.590e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.007e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,328:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.245e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,328:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.547e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,328:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.202e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.266e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,328:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.502e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,328:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.135e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,328:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.988e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,330:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.610e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,330:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.482e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,330:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.445e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,330:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.571e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.276e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,330:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.571e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,330:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.424e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,330:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.461e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,331:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.401e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.928e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,331:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.447e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,331:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.426e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.326e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,331:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.394e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,332:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.386e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,332:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.341e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,332:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.305e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,333:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.322e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.785e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,333:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.202e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.536e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,333:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.317e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,333:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.160e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,334:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.241e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,334:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.138e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,334:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.041e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.095e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,334:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.928e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.949e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,334:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.116e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,335:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.102e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,335:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.901e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.767e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,335:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.094e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,335:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.837e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,336:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.786e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.447e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,336:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.075e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,336:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.641e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,336:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.052e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,337:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.038e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,337:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.436e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.030e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.360e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.190e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.029e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.027e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.272e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.889e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.233e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.256e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,340:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.633e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,340:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.093e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.647e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,340:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.382e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,341:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.335e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,341:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.024e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.410e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,341:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.151e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,341:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.979e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,342:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.986e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,342:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.869e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.226e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,342:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.840e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,342:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.864e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,342:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.579e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,343:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.705e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,343:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.559e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,343:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.603e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,343:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.331e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.343e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,343:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.101e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,344:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.277e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,344:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.099e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,344:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.184e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.204e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,344:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.073e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,344:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.139e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,344:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.068e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,344:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.734e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,344:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.057e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,344:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.970e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,345:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.827e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.744e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,346:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.813e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,346:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.652e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.668e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,346:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.468e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,346:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.657e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,347:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.377e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,347:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.533e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,347:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.243e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,347:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.336e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,347:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.235e-02, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.800e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,347:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.325e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,348:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.979e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,348:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.963e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,348:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.509e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,348:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=4.965e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,348:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.066e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,349:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.754e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,349:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.466e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,350:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.446e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,350:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.123e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,350:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.963e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,351:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.864e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,351:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.536e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,352:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.517e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,352:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.478e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,352:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.283e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,353:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.204e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,353:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.132e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.343e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,353:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.104e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,354:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.937e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,354:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.913e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,354:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.908e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,355:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.778e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,355:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.723e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,356:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.626e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,356:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.579e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,356:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.217e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,357:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.633e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,357:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.338e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.532e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,357:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.092e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,358:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.225e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,358:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.218e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:31,358:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.167e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:32,415:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=5.679e-01, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:32,436:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=6.921e-01, with an active set of 98 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:32,452:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=1.399e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:33,020:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=9.943e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:33,031:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=7.048e-01, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:33,040:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=7.098e-01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:34,125:INFO:Calculating mean and std
2023-06-14 12:41:34,126:INFO:Creating metrics dataframe
2023-06-14 12:41:34,382:INFO:Uploading results into container
2023-06-14 12:41:34,383:INFO:Uploading model into container now
2023-06-14 12:41:34,383:INFO:_master_model_container: 5
2023-06-14 12:41:34,383:INFO:_display_container: 2
2023-06-14 12:41:34,384:INFO:Lars(random_state=4874)
2023-06-14 12:41:34,384:INFO:create_model() successfully completed......................................
2023-06-14 12:41:34,441:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:34,441:INFO:Creating metrics dataframe
2023-06-14 12:41:34,445:INFO:Initializing Lasso Least Angle Regression
2023-06-14 12:41:34,445:INFO:Total runtime is 0.2986311475435892 minutes
2023-06-14 12:41:34,445:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:34,446:INFO:Initializing create_model()
2023-06-14 12:41:34,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:34,447:INFO:Checking exceptions
2023-06-14 12:41:34,447:INFO:Importing libraries
2023-06-14 12:41:34,447:INFO:Copying training dataset
2023-06-14 12:41:34,452:INFO:Defining folds
2023-06-14 12:41:34,452:INFO:Declaring metric variables
2023-06-14 12:41:34,452:INFO:Importing untrained model
2023-06-14 12:41:34,452:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 12:41:34,453:INFO:Starting cross validation
2023-06-14 12:41:34,454:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:34,604:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.043e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:34,620:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.032e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:34,624:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.024e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:34,639:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.129e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:41:36,371:INFO:Calculating mean and std
2023-06-14 12:41:36,372:INFO:Creating metrics dataframe
2023-06-14 12:41:36,623:INFO:Uploading results into container
2023-06-14 12:41:36,623:INFO:Uploading model into container now
2023-06-14 12:41:36,624:INFO:_master_model_container: 6
2023-06-14 12:41:36,624:INFO:_display_container: 2
2023-06-14 12:41:36,624:INFO:LassoLars(random_state=4874)
2023-06-14 12:41:36,624:INFO:create_model() successfully completed......................................
2023-06-14 12:41:36,684:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:36,684:INFO:Creating metrics dataframe
2023-06-14 12:41:36,690:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 12:41:36,690:INFO:Total runtime is 0.3360492825508117 minutes
2023-06-14 12:41:36,690:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:36,690:INFO:Initializing create_model()
2023-06-14 12:41:36,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:36,690:INFO:Checking exceptions
2023-06-14 12:41:36,691:INFO:Importing libraries
2023-06-14 12:41:36,691:INFO:Copying training dataset
2023-06-14 12:41:36,696:INFO:Defining folds
2023-06-14 12:41:36,696:INFO:Declaring metric variables
2023-06-14 12:41:36,696:INFO:Importing untrained model
2023-06-14 12:41:36,697:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 12:41:36,697:INFO:Starting cross validation
2023-06-14 12:41:36,699:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:38,607:INFO:Calculating mean and std
2023-06-14 12:41:38,608:INFO:Creating metrics dataframe
2023-06-14 12:41:38,860:INFO:Uploading results into container
2023-06-14 12:41:38,860:INFO:Uploading model into container now
2023-06-14 12:41:38,860:INFO:_master_model_container: 7
2023-06-14 12:41:38,861:INFO:_display_container: 2
2023-06-14 12:41:38,861:INFO:OrthogonalMatchingPursuit()
2023-06-14 12:41:38,861:INFO:create_model() successfully completed......................................
2023-06-14 12:41:38,919:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:38,919:INFO:Creating metrics dataframe
2023-06-14 12:41:38,923:INFO:Initializing Bayesian Ridge
2023-06-14 12:41:38,923:INFO:Total runtime is 0.37326197226842234 minutes
2023-06-14 12:41:38,923:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:38,923:INFO:Initializing create_model()
2023-06-14 12:41:38,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:38,924:INFO:Checking exceptions
2023-06-14 12:41:38,924:INFO:Importing libraries
2023-06-14 12:41:38,924:INFO:Copying training dataset
2023-06-14 12:41:38,928:INFO:Defining folds
2023-06-14 12:41:38,928:INFO:Declaring metric variables
2023-06-14 12:41:38,928:INFO:Importing untrained model
2023-06-14 12:41:38,929:INFO:Bayesian Ridge Imported successfully
2023-06-14 12:41:38,929:INFO:Starting cross validation
2023-06-14 12:41:38,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:41,179:INFO:Calculating mean and std
2023-06-14 12:41:41,180:INFO:Creating metrics dataframe
2023-06-14 12:41:41,433:INFO:Uploading results into container
2023-06-14 12:41:41,433:INFO:Uploading model into container now
2023-06-14 12:41:41,434:INFO:_master_model_container: 8
2023-06-14 12:41:41,434:INFO:_display_container: 2
2023-06-14 12:41:41,434:INFO:BayesianRidge()
2023-06-14 12:41:41,434:INFO:create_model() successfully completed......................................
2023-06-14 12:41:41,491:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:41,491:INFO:Creating metrics dataframe
2023-06-14 12:41:41,495:INFO:Initializing Passive Aggressive Regressor
2023-06-14 12:41:41,495:INFO:Total runtime is 0.416128647327423 minutes
2023-06-14 12:41:41,496:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:41,496:INFO:Initializing create_model()
2023-06-14 12:41:41,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:41,496:INFO:Checking exceptions
2023-06-14 12:41:41,496:INFO:Importing libraries
2023-06-14 12:41:41,496:INFO:Copying training dataset
2023-06-14 12:41:41,500:INFO:Defining folds
2023-06-14 12:41:41,501:INFO:Declaring metric variables
2023-06-14 12:41:41,501:INFO:Importing untrained model
2023-06-14 12:41:41,501:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 12:41:41,501:INFO:Starting cross validation
2023-06-14 12:41:41,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:43,495:INFO:Calculating mean and std
2023-06-14 12:41:43,495:INFO:Creating metrics dataframe
2023-06-14 12:41:43,760:INFO:Uploading results into container
2023-06-14 12:41:43,760:INFO:Uploading model into container now
2023-06-14 12:41:43,761:INFO:_master_model_container: 9
2023-06-14 12:41:43,761:INFO:_display_container: 2
2023-06-14 12:41:43,761:INFO:PassiveAggressiveRegressor(random_state=4874)
2023-06-14 12:41:43,761:INFO:create_model() successfully completed......................................
2023-06-14 12:41:43,820:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:43,820:INFO:Creating metrics dataframe
2023-06-14 12:41:43,825:INFO:Initializing Huber Regressor
2023-06-14 12:41:43,825:INFO:Total runtime is 0.4549553831418354 minutes
2023-06-14 12:41:43,825:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:43,825:INFO:Initializing create_model()
2023-06-14 12:41:43,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:43,825:INFO:Checking exceptions
2023-06-14 12:41:43,825:INFO:Importing libraries
2023-06-14 12:41:43,825:INFO:Copying training dataset
2023-06-14 12:41:43,830:INFO:Defining folds
2023-06-14 12:41:43,830:INFO:Declaring metric variables
2023-06-14 12:41:43,830:INFO:Importing untrained model
2023-06-14 12:41:43,830:INFO:Huber Regressor Imported successfully
2023-06-14 12:41:43,830:INFO:Starting cross validation
2023-06-14 12:41:43,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:44,158:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:41:44,163:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:41:44,170:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:41:44,171:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:41:44,793:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:41:46,176:INFO:Calculating mean and std
2023-06-14 12:41:46,176:INFO:Creating metrics dataframe
2023-06-14 12:41:46,437:INFO:Uploading results into container
2023-06-14 12:41:46,437:INFO:Uploading model into container now
2023-06-14 12:41:46,437:INFO:_master_model_container: 10
2023-06-14 12:41:46,438:INFO:_display_container: 2
2023-06-14 12:41:46,438:INFO:HuberRegressor()
2023-06-14 12:41:46,438:INFO:create_model() successfully completed......................................
2023-06-14 12:41:46,497:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:46,498:INFO:Creating metrics dataframe
2023-06-14 12:41:46,501:INFO:Initializing K Neighbors Regressor
2023-06-14 12:41:46,501:INFO:Total runtime is 0.49956570466359446 minutes
2023-06-14 12:41:46,502:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:46,502:INFO:Initializing create_model()
2023-06-14 12:41:46,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:46,502:INFO:Checking exceptions
2023-06-14 12:41:46,502:INFO:Importing libraries
2023-06-14 12:41:46,502:INFO:Copying training dataset
2023-06-14 12:41:46,507:INFO:Defining folds
2023-06-14 12:41:46,507:INFO:Declaring metric variables
2023-06-14 12:41:46,507:INFO:Importing untrained model
2023-06-14 12:41:46,507:INFO:K Neighbors Regressor Imported successfully
2023-06-14 12:41:46,507:INFO:Starting cross validation
2023-06-14 12:41:46,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:48,767:INFO:Calculating mean and std
2023-06-14 12:41:48,768:INFO:Creating metrics dataframe
2023-06-14 12:41:49,023:INFO:Uploading results into container
2023-06-14 12:41:49,023:INFO:Uploading model into container now
2023-06-14 12:41:49,024:INFO:_master_model_container: 11
2023-06-14 12:41:49,024:INFO:_display_container: 2
2023-06-14 12:41:49,024:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 12:41:49,024:INFO:create_model() successfully completed......................................
2023-06-14 12:41:49,083:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:49,083:INFO:Creating metrics dataframe
2023-06-14 12:41:49,088:INFO:Initializing Decision Tree Regressor
2023-06-14 12:41:49,088:INFO:Total runtime is 0.5426795562108356 minutes
2023-06-14 12:41:49,088:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:49,088:INFO:Initializing create_model()
2023-06-14 12:41:49,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:49,088:INFO:Checking exceptions
2023-06-14 12:41:49,089:INFO:Importing libraries
2023-06-14 12:41:49,089:INFO:Copying training dataset
2023-06-14 12:41:49,094:INFO:Defining folds
2023-06-14 12:41:49,094:INFO:Declaring metric variables
2023-06-14 12:41:49,094:INFO:Importing untrained model
2023-06-14 12:41:49,095:INFO:Decision Tree Regressor Imported successfully
2023-06-14 12:41:49,095:INFO:Starting cross validation
2023-06-14 12:41:49,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:51,213:INFO:Calculating mean and std
2023-06-14 12:41:51,214:INFO:Creating metrics dataframe
2023-06-14 12:41:51,472:INFO:Uploading results into container
2023-06-14 12:41:51,472:INFO:Uploading model into container now
2023-06-14 12:41:51,472:INFO:_master_model_container: 12
2023-06-14 12:41:51,473:INFO:_display_container: 2
2023-06-14 12:41:51,473:INFO:DecisionTreeRegressor(random_state=4874)
2023-06-14 12:41:51,473:INFO:create_model() successfully completed......................................
2023-06-14 12:41:51,532:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:51,532:INFO:Creating metrics dataframe
2023-06-14 12:41:51,536:INFO:Initializing Random Forest Regressor
2023-06-14 12:41:51,536:INFO:Total runtime is 0.5834785977999368 minutes
2023-06-14 12:41:51,536:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:51,537:INFO:Initializing create_model()
2023-06-14 12:41:51,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:51,537:INFO:Checking exceptions
2023-06-14 12:41:51,537:INFO:Importing libraries
2023-06-14 12:41:51,537:INFO:Copying training dataset
2023-06-14 12:41:51,541:INFO:Defining folds
2023-06-14 12:41:51,541:INFO:Declaring metric variables
2023-06-14 12:41:51,542:INFO:Importing untrained model
2023-06-14 12:41:51,542:INFO:Random Forest Regressor Imported successfully
2023-06-14 12:41:51,542:INFO:Starting cross validation
2023-06-14 12:41:51,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:55,170:INFO:Calculating mean and std
2023-06-14 12:41:55,171:INFO:Creating metrics dataframe
2023-06-14 12:41:55,439:INFO:Uploading results into container
2023-06-14 12:41:55,439:INFO:Uploading model into container now
2023-06-14 12:41:55,440:INFO:_master_model_container: 13
2023-06-14 12:41:55,440:INFO:_display_container: 2
2023-06-14 12:41:55,440:INFO:RandomForestRegressor(n_jobs=-1, random_state=4874)
2023-06-14 12:41:55,440:INFO:create_model() successfully completed......................................
2023-06-14 12:41:55,500:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:55,500:INFO:Creating metrics dataframe
2023-06-14 12:41:55,504:INFO:Initializing Extra Trees Regressor
2023-06-14 12:41:55,504:INFO:Total runtime is 0.6496159275372821 minutes
2023-06-14 12:41:55,504:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:55,505:INFO:Initializing create_model()
2023-06-14 12:41:55,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:55,505:INFO:Checking exceptions
2023-06-14 12:41:55,505:INFO:Importing libraries
2023-06-14 12:41:55,505:INFO:Copying training dataset
2023-06-14 12:41:55,510:INFO:Defining folds
2023-06-14 12:41:55,510:INFO:Declaring metric variables
2023-06-14 12:41:55,510:INFO:Importing untrained model
2023-06-14 12:41:55,510:INFO:Extra Trees Regressor Imported successfully
2023-06-14 12:41:55,510:INFO:Starting cross validation
2023-06-14 12:41:55,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:41:59,083:INFO:Calculating mean and std
2023-06-14 12:41:59,083:INFO:Creating metrics dataframe
2023-06-14 12:41:59,356:INFO:Uploading results into container
2023-06-14 12:41:59,357:INFO:Uploading model into container now
2023-06-14 12:41:59,357:INFO:_master_model_container: 14
2023-06-14 12:41:59,357:INFO:_display_container: 2
2023-06-14 12:41:59,358:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4874)
2023-06-14 12:41:59,358:INFO:create_model() successfully completed......................................
2023-06-14 12:41:59,417:INFO:SubProcess create_model() end ==================================
2023-06-14 12:41:59,417:INFO:Creating metrics dataframe
2023-06-14 12:41:59,422:INFO:Initializing AdaBoost Regressor
2023-06-14 12:41:59,423:INFO:Total runtime is 0.7149199565251667 minutes
2023-06-14 12:41:59,423:INFO:SubProcess create_model() called ==================================
2023-06-14 12:41:59,423:INFO:Initializing create_model()
2023-06-14 12:41:59,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:41:59,423:INFO:Checking exceptions
2023-06-14 12:41:59,423:INFO:Importing libraries
2023-06-14 12:41:59,423:INFO:Copying training dataset
2023-06-14 12:41:59,428:INFO:Defining folds
2023-06-14 12:41:59,428:INFO:Declaring metric variables
2023-06-14 12:41:59,428:INFO:Importing untrained model
2023-06-14 12:41:59,428:INFO:AdaBoost Regressor Imported successfully
2023-06-14 12:41:59,429:INFO:Starting cross validation
2023-06-14 12:41:59,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:02,293:INFO:Calculating mean and std
2023-06-14 12:42:02,293:INFO:Creating metrics dataframe
2023-06-14 12:42:02,565:INFO:Uploading results into container
2023-06-14 12:42:02,566:INFO:Uploading model into container now
2023-06-14 12:42:02,566:INFO:_master_model_container: 15
2023-06-14 12:42:02,566:INFO:_display_container: 2
2023-06-14 12:42:02,567:INFO:AdaBoostRegressor(random_state=4874)
2023-06-14 12:42:02,567:INFO:create_model() successfully completed......................................
2023-06-14 12:42:02,625:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:02,625:INFO:Creating metrics dataframe
2023-06-14 12:42:02,629:INFO:Initializing Gradient Boosting Regressor
2023-06-14 12:42:02,629:INFO:Total runtime is 0.7683633883794148 minutes
2023-06-14 12:42:02,630:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:02,630:INFO:Initializing create_model()
2023-06-14 12:42:02,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:02,630:INFO:Checking exceptions
2023-06-14 12:42:02,630:INFO:Importing libraries
2023-06-14 12:42:02,630:INFO:Copying training dataset
2023-06-14 12:42:02,635:INFO:Defining folds
2023-06-14 12:42:02,635:INFO:Declaring metric variables
2023-06-14 12:42:02,636:INFO:Importing untrained model
2023-06-14 12:42:02,636:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 12:42:02,636:INFO:Starting cross validation
2023-06-14 12:42:02,638:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:05,975:INFO:Calculating mean and std
2023-06-14 12:42:05,975:INFO:Creating metrics dataframe
2023-06-14 12:42:06,246:INFO:Uploading results into container
2023-06-14 12:42:06,246:INFO:Uploading model into container now
2023-06-14 12:42:06,246:INFO:_master_model_container: 16
2023-06-14 12:42:06,246:INFO:_display_container: 2
2023-06-14 12:42:06,247:INFO:GradientBoostingRegressor(random_state=4874)
2023-06-14 12:42:06,247:INFO:create_model() successfully completed......................................
2023-06-14 12:42:06,306:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:06,306:INFO:Creating metrics dataframe
2023-06-14 12:42:06,311:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 12:42:06,311:INFO:Total runtime is 0.8297183672587075 minutes
2023-06-14 12:42:06,311:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:06,311:INFO:Initializing create_model()
2023-06-14 12:42:06,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:06,311:INFO:Checking exceptions
2023-06-14 12:42:06,311:INFO:Importing libraries
2023-06-14 12:42:06,311:INFO:Copying training dataset
2023-06-14 12:42:06,316:INFO:Defining folds
2023-06-14 12:42:06,316:INFO:Declaring metric variables
2023-06-14 12:42:06,316:INFO:Importing untrained model
2023-06-14 12:42:06,317:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 12:42:06,317:INFO:Starting cross validation
2023-06-14 12:42:06,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:08,692:INFO:Calculating mean and std
2023-06-14 12:42:08,693:INFO:Creating metrics dataframe
2023-06-14 12:42:08,983:INFO:Uploading results into container
2023-06-14 12:42:08,983:INFO:Uploading model into container now
2023-06-14 12:42:08,984:INFO:_master_model_container: 17
2023-06-14 12:42:08,984:INFO:_display_container: 2
2023-06-14 12:42:08,984:INFO:LGBMRegressor(random_state=4874)
2023-06-14 12:42:08,984:INFO:create_model() successfully completed......................................
2023-06-14 12:42:09,042:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:09,042:INFO:Creating metrics dataframe
2023-06-14 12:42:09,046:INFO:Initializing Dummy Regressor
2023-06-14 12:42:09,046:INFO:Total runtime is 0.8753024101257323 minutes
2023-06-14 12:42:09,047:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:09,047:INFO:Initializing create_model()
2023-06-14 12:42:09,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020846F13460>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:09,047:INFO:Checking exceptions
2023-06-14 12:42:09,047:INFO:Importing libraries
2023-06-14 12:42:09,047:INFO:Copying training dataset
2023-06-14 12:42:09,051:INFO:Defining folds
2023-06-14 12:42:09,051:INFO:Declaring metric variables
2023-06-14 12:42:09,051:INFO:Importing untrained model
2023-06-14 12:42:09,052:INFO:Dummy Regressor Imported successfully
2023-06-14 12:42:09,052:INFO:Starting cross validation
2023-06-14 12:42:09,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:11,213:INFO:Calculating mean and std
2023-06-14 12:42:11,214:INFO:Creating metrics dataframe
2023-06-14 12:42:11,505:INFO:Uploading results into container
2023-06-14 12:42:11,506:INFO:Uploading model into container now
2023-06-14 12:42:11,506:INFO:_master_model_container: 18
2023-06-14 12:42:11,506:INFO:_display_container: 2
2023-06-14 12:42:11,506:INFO:DummyRegressor()
2023-06-14 12:42:11,506:INFO:create_model() successfully completed......................................
2023-06-14 12:42:11,566:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:11,566:INFO:Creating metrics dataframe
2023-06-14 12:42:11,572:INFO:Initializing create_model()
2023-06-14 12:42:11,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020846E2A950>, estimator=LGBMRegressor(random_state=4874), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:11,572:INFO:Checking exceptions
2023-06-14 12:42:11,573:INFO:Importing libraries
2023-06-14 12:42:11,573:INFO:Copying training dataset
2023-06-14 12:42:11,577:INFO:Defining folds
2023-06-14 12:42:11,577:INFO:Declaring metric variables
2023-06-14 12:42:11,579:INFO:Importing untrained model
2023-06-14 12:42:11,579:INFO:Declaring custom model
2023-06-14 12:42:11,580:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 12:42:11,581:INFO:Cross validation set to False
2023-06-14 12:42:11,581:INFO:Fitting Model
2023-06-14 12:42:11,892:INFO:LGBMRegressor(random_state=4874)
2023-06-14 12:42:11,892:INFO:create_model() successfully completed......................................
2023-06-14 12:42:11,968:INFO:_master_model_container: 18
2023-06-14 12:42:11,968:INFO:_display_container: 2
2023-06-14 12:42:11,968:INFO:LGBMRegressor(random_state=4874)
2023-06-14 12:42:11,968:INFO:compare_models() successfully completed......................................
2023-06-14 12:42:14,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:42:14,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:42:14,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:42:14,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:42:14,502:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:42:15,206:INFO:PyCaret RegressionExperiment
2023-06-14 12:42:15,207:INFO:Logging name: reg-default-name
2023-06-14 12:42:15,207:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 12:42:15,207:INFO:version 3.0.2
2023-06-14 12:42:15,207:INFO:Initializing setup()
2023-06-14 12:42:15,207:INFO:self.USI: 636b
2023-06-14 12:42:15,207:INFO:self._variable_keys: {'_ml_usecase', 'fold_shuffle_param', 'y_test', 'y', '_available_plots', 'logging_param', 'data', 'fold_groups_param', 'X_test', 'gpu_param', 'memory', 'n_jobs_param', 'X', 'USI', 'html_param', 'target_param', 'pipeline', 'fold_generator', 'y_train', 'idx', 'gpu_n_jobs_param', 'log_plots_param', 'transform_target_param', 'X_train', 'seed', 'exp_name_log', 'exp_id'}
2023-06-14 12:42:15,207:INFO:Checking environment
2023-06-14 12:42:15,207:INFO:python_version: 3.10.11
2023-06-14 12:42:15,207:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-06-14 12:42:15,207:INFO:machine: AMD64
2023-06-14 12:42:15,225:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 12:42:15,229:INFO:Memory: svmem(total=17013329920, available=2181783552, percent=87.2, used=14831546368, free=2181783552)
2023-06-14 12:42:15,229:INFO:Physical Core: 4
2023-06-14 12:42:15,230:INFO:Logical Core: 8
2023-06-14 12:42:15,230:INFO:Checking libraries
2023-06-14 12:42:15,230:INFO:System:
2023-06-14 12:42:15,230:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-06-14 12:42:15,230:INFO:executable: E:\Machine learning\mini\adam\Scripts\python.exe
2023-06-14 12:42:15,230:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 12:42:15,230:INFO:PyCaret required dependencies:
2023-06-14 12:42:15,230:INFO:                 pip: 23.0.1
2023-06-14 12:42:15,230:INFO:          setuptools: 65.5.0
2023-06-14 12:42:15,230:INFO:             pycaret: 3.0.2
2023-06-14 12:42:15,230:INFO:             IPython: 8.14.0
2023-06-14 12:42:15,230:INFO:          ipywidgets: 8.0.6
2023-06-14 12:42:15,230:INFO:                tqdm: 4.65.0
2023-06-14 12:42:15,230:INFO:               numpy: 1.23.5
2023-06-14 12:42:15,230:INFO:              pandas: 1.5.3
2023-06-14 12:42:15,230:INFO:              jinja2: 3.1.2
2023-06-14 12:42:15,230:INFO:               scipy: 1.10.1
2023-06-14 12:42:15,230:INFO:              joblib: 1.2.0
2023-06-14 12:42:15,230:INFO:             sklearn: 1.2.2
2023-06-14 12:42:15,230:INFO:                pyod: 1.0.9
2023-06-14 12:42:15,231:INFO:            imblearn: 0.10.1
2023-06-14 12:42:15,231:INFO:   category_encoders: 2.6.1
2023-06-14 12:42:15,231:INFO:            lightgbm: 3.3.5
2023-06-14 12:42:15,231:INFO:               numba: 0.57.0
2023-06-14 12:42:15,231:INFO:            requests: 2.31.0
2023-06-14 12:42:15,231:INFO:          matplotlib: 3.7.1
2023-06-14 12:42:15,231:INFO:          scikitplot: 0.3.7
2023-06-14 12:42:15,231:INFO:         yellowbrick: 1.5
2023-06-14 12:42:15,231:INFO:              plotly: 5.15.0
2023-06-14 12:42:15,231:INFO:             kaleido: 0.2.1
2023-06-14 12:42:15,231:INFO:         statsmodels: 0.14.0
2023-06-14 12:42:15,231:INFO:              sktime: 0.17.0
2023-06-14 12:42:15,231:INFO:               tbats: 1.1.3
2023-06-14 12:42:15,231:INFO:            pmdarima: 2.0.3
2023-06-14 12:42:15,231:INFO:              psutil: 5.9.5
2023-06-14 12:42:15,231:INFO:PyCaret optional dependencies:
2023-06-14 12:42:15,244:INFO:                shap: Not installed
2023-06-14 12:42:15,244:INFO:           interpret: Not installed
2023-06-14 12:42:15,244:INFO:                umap: Not installed
2023-06-14 12:42:15,244:INFO:    pandas_profiling: Not installed
2023-06-14 12:42:15,244:INFO:  explainerdashboard: Not installed
2023-06-14 12:42:15,244:INFO:             autoviz: Not installed
2023-06-14 12:42:15,244:INFO:           fairlearn: Not installed
2023-06-14 12:42:15,244:INFO:             xgboost: Not installed
2023-06-14 12:42:15,244:INFO:            catboost: Not installed
2023-06-14 12:42:15,244:INFO:              kmodes: Not installed
2023-06-14 12:42:15,244:INFO:             mlxtend: Not installed
2023-06-14 12:42:15,245:INFO:       statsforecast: Not installed
2023-06-14 12:42:15,245:INFO:        tune_sklearn: Not installed
2023-06-14 12:42:15,245:INFO:                 ray: Not installed
2023-06-14 12:42:15,245:INFO:            hyperopt: Not installed
2023-06-14 12:42:15,245:INFO:              optuna: Not installed
2023-06-14 12:42:15,245:INFO:               skopt: Not installed
2023-06-14 12:42:15,245:INFO:              mlflow: Not installed
2023-06-14 12:42:15,245:INFO:              gradio: Not installed
2023-06-14 12:42:15,245:INFO:             fastapi: Not installed
2023-06-14 12:42:15,245:INFO:             uvicorn: Not installed
2023-06-14 12:42:15,245:INFO:              m2cgen: Not installed
2023-06-14 12:42:15,245:INFO:           evidently: Not installed
2023-06-14 12:42:15,245:INFO:               fugue: Not installed
2023-06-14 12:42:15,245:INFO:           streamlit: Not installed
2023-06-14 12:42:15,245:INFO:             prophet: Not installed
2023-06-14 12:42:15,245:INFO:None
2023-06-14 12:42:15,245:INFO:Set up data.
2023-06-14 12:42:15,379:INFO:Set up train/test split.
2023-06-14 12:42:15,386:INFO:Set up index.
2023-06-14 12:42:15,386:INFO:Set up folding strategy.
2023-06-14 12:42:15,387:INFO:Assigning column types.
2023-06-14 12:42:15,391:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 12:42:15,391:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,395:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,399:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:15,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:15,506:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,510:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,514:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,565:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,604:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:15,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:15,606:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 12:42:15,610:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,615:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,665:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:15,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:15,709:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,714:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,765:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,804:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:15,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:15,805:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 12:42:15,814:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,866:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:15,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:15,921:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:42:15,972:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:42:16,012:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:42:16,012:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,012:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 12:42:16,072:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:42:16,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:42:16,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:42:16,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:42:16,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,223:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 12:42:16,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:42:16,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,386:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:42:16,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,427:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 12:42:16,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,632:INFO:Preparing preprocessing pipeline...
2023-06-14 12:42:16,632:INFO:Set up simple imputation.
2023-06-14 12:42:16,673:INFO:Finished creating preprocessing pipeline.
2023-06-14 12:42:16,680:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\adamr\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bid_amount', '0', '1', '2', '3',
                                             '4', '5', '6', '7', '8', '9', '10',
                                             '11', '12', '13', '14', '15', '16',
                                             '17', '18', '19', '20', '21', '22',
                                             '23', '24', '25', '26', '27', '28', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-06-14 12:42:16,680:INFO:Creating final display dataframe.
2023-06-14 12:42:16,838:INFO:Setup _display_container:                     Description             Value
0                    Session id               278
1                        Target    combined_score
2                   Target type        Regression
3           Original data shape        (211, 597)
4        Transformed data shape        (211, 597)
5   Transformed train set shape        (147, 597)
6    Transformed test set shape         (64, 597)
7              Numeric features               596
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              636b
2023-06-14 12:42:16,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:16,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:17,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:17,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:42:17,045:INFO:setup() successfully completed in 2.02s...............
2023-06-14 12:42:17,045:INFO:Initializing compare_models()
2023-06-14 12:42:17,045:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 12:42:17,045:INFO:Checking exceptions
2023-06-14 12:42:17,047:INFO:Preparing display monitor
2023-06-14 12:42:17,051:INFO:Initializing Linear Regression
2023-06-14 12:42:17,051:INFO:Total runtime is 0.0 minutes
2023-06-14 12:42:17,051:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:17,051:INFO:Initializing create_model()
2023-06-14 12:42:17,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:17,051:INFO:Checking exceptions
2023-06-14 12:42:17,051:INFO:Importing libraries
2023-06-14 12:42:17,051:INFO:Copying training dataset
2023-06-14 12:42:17,055:INFO:Defining folds
2023-06-14 12:42:17,055:INFO:Declaring metric variables
2023-06-14 12:42:17,055:INFO:Importing untrained model
2023-06-14 12:42:17,055:INFO:Linear Regression Imported successfully
2023-06-14 12:42:17,056:INFO:Starting cross validation
2023-06-14 12:42:17,060:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:24,220:INFO:Calculating mean and std
2023-06-14 12:42:24,220:INFO:Creating metrics dataframe
2023-06-14 12:42:24,499:INFO:Uploading results into container
2023-06-14 12:42:24,500:INFO:Uploading model into container now
2023-06-14 12:42:24,500:INFO:_master_model_container: 1
2023-06-14 12:42:24,500:INFO:_display_container: 2
2023-06-14 12:42:24,500:INFO:LinearRegression(n_jobs=-1)
2023-06-14 12:42:24,500:INFO:create_model() successfully completed......................................
2023-06-14 12:42:24,558:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:24,558:INFO:Creating metrics dataframe
2023-06-14 12:42:24,563:INFO:Initializing Lasso Regression
2023-06-14 12:42:24,563:INFO:Total runtime is 0.12519668340682982 minutes
2023-06-14 12:42:24,563:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:24,563:INFO:Initializing create_model()
2023-06-14 12:42:24,563:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:24,563:INFO:Checking exceptions
2023-06-14 12:42:24,563:INFO:Importing libraries
2023-06-14 12:42:24,563:INFO:Copying training dataset
2023-06-14 12:42:24,568:INFO:Defining folds
2023-06-14 12:42:24,568:INFO:Declaring metric variables
2023-06-14 12:42:24,568:INFO:Importing untrained model
2023-06-14 12:42:24,568:INFO:Lasso Regression Imported successfully
2023-06-14 12:42:24,568:INFO:Starting cross validation
2023-06-14 12:42:24,570:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:26,828:INFO:Calculating mean and std
2023-06-14 12:42:26,829:INFO:Creating metrics dataframe
2023-06-14 12:42:27,118:INFO:Uploading results into container
2023-06-14 12:42:27,118:INFO:Uploading model into container now
2023-06-14 12:42:27,119:INFO:_master_model_container: 2
2023-06-14 12:42:27,119:INFO:_display_container: 2
2023-06-14 12:42:27,119:INFO:Lasso(random_state=278)
2023-06-14 12:42:27,119:INFO:create_model() successfully completed......................................
2023-06-14 12:42:27,174:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:27,175:INFO:Creating metrics dataframe
2023-06-14 12:42:27,179:INFO:Initializing Ridge Regression
2023-06-14 12:42:27,179:INFO:Total runtime is 0.16881091197331746 minutes
2023-06-14 12:42:27,179:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:27,180:INFO:Initializing create_model()
2023-06-14 12:42:27,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:27,180:INFO:Checking exceptions
2023-06-14 12:42:27,180:INFO:Importing libraries
2023-06-14 12:42:27,180:INFO:Copying training dataset
2023-06-14 12:42:27,184:INFO:Defining folds
2023-06-14 12:42:27,184:INFO:Declaring metric variables
2023-06-14 12:42:27,185:INFO:Importing untrained model
2023-06-14 12:42:27,185:INFO:Ridge Regression Imported successfully
2023-06-14 12:42:27,185:INFO:Starting cross validation
2023-06-14 12:42:27,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:29,507:INFO:Calculating mean and std
2023-06-14 12:42:29,507:INFO:Creating metrics dataframe
2023-06-14 12:42:29,795:INFO:Uploading results into container
2023-06-14 12:42:29,795:INFO:Uploading model into container now
2023-06-14 12:42:29,796:INFO:_master_model_container: 3
2023-06-14 12:42:29,796:INFO:_display_container: 2
2023-06-14 12:42:29,796:INFO:Ridge(random_state=278)
2023-06-14 12:42:29,796:INFO:create_model() successfully completed......................................
2023-06-14 12:42:29,854:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:29,854:INFO:Creating metrics dataframe
2023-06-14 12:42:29,858:INFO:Initializing Elastic Net
2023-06-14 12:42:29,859:INFO:Total runtime is 0.21347405115763346 minutes
2023-06-14 12:42:29,859:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:29,859:INFO:Initializing create_model()
2023-06-14 12:42:29,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:29,859:INFO:Checking exceptions
2023-06-14 12:42:29,859:INFO:Importing libraries
2023-06-14 12:42:29,859:INFO:Copying training dataset
2023-06-14 12:42:29,864:INFO:Defining folds
2023-06-14 12:42:29,864:INFO:Declaring metric variables
2023-06-14 12:42:29,865:INFO:Importing untrained model
2023-06-14 12:42:29,865:INFO:Elastic Net Imported successfully
2023-06-14 12:42:29,865:INFO:Starting cross validation
2023-06-14 12:42:29,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:30,751:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 12:42:30,758:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 12:42:32,342:INFO:Calculating mean and std
2023-06-14 12:42:32,343:INFO:Creating metrics dataframe
2023-06-14 12:42:32,624:INFO:Uploading results into container
2023-06-14 12:42:32,625:INFO:Uploading model into container now
2023-06-14 12:42:32,625:INFO:_master_model_container: 4
2023-06-14 12:42:32,625:INFO:_display_container: 2
2023-06-14 12:42:32,626:INFO:ElasticNet(random_state=278)
2023-06-14 12:42:32,626:INFO:create_model() successfully completed......................................
2023-06-14 12:42:32,685:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:32,685:INFO:Creating metrics dataframe
2023-06-14 12:42:32,690:INFO:Initializing Least Angle Regression
2023-06-14 12:42:32,690:INFO:Total runtime is 0.2606485843658447 minutes
2023-06-14 12:42:32,690:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:32,690:INFO:Initializing create_model()
2023-06-14 12:42:32,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:32,690:INFO:Checking exceptions
2023-06-14 12:42:32,690:INFO:Importing libraries
2023-06-14 12:42:32,690:INFO:Copying training dataset
2023-06-14 12:42:32,695:INFO:Defining folds
2023-06-14 12:42:32,695:INFO:Declaring metric variables
2023-06-14 12:42:32,695:INFO:Importing untrained model
2023-06-14 12:42:32,695:INFO:Least Angle Regression Imported successfully
2023-06-14 12:42:32,695:INFO:Starting cross validation
2023-06-14 12:42:32,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:32,828:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.184e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,830:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.105e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,834:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.074e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,836:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.058e+00, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,838:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.071e+00, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,838:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.064e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,839:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.059e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,842:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.047e+00, with an active set of 58 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,842:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.045e+00, with an active set of 58 regressors, and the smallest cholesky pivot element being 1.207e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,843:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.020e+00, with an active set of 60 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,850:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.214e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 6.076e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,853:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.227e+00, with an active set of 79 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,855:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=1.142e+00, with an active set of 82 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,855:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=1.113e+00, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,855:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.918e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,857:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.149e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,857:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.103e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 3.049e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,858:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.074e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,858:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.790e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,858:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.064e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,858:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.055e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 3.853e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,859:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.047e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,859:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.043e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,860:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.024e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.647e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,860:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=9.859e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,861:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.181e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,861:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.800e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 5.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,864:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.806e+00, with an active set of 49 regressors, and the smallest cholesky pivot element being 5.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,866:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.715e+00, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,867:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=9.983e-01, with an active set of 100 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,867:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.681e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.675e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.385e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=9.489e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=9.489e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,871:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=1.086e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=1.572e+00, with an active set of 69 regressors, and the smallest cholesky pivot element being 4.501e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,878:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.102e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,879:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.717e+00, with an active set of 71 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,880:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.625e+00, with an active set of 72 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,881:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.619e+00, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=8.064e-01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.608e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=7.955e-01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=7.929e-01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.771e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,885:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.926e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.673e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,887:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=7.761e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,888:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=9.808e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,888:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.606e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,889:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.606e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,891:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.601e+00, with an active set of 92 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,890:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=7.760e-01, with an active set of 83 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,893:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=9.296e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,893:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=7.725e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,893:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.647e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,893:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=7.725e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,894:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=7.703e-01, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=7.662e-01, with an active set of 88 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.627e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.861e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.641e+00, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,896:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.627e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 3.311e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,898:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.622e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 3.049e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,900:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=8.852e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,900:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=7.670e-01, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,901:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.146e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,901:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.212e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,901:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.133e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,903:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.453e+00, with an active set of 43 regressors, and the smallest cholesky pivot element being 3.404e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,905:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.571e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,906:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.571e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,910:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=8.478e-01, with an active set of 107 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,914:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.090e+00, with an active set of 64 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=1.801e+00, with an active set of 68 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=2.487e+01, with an active set of 124 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.078e+00, with an active set of 68 regressors, and the smallest cholesky pivot element being 3.404e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.296e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.790e+00, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=2.487e+01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=1.076e+00, with an active set of 71 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=1.076e+00, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=1.076e+00, with an active set of 71 regressors, and the smallest cholesky pivot element being 3.183e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,920:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.539e-01, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,920:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.771e+00, with an active set of 75 regressors, and the smallest cholesky pivot element being 3.311e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,920:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=2.588e+01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.706e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,920:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=2.467e+01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.706e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,921:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=2.419e+01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=8.757e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.861e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=8.753e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,924:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.830e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,924:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.741e+00, with an active set of 84 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,924:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.578e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,925:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.575e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.869e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,925:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=1.740e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,925:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=1.740e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=8.519e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.874e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.615e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.525e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.396e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=1.787e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,927:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.511e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,927:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.184e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,927:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=1.061e+00, with an active set of 86 regressors, and the smallest cholesky pivot element being 3.404e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,927:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.162e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.147e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.977e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=8.245e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.945e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.922e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.904e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.867e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.848e+01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,930:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.174e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,931:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.119e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,932:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=4.991e-01, with an active set of 60 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-06-14 12:42:32,932:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.991e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,932:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.974e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.746e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.116e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.168e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.494e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.432e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.115e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.115e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.485e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.089e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.386e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.259e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.085e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.207e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=8.648e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.065e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,935:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.039e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,935:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.018e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,936:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.231e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.706e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,937:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=8.640e-01, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,938:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=6.569e+00, with an active set of 63 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,940:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=4.957e+00, with an active set of 65 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,941:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.745e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=9.136e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.874e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=4.703e+00, with an active set of 77 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,947:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=9.013e-01, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,950:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=9.175e-01, with an active set of 97 regressors, and the smallest cholesky pivot element being 3.094e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,955:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=9.369e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,959:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=2.374e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,961:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=2.368e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,963:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=2.309e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,966:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=9.554e-01, with an active set of 116 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,966:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=4.919e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,967:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=9.552e-01, with an active set of 117 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,967:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=9.552e-01, with an active set of 117 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,971:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=5.355e+00, with an active set of 111 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,974:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=4.447e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,975:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=4.447e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=1.044e+01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=9.004e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.601e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=8.810e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.494e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,985:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=8.511e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.030e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,985:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.846e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.528e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,986:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.722e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,987:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.640e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,987:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.639e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,987:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.372e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:32,990:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=9.178e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:42:34,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:42:34,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:42:34,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:42:34,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:42:34,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:42:34,810:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=9.849e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,828:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=5.400e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,839:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=6.173e-01, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,842:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=6.058e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,857:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=6.422e-01, with an active set of 112 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,863:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.066e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,864:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=7.061e-01, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,867:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=7.407e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,867:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=7.217e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=7.185e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=7.064e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.616e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=7.024e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.185e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.714e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.701e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.667e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,871:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.661e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,913:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.839e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.609e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.566e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.566e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.538e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.490e+00, with an active set of 48 regressors, and the smallest cholesky pivot element being 3.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.433e+00, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.431e+00, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.420e+00, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.380e+00, with an active set of 50 regressors, and the smallest cholesky pivot element being 3.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.437e+00, with an active set of 67 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,924:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.432e+00, with an active set of 68 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.409e+00, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.404e+00, with an active set of 84 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.400e+00, with an active set of 87 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,930:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.395e+00, with an active set of 91 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,938:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.561e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:34,948:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=3.833e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:36,563:INFO:Calculating mean and std
2023-06-14 12:42:36,564:INFO:Creating metrics dataframe
2023-06-14 12:42:36,838:INFO:Uploading results into container
2023-06-14 12:42:36,839:INFO:Uploading model into container now
2023-06-14 12:42:36,839:INFO:_master_model_container: 5
2023-06-14 12:42:36,839:INFO:_display_container: 2
2023-06-14 12:42:36,839:INFO:Lars(random_state=278)
2023-06-14 12:42:36,839:INFO:create_model() successfully completed......................................
2023-06-14 12:42:36,903:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:36,903:INFO:Creating metrics dataframe
2023-06-14 12:42:36,907:INFO:Initializing Lasso Least Angle Regression
2023-06-14 12:42:36,907:INFO:Total runtime is 0.33094306389490763 minutes
2023-06-14 12:42:36,907:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:36,907:INFO:Initializing create_model()
2023-06-14 12:42:36,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:36,907:INFO:Checking exceptions
2023-06-14 12:42:36,907:INFO:Importing libraries
2023-06-14 12:42:36,907:INFO:Copying training dataset
2023-06-14 12:42:36,913:INFO:Defining folds
2023-06-14 12:42:36,913:INFO:Declaring metric variables
2023-06-14 12:42:36,913:INFO:Importing untrained model
2023-06-14 12:42:36,914:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 12:42:36,914:INFO:Starting cross validation
2023-06-14 12:42:36,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:37,056:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.093e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:37,072:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.199e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:37,098:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.212e+00, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:37,113:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.296e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:42:39,173:INFO:Calculating mean and std
2023-06-14 12:42:39,174:INFO:Creating metrics dataframe
2023-06-14 12:42:39,470:INFO:Uploading results into container
2023-06-14 12:42:39,471:INFO:Uploading model into container now
2023-06-14 12:42:39,471:INFO:_master_model_container: 6
2023-06-14 12:42:39,471:INFO:_display_container: 2
2023-06-14 12:42:39,472:INFO:LassoLars(random_state=278)
2023-06-14 12:42:39,472:INFO:create_model() successfully completed......................................
2023-06-14 12:42:39,531:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:39,531:INFO:Creating metrics dataframe
2023-06-14 12:42:39,536:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 12:42:39,536:INFO:Total runtime is 0.3747530539830526 minutes
2023-06-14 12:42:39,536:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:39,536:INFO:Initializing create_model()
2023-06-14 12:42:39,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:39,536:INFO:Checking exceptions
2023-06-14 12:42:39,536:INFO:Importing libraries
2023-06-14 12:42:39,536:INFO:Copying training dataset
2023-06-14 12:42:39,540:INFO:Defining folds
2023-06-14 12:42:39,540:INFO:Declaring metric variables
2023-06-14 12:42:39,540:INFO:Importing untrained model
2023-06-14 12:42:39,541:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 12:42:39,541:INFO:Starting cross validation
2023-06-14 12:42:39,542:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:41,951:INFO:Calculating mean and std
2023-06-14 12:42:41,952:INFO:Creating metrics dataframe
2023-06-14 12:42:42,242:INFO:Uploading results into container
2023-06-14 12:42:42,244:INFO:Uploading model into container now
2023-06-14 12:42:42,244:INFO:_master_model_container: 7
2023-06-14 12:42:42,244:INFO:_display_container: 2
2023-06-14 12:42:42,244:INFO:OrthogonalMatchingPursuit()
2023-06-14 12:42:42,245:INFO:create_model() successfully completed......................................
2023-06-14 12:42:42,305:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:42,305:INFO:Creating metrics dataframe
2023-06-14 12:42:42,311:INFO:Initializing Bayesian Ridge
2023-06-14 12:42:42,311:INFO:Total runtime is 0.42100065151850385 minutes
2023-06-14 12:42:42,311:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:42,311:INFO:Initializing create_model()
2023-06-14 12:42:42,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:42,312:INFO:Checking exceptions
2023-06-14 12:42:42,312:INFO:Importing libraries
2023-06-14 12:42:42,312:INFO:Copying training dataset
2023-06-14 12:42:42,319:INFO:Defining folds
2023-06-14 12:42:42,320:INFO:Declaring metric variables
2023-06-14 12:42:42,320:INFO:Importing untrained model
2023-06-14 12:42:42,321:INFO:Bayesian Ridge Imported successfully
2023-06-14 12:42:42,321:INFO:Starting cross validation
2023-06-14 12:42:42,324:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:44,703:INFO:Calculating mean and std
2023-06-14 12:42:44,704:INFO:Creating metrics dataframe
2023-06-14 12:42:44,994:INFO:Uploading results into container
2023-06-14 12:42:44,994:INFO:Uploading model into container now
2023-06-14 12:42:44,994:INFO:_master_model_container: 8
2023-06-14 12:42:44,995:INFO:_display_container: 2
2023-06-14 12:42:44,995:INFO:BayesianRidge()
2023-06-14 12:42:44,995:INFO:create_model() successfully completed......................................
2023-06-14 12:42:45,052:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:45,052:INFO:Creating metrics dataframe
2023-06-14 12:42:45,057:INFO:Initializing Passive Aggressive Regressor
2023-06-14 12:42:45,057:INFO:Total runtime is 0.4667732954025269 minutes
2023-06-14 12:42:45,057:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:45,057:INFO:Initializing create_model()
2023-06-14 12:42:45,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:45,057:INFO:Checking exceptions
2023-06-14 12:42:45,057:INFO:Importing libraries
2023-06-14 12:42:45,057:INFO:Copying training dataset
2023-06-14 12:42:45,062:INFO:Defining folds
2023-06-14 12:42:45,062:INFO:Declaring metric variables
2023-06-14 12:42:45,062:INFO:Importing untrained model
2023-06-14 12:42:45,063:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 12:42:45,063:INFO:Starting cross validation
2023-06-14 12:42:45,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:47,290:INFO:Calculating mean and std
2023-06-14 12:42:47,291:INFO:Creating metrics dataframe
2023-06-14 12:42:47,576:INFO:Uploading results into container
2023-06-14 12:42:47,576:INFO:Uploading model into container now
2023-06-14 12:42:47,577:INFO:_master_model_container: 9
2023-06-14 12:42:47,577:INFO:_display_container: 2
2023-06-14 12:42:47,577:INFO:PassiveAggressiveRegressor(random_state=278)
2023-06-14 12:42:47,577:INFO:create_model() successfully completed......................................
2023-06-14 12:42:47,635:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:47,635:INFO:Creating metrics dataframe
2023-06-14 12:42:47,640:INFO:Initializing Huber Regressor
2023-06-14 12:42:47,640:INFO:Total runtime is 0.5098206877708436 minutes
2023-06-14 12:42:47,641:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:47,641:INFO:Initializing create_model()
2023-06-14 12:42:47,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:47,641:INFO:Checking exceptions
2023-06-14 12:42:47,641:INFO:Importing libraries
2023-06-14 12:42:47,641:INFO:Copying training dataset
2023-06-14 12:42:47,646:INFO:Defining folds
2023-06-14 12:42:47,646:INFO:Declaring metric variables
2023-06-14 12:42:47,646:INFO:Importing untrained model
2023-06-14 12:42:47,647:INFO:Huber Regressor Imported successfully
2023-06-14 12:42:47,647:INFO:Starting cross validation
2023-06-14 12:42:47,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:47,940:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:42:47,949:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:42:47,967:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:42:47,971:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:42:47,972:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:42:47,992:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:42:48,013:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:42:48,023:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:42:48,974:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:42:48,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:42:50,384:INFO:Calculating mean and std
2023-06-14 12:42:50,385:INFO:Creating metrics dataframe
2023-06-14 12:42:50,675:INFO:Uploading results into container
2023-06-14 12:42:50,675:INFO:Uploading model into container now
2023-06-14 12:42:50,677:INFO:_master_model_container: 10
2023-06-14 12:42:50,677:INFO:_display_container: 2
2023-06-14 12:42:50,677:INFO:HuberRegressor()
2023-06-14 12:42:50,677:INFO:create_model() successfully completed......................................
2023-06-14 12:42:50,735:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:50,735:INFO:Creating metrics dataframe
2023-06-14 12:42:50,740:INFO:Initializing K Neighbors Regressor
2023-06-14 12:42:50,740:INFO:Total runtime is 0.5614862004915874 minutes
2023-06-14 12:42:50,740:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:50,740:INFO:Initializing create_model()
2023-06-14 12:42:50,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:50,740:INFO:Checking exceptions
2023-06-14 12:42:50,740:INFO:Importing libraries
2023-06-14 12:42:50,740:INFO:Copying training dataset
2023-06-14 12:42:50,745:INFO:Defining folds
2023-06-14 12:42:50,745:INFO:Declaring metric variables
2023-06-14 12:42:50,746:INFO:Importing untrained model
2023-06-14 12:42:50,746:INFO:K Neighbors Regressor Imported successfully
2023-06-14 12:42:50,746:INFO:Starting cross validation
2023-06-14 12:42:50,748:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:53,151:INFO:Calculating mean and std
2023-06-14 12:42:53,152:INFO:Creating metrics dataframe
2023-06-14 12:42:53,448:INFO:Uploading results into container
2023-06-14 12:42:53,448:INFO:Uploading model into container now
2023-06-14 12:42:53,448:INFO:_master_model_container: 11
2023-06-14 12:42:53,449:INFO:_display_container: 2
2023-06-14 12:42:53,449:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 12:42:53,449:INFO:create_model() successfully completed......................................
2023-06-14 12:42:53,510:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:53,510:INFO:Creating metrics dataframe
2023-06-14 12:42:53,514:INFO:Initializing Decision Tree Regressor
2023-06-14 12:42:53,514:INFO:Total runtime is 0.6077252388000489 minutes
2023-06-14 12:42:53,515:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:53,515:INFO:Initializing create_model()
2023-06-14 12:42:53,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:53,515:INFO:Checking exceptions
2023-06-14 12:42:53,515:INFO:Importing libraries
2023-06-14 12:42:53,515:INFO:Copying training dataset
2023-06-14 12:42:53,520:INFO:Defining folds
2023-06-14 12:42:53,520:INFO:Declaring metric variables
2023-06-14 12:42:53,520:INFO:Importing untrained model
2023-06-14 12:42:53,520:INFO:Decision Tree Regressor Imported successfully
2023-06-14 12:42:53,520:INFO:Starting cross validation
2023-06-14 12:42:53,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:55,748:INFO:Calculating mean and std
2023-06-14 12:42:55,749:INFO:Creating metrics dataframe
2023-06-14 12:42:56,041:INFO:Uploading results into container
2023-06-14 12:42:56,042:INFO:Uploading model into container now
2023-06-14 12:42:56,042:INFO:_master_model_container: 12
2023-06-14 12:42:56,042:INFO:_display_container: 2
2023-06-14 12:42:56,042:INFO:DecisionTreeRegressor(random_state=278)
2023-06-14 12:42:56,042:INFO:create_model() successfully completed......................................
2023-06-14 12:42:56,102:INFO:SubProcess create_model() end ==================================
2023-06-14 12:42:56,102:INFO:Creating metrics dataframe
2023-06-14 12:42:56,106:INFO:Initializing Random Forest Regressor
2023-06-14 12:42:56,106:INFO:Total runtime is 0.6509274681409201 minutes
2023-06-14 12:42:56,107:INFO:SubProcess create_model() called ==================================
2023-06-14 12:42:56,107:INFO:Initializing create_model()
2023-06-14 12:42:56,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:42:56,107:INFO:Checking exceptions
2023-06-14 12:42:56,107:INFO:Importing libraries
2023-06-14 12:42:56,107:INFO:Copying training dataset
2023-06-14 12:42:56,112:INFO:Defining folds
2023-06-14 12:42:56,112:INFO:Declaring metric variables
2023-06-14 12:42:56,112:INFO:Importing untrained model
2023-06-14 12:42:56,112:INFO:Random Forest Regressor Imported successfully
2023-06-14 12:42:56,113:INFO:Starting cross validation
2023-06-14 12:42:56,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:42:57,482:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:42:59,987:INFO:Calculating mean and std
2023-06-14 12:42:59,987:INFO:Creating metrics dataframe
2023-06-14 12:43:00,302:INFO:Uploading results into container
2023-06-14 12:43:00,302:INFO:Uploading model into container now
2023-06-14 12:43:00,303:INFO:_master_model_container: 13
2023-06-14 12:43:00,303:INFO:_display_container: 2
2023-06-14 12:43:00,303:INFO:RandomForestRegressor(n_jobs=-1, random_state=278)
2023-06-14 12:43:00,303:INFO:create_model() successfully completed......................................
2023-06-14 12:43:00,363:INFO:SubProcess create_model() end ==================================
2023-06-14 12:43:00,363:INFO:Creating metrics dataframe
2023-06-14 12:43:00,367:INFO:Initializing Extra Trees Regressor
2023-06-14 12:43:00,367:INFO:Total runtime is 0.7219332098960877 minutes
2023-06-14 12:43:00,367:INFO:SubProcess create_model() called ==================================
2023-06-14 12:43:00,368:INFO:Initializing create_model()
2023-06-14 12:43:00,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:43:00,368:INFO:Checking exceptions
2023-06-14 12:43:00,368:INFO:Importing libraries
2023-06-14 12:43:00,368:INFO:Copying training dataset
2023-06-14 12:43:00,372:INFO:Defining folds
2023-06-14 12:43:00,372:INFO:Declaring metric variables
2023-06-14 12:43:00,372:INFO:Importing untrained model
2023-06-14 12:43:00,373:INFO:Extra Trees Regressor Imported successfully
2023-06-14 12:43:00,373:INFO:Starting cross validation
2023-06-14 12:43:00,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:43:01,607:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:43:04,155:INFO:Calculating mean and std
2023-06-14 12:43:04,156:INFO:Creating metrics dataframe
2023-06-14 12:43:04,477:INFO:Uploading results into container
2023-06-14 12:43:04,478:INFO:Uploading model into container now
2023-06-14 12:43:04,478:INFO:_master_model_container: 14
2023-06-14 12:43:04,478:INFO:_display_container: 2
2023-06-14 12:43:04,478:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=278)
2023-06-14 12:43:04,478:INFO:create_model() successfully completed......................................
2023-06-14 12:43:04,538:INFO:SubProcess create_model() end ==================================
2023-06-14 12:43:04,538:INFO:Creating metrics dataframe
2023-06-14 12:43:04,543:INFO:Initializing AdaBoost Regressor
2023-06-14 12:43:04,543:INFO:Total runtime is 0.7915396332740784 minutes
2023-06-14 12:43:04,543:INFO:SubProcess create_model() called ==================================
2023-06-14 12:43:04,543:INFO:Initializing create_model()
2023-06-14 12:43:04,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:43:04,543:INFO:Checking exceptions
2023-06-14 12:43:04,544:INFO:Importing libraries
2023-06-14 12:43:04,544:INFO:Copying training dataset
2023-06-14 12:43:04,549:INFO:Defining folds
2023-06-14 12:43:04,549:INFO:Declaring metric variables
2023-06-14 12:43:04,549:INFO:Importing untrained model
2023-06-14 12:43:04,550:INFO:AdaBoost Regressor Imported successfully
2023-06-14 12:43:04,550:INFO:Starting cross validation
2023-06-14 12:43:04,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:43:07,672:INFO:Calculating mean and std
2023-06-14 12:43:07,673:INFO:Creating metrics dataframe
2023-06-14 12:43:07,999:INFO:Uploading results into container
2023-06-14 12:43:07,999:INFO:Uploading model into container now
2023-06-14 12:43:07,999:INFO:_master_model_container: 15
2023-06-14 12:43:07,999:INFO:_display_container: 2
2023-06-14 12:43:07,999:INFO:AdaBoostRegressor(random_state=278)
2023-06-14 12:43:08,001:INFO:create_model() successfully completed......................................
2023-06-14 12:43:08,058:INFO:SubProcess create_model() end ==================================
2023-06-14 12:43:08,059:INFO:Creating metrics dataframe
2023-06-14 12:43:08,063:INFO:Initializing Gradient Boosting Regressor
2023-06-14 12:43:08,064:INFO:Total runtime is 0.8502170046170553 minutes
2023-06-14 12:43:08,064:INFO:SubProcess create_model() called ==================================
2023-06-14 12:43:08,064:INFO:Initializing create_model()
2023-06-14 12:43:08,064:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:43:08,064:INFO:Checking exceptions
2023-06-14 12:43:08,064:INFO:Importing libraries
2023-06-14 12:43:08,064:INFO:Copying training dataset
2023-06-14 12:43:08,068:INFO:Defining folds
2023-06-14 12:43:08,069:INFO:Declaring metric variables
2023-06-14 12:43:08,069:INFO:Importing untrained model
2023-06-14 12:43:08,069:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 12:43:08,069:INFO:Starting cross validation
2023-06-14 12:43:08,071:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:43:11,441:INFO:Calculating mean and std
2023-06-14 12:43:11,443:INFO:Creating metrics dataframe
2023-06-14 12:43:11,756:INFO:Uploading results into container
2023-06-14 12:43:11,756:INFO:Uploading model into container now
2023-06-14 12:43:11,757:INFO:_master_model_container: 16
2023-06-14 12:43:11,757:INFO:_display_container: 2
2023-06-14 12:43:11,757:INFO:GradientBoostingRegressor(random_state=278)
2023-06-14 12:43:11,757:INFO:create_model() successfully completed......................................
2023-06-14 12:43:11,816:INFO:SubProcess create_model() end ==================================
2023-06-14 12:43:11,816:INFO:Creating metrics dataframe
2023-06-14 12:43:11,821:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 12:43:11,821:INFO:Total runtime is 0.9128368457158407 minutes
2023-06-14 12:43:11,821:INFO:SubProcess create_model() called ==================================
2023-06-14 12:43:11,821:INFO:Initializing create_model()
2023-06-14 12:43:11,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:43:11,822:INFO:Checking exceptions
2023-06-14 12:43:11,822:INFO:Importing libraries
2023-06-14 12:43:11,822:INFO:Copying training dataset
2023-06-14 12:43:11,826:INFO:Defining folds
2023-06-14 12:43:11,826:INFO:Declaring metric variables
2023-06-14 12:43:11,827:INFO:Importing untrained model
2023-06-14 12:43:11,827:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 12:43:11,827:INFO:Starting cross validation
2023-06-14 12:43:11,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:43:14,295:INFO:Calculating mean and std
2023-06-14 12:43:14,295:INFO:Creating metrics dataframe
2023-06-14 12:43:14,614:INFO:Uploading results into container
2023-06-14 12:43:14,614:INFO:Uploading model into container now
2023-06-14 12:43:14,614:INFO:_master_model_container: 17
2023-06-14 12:43:14,615:INFO:_display_container: 2
2023-06-14 12:43:14,615:INFO:LGBMRegressor(random_state=278)
2023-06-14 12:43:14,615:INFO:create_model() successfully completed......................................
2023-06-14 12:43:14,677:INFO:SubProcess create_model() end ==================================
2023-06-14 12:43:14,677:INFO:Creating metrics dataframe
2023-06-14 12:43:14,682:INFO:Initializing Dummy Regressor
2023-06-14 12:43:14,682:INFO:Total runtime is 0.960514775911967 minutes
2023-06-14 12:43:14,682:INFO:SubProcess create_model() called ==================================
2023-06-14 12:43:14,682:INFO:Initializing create_model()
2023-06-14 12:43:14,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002176D91B3A0>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:43:14,682:INFO:Checking exceptions
2023-06-14 12:43:14,682:INFO:Importing libraries
2023-06-14 12:43:14,682:INFO:Copying training dataset
2023-06-14 12:43:14,687:INFO:Defining folds
2023-06-14 12:43:14,687:INFO:Declaring metric variables
2023-06-14 12:43:14,687:INFO:Importing untrained model
2023-06-14 12:43:14,687:INFO:Dummy Regressor Imported successfully
2023-06-14 12:43:14,687:INFO:Starting cross validation
2023-06-14 12:43:14,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:43:17,061:INFO:Calculating mean and std
2023-06-14 12:43:17,061:INFO:Creating metrics dataframe
2023-06-14 12:43:17,374:INFO:Uploading results into container
2023-06-14 12:43:17,376:INFO:Uploading model into container now
2023-06-14 12:43:17,376:INFO:_master_model_container: 18
2023-06-14 12:43:17,376:INFO:_display_container: 2
2023-06-14 12:43:17,376:INFO:DummyRegressor()
2023-06-14 12:43:17,376:INFO:create_model() successfully completed......................................
2023-06-14 12:43:17,434:INFO:SubProcess create_model() end ==================================
2023-06-14 12:43:17,434:INFO:Creating metrics dataframe
2023-06-14 12:43:17,441:INFO:Initializing create_model()
2023-06-14 12:43:17,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002176D826980>, estimator=AdaBoostRegressor(random_state=278), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:43:17,441:INFO:Checking exceptions
2023-06-14 12:43:17,441:INFO:Importing libraries
2023-06-14 12:43:17,442:INFO:Copying training dataset
2023-06-14 12:43:17,446:INFO:Defining folds
2023-06-14 12:43:17,446:INFO:Declaring metric variables
2023-06-14 12:43:17,446:INFO:Importing untrained model
2023-06-14 12:43:17,446:INFO:Declaring custom model
2023-06-14 12:43:17,446:INFO:AdaBoost Regressor Imported successfully
2023-06-14 12:43:17,449:INFO:Cross validation set to False
2023-06-14 12:43:17,449:INFO:Fitting Model
2023-06-14 12:43:18,047:INFO:AdaBoostRegressor(random_state=278)
2023-06-14 12:43:18,048:INFO:create_model() successfully completed......................................
2023-06-14 12:43:18,121:INFO:_master_model_container: 18
2023-06-14 12:43:18,121:INFO:_display_container: 2
2023-06-14 12:43:18,121:INFO:AdaBoostRegressor(random_state=278)
2023-06-14 12:43:18,121:INFO:compare_models() successfully completed......................................
2023-06-14 12:45:06,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:45:06,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:45:06,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:45:06,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:45:06,718:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:45:07,503:INFO:PyCaret RegressionExperiment
2023-06-14 12:45:07,503:INFO:Logging name: reg-default-name
2023-06-14 12:45:07,503:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 12:45:07,503:INFO:version 3.0.2
2023-06-14 12:45:07,503:INFO:Initializing setup()
2023-06-14 12:45:07,503:INFO:self.USI: 214e
2023-06-14 12:45:07,503:INFO:self._variable_keys: {'exp_name_log', 'exp_id', 'idx', 'html_param', 'transform_target_param', 'y_test', 'pipeline', 'seed', 'X', 'n_jobs_param', 'USI', 'fold_generator', 'y_train', '_ml_usecase', 'data', '_available_plots', 'logging_param', 'fold_groups_param', 'memory', 'X_test', 'log_plots_param', 'y', 'gpu_param', 'fold_shuffle_param', 'target_param', 'gpu_n_jobs_param', 'X_train'}
2023-06-14 12:45:07,504:INFO:Checking environment
2023-06-14 12:45:07,504:INFO:python_version: 3.10.11
2023-06-14 12:45:07,504:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-06-14 12:45:07,504:INFO:machine: AMD64
2023-06-14 12:45:07,517:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 12:45:07,522:INFO:Memory: svmem(total=17013329920, available=3268534272, percent=80.8, used=13744795648, free=3268534272)
2023-06-14 12:45:07,522:INFO:Physical Core: 4
2023-06-14 12:45:07,522:INFO:Logical Core: 8
2023-06-14 12:45:07,522:INFO:Checking libraries
2023-06-14 12:45:07,522:INFO:System:
2023-06-14 12:45:07,522:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-06-14 12:45:07,522:INFO:executable: E:\Machine learning\mini\adam\Scripts\python.exe
2023-06-14 12:45:07,522:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 12:45:07,522:INFO:PyCaret required dependencies:
2023-06-14 12:45:07,522:INFO:                 pip: 23.0.1
2023-06-14 12:45:07,522:INFO:          setuptools: 65.5.0
2023-06-14 12:45:07,522:INFO:             pycaret: 3.0.2
2023-06-14 12:45:07,523:INFO:             IPython: 8.14.0
2023-06-14 12:45:07,523:INFO:          ipywidgets: 8.0.6
2023-06-14 12:45:07,523:INFO:                tqdm: 4.65.0
2023-06-14 12:45:07,523:INFO:               numpy: 1.23.5
2023-06-14 12:45:07,523:INFO:              pandas: 1.5.3
2023-06-14 12:45:07,523:INFO:              jinja2: 3.1.2
2023-06-14 12:45:07,523:INFO:               scipy: 1.10.1
2023-06-14 12:45:07,523:INFO:              joblib: 1.2.0
2023-06-14 12:45:07,523:INFO:             sklearn: 1.2.2
2023-06-14 12:45:07,523:INFO:                pyod: 1.0.9
2023-06-14 12:45:07,523:INFO:            imblearn: 0.10.1
2023-06-14 12:45:07,523:INFO:   category_encoders: 2.6.1
2023-06-14 12:45:07,523:INFO:            lightgbm: 3.3.5
2023-06-14 12:45:07,523:INFO:               numba: 0.57.0
2023-06-14 12:45:07,523:INFO:            requests: 2.31.0
2023-06-14 12:45:07,523:INFO:          matplotlib: 3.7.1
2023-06-14 12:45:07,523:INFO:          scikitplot: 0.3.7
2023-06-14 12:45:07,523:INFO:         yellowbrick: 1.5
2023-06-14 12:45:07,523:INFO:              plotly: 5.15.0
2023-06-14 12:45:07,523:INFO:             kaleido: 0.2.1
2023-06-14 12:45:07,523:INFO:         statsmodels: 0.14.0
2023-06-14 12:45:07,523:INFO:              sktime: 0.17.0
2023-06-14 12:45:07,523:INFO:               tbats: 1.1.3
2023-06-14 12:45:07,523:INFO:            pmdarima: 2.0.3
2023-06-14 12:45:07,523:INFO:              psutil: 5.9.5
2023-06-14 12:45:07,524:INFO:PyCaret optional dependencies:
2023-06-14 12:45:07,536:INFO:                shap: Not installed
2023-06-14 12:45:07,536:INFO:           interpret: Not installed
2023-06-14 12:45:07,536:INFO:                umap: Not installed
2023-06-14 12:45:07,536:INFO:    pandas_profiling: Not installed
2023-06-14 12:45:07,536:INFO:  explainerdashboard: Not installed
2023-06-14 12:45:07,536:INFO:             autoviz: Not installed
2023-06-14 12:45:07,536:INFO:           fairlearn: Not installed
2023-06-14 12:45:07,536:INFO:             xgboost: Not installed
2023-06-14 12:45:07,536:INFO:            catboost: Not installed
2023-06-14 12:45:07,536:INFO:              kmodes: Not installed
2023-06-14 12:45:07,536:INFO:             mlxtend: Not installed
2023-06-14 12:45:07,536:INFO:       statsforecast: Not installed
2023-06-14 12:45:07,536:INFO:        tune_sklearn: Not installed
2023-06-14 12:45:07,536:INFO:                 ray: Not installed
2023-06-14 12:45:07,536:INFO:            hyperopt: Not installed
2023-06-14 12:45:07,537:INFO:              optuna: Not installed
2023-06-14 12:45:07,537:INFO:               skopt: Not installed
2023-06-14 12:45:07,537:INFO:              mlflow: Not installed
2023-06-14 12:45:07,537:INFO:              gradio: Not installed
2023-06-14 12:45:07,537:INFO:             fastapi: Not installed
2023-06-14 12:45:07,537:INFO:             uvicorn: Not installed
2023-06-14 12:45:07,537:INFO:              m2cgen: Not installed
2023-06-14 12:45:07,537:INFO:           evidently: Not installed
2023-06-14 12:45:07,537:INFO:               fugue: Not installed
2023-06-14 12:45:07,537:INFO:           streamlit: Not installed
2023-06-14 12:45:07,537:INFO:             prophet: Not installed
2023-06-14 12:45:07,537:INFO:None
2023-06-14 12:45:07,537:INFO:Set up data.
2023-06-14 12:45:07,664:INFO:Set up train/test split.
2023-06-14 12:45:07,672:INFO:Set up index.
2023-06-14 12:45:07,673:INFO:Set up folding strategy.
2023-06-14 12:45:07,673:INFO:Assigning column types.
2023-06-14 12:45:07,677:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 12:45:07,677:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,680:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,684:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,784:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:07,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:07,796:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,801:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,805:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,857:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:07,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:07,918:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 12:45:07,923:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,927:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:45:07,981:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,024:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,029:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,034:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,098:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,173:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 12:45:08,180:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,311:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,401:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,401:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 12:45:08,463:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,503:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,701:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,702:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 12:45:08,769:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,809:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,877:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:45:08,921:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:08,921:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 12:45:09,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:09,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:09,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:09,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:09,132:INFO:Preparing preprocessing pipeline...
2023-06-14 12:45:09,133:INFO:Set up simple imputation.
2023-06-14 12:45:09,174:INFO:Finished creating preprocessing pipeline.
2023-06-14 12:45:09,181:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\adamr\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bid_amount', '0', '1', '2', '3',
                                             '4', '5', '6', '7', '8', '9', '10',
                                             '11', '12', '13', '14', '15', '16',
                                             '17', '18', '19', '20', '21', '22',
                                             '23', '24', '25', '26', '27', '28', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-06-14 12:45:09,181:INFO:Creating final display dataframe.
2023-06-14 12:45:09,360:INFO:Setup _display_container:                     Description             Value
0                    Session id              8186
1                        Target    combined_score
2                   Target type        Regression
3           Original data shape        (211, 597)
4        Transformed data shape        (211, 597)
5   Transformed train set shape        (147, 597)
6    Transformed test set shape         (64, 597)
7              Numeric features               596
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              214e
2023-06-14 12:45:09,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:09,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:09,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:09,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:45:09,611:INFO:setup() successfully completed in 2.33s...............
2023-06-14 12:45:09,611:INFO:Initializing compare_models()
2023-06-14 12:45:09,611:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 12:45:09,611:INFO:Checking exceptions
2023-06-14 12:45:09,613:INFO:Preparing display monitor
2023-06-14 12:45:09,616:INFO:Initializing Linear Regression
2023-06-14 12:45:09,617:INFO:Total runtime is 1.6065438588460288e-05 minutes
2023-06-14 12:45:09,617:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:09,617:INFO:Initializing create_model()
2023-06-14 12:45:09,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:09,617:INFO:Checking exceptions
2023-06-14 12:45:09,617:INFO:Importing libraries
2023-06-14 12:45:09,617:INFO:Copying training dataset
2023-06-14 12:45:09,622:INFO:Defining folds
2023-06-14 12:45:09,622:INFO:Declaring metric variables
2023-06-14 12:45:09,622:INFO:Importing untrained model
2023-06-14 12:45:09,623:INFO:Linear Regression Imported successfully
2023-06-14 12:45:09,623:INFO:Starting cross validation
2023-06-14 12:45:09,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:16,838:INFO:Calculating mean and std
2023-06-14 12:45:16,839:INFO:Creating metrics dataframe
2023-06-14 12:45:17,185:INFO:Uploading results into container
2023-06-14 12:45:17,186:INFO:Uploading model into container now
2023-06-14 12:45:17,186:INFO:_master_model_container: 1
2023-06-14 12:45:17,186:INFO:_display_container: 2
2023-06-14 12:45:17,186:INFO:LinearRegression(n_jobs=-1)
2023-06-14 12:45:17,186:INFO:create_model() successfully completed......................................
2023-06-14 12:45:17,246:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:17,246:INFO:Creating metrics dataframe
2023-06-14 12:45:17,250:INFO:Initializing Lasso Regression
2023-06-14 12:45:17,250:INFO:Total runtime is 0.12723798751831053 minutes
2023-06-14 12:45:17,250:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:17,250:INFO:Initializing create_model()
2023-06-14 12:45:17,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:17,250:INFO:Checking exceptions
2023-06-14 12:45:17,250:INFO:Importing libraries
2023-06-14 12:45:17,250:INFO:Copying training dataset
2023-06-14 12:45:17,255:INFO:Defining folds
2023-06-14 12:45:17,255:INFO:Declaring metric variables
2023-06-14 12:45:17,255:INFO:Importing untrained model
2023-06-14 12:45:17,256:INFO:Lasso Regression Imported successfully
2023-06-14 12:45:17,256:INFO:Starting cross validation
2023-06-14 12:45:17,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:19,739:INFO:Calculating mean and std
2023-06-14 12:45:19,740:INFO:Creating metrics dataframe
2023-06-14 12:45:20,054:INFO:Uploading results into container
2023-06-14 12:45:20,054:INFO:Uploading model into container now
2023-06-14 12:45:20,054:INFO:_master_model_container: 2
2023-06-14 12:45:20,056:INFO:_display_container: 2
2023-06-14 12:45:20,056:INFO:Lasso(random_state=8186)
2023-06-14 12:45:20,056:INFO:create_model() successfully completed......................................
2023-06-14 12:45:20,114:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:20,114:INFO:Creating metrics dataframe
2023-06-14 12:45:20,118:INFO:Initializing Ridge Regression
2023-06-14 12:45:20,118:INFO:Total runtime is 0.17502810557683307 minutes
2023-06-14 12:45:20,118:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:20,118:INFO:Initializing create_model()
2023-06-14 12:45:20,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:20,118:INFO:Checking exceptions
2023-06-14 12:45:20,118:INFO:Importing libraries
2023-06-14 12:45:20,119:INFO:Copying training dataset
2023-06-14 12:45:20,122:INFO:Defining folds
2023-06-14 12:45:20,122:INFO:Declaring metric variables
2023-06-14 12:45:20,123:INFO:Importing untrained model
2023-06-14 12:45:20,123:INFO:Ridge Regression Imported successfully
2023-06-14 12:45:20,123:INFO:Starting cross validation
2023-06-14 12:45:20,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:22,587:INFO:Calculating mean and std
2023-06-14 12:45:22,587:INFO:Creating metrics dataframe
2023-06-14 12:45:22,904:INFO:Uploading results into container
2023-06-14 12:45:22,905:INFO:Uploading model into container now
2023-06-14 12:45:22,905:INFO:_master_model_container: 3
2023-06-14 12:45:22,905:INFO:_display_container: 2
2023-06-14 12:45:22,906:INFO:Ridge(random_state=8186)
2023-06-14 12:45:22,906:INFO:create_model() successfully completed......................................
2023-06-14 12:45:22,966:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:22,966:INFO:Creating metrics dataframe
2023-06-14 12:45:22,969:INFO:Initializing Elastic Net
2023-06-14 12:45:22,969:INFO:Total runtime is 0.22255855401357014 minutes
2023-06-14 12:45:22,969:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:22,969:INFO:Initializing create_model()
2023-06-14 12:45:22,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:22,969:INFO:Checking exceptions
2023-06-14 12:45:22,969:INFO:Importing libraries
2023-06-14 12:45:22,969:INFO:Copying training dataset
2023-06-14 12:45:22,975:INFO:Defining folds
2023-06-14 12:45:22,975:INFO:Declaring metric variables
2023-06-14 12:45:22,975:INFO:Importing untrained model
2023-06-14 12:45:22,975:INFO:Elastic Net Imported successfully
2023-06-14 12:45:22,975:INFO:Starting cross validation
2023-06-14 12:45:22,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:25,452:INFO:Calculating mean and std
2023-06-14 12:45:25,453:INFO:Creating metrics dataframe
2023-06-14 12:45:25,778:INFO:Uploading results into container
2023-06-14 12:45:25,779:INFO:Uploading model into container now
2023-06-14 12:45:25,779:INFO:_master_model_container: 4
2023-06-14 12:45:25,779:INFO:_display_container: 2
2023-06-14 12:45:25,780:INFO:ElasticNet(random_state=8186)
2023-06-14 12:45:25,780:INFO:create_model() successfully completed......................................
2023-06-14 12:45:25,837:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:25,838:INFO:Creating metrics dataframe
2023-06-14 12:45:25,842:INFO:Initializing Least Angle Regression
2023-06-14 12:45:25,843:INFO:Total runtime is 0.2704429348309835 minutes
2023-06-14 12:45:25,843:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:25,843:INFO:Initializing create_model()
2023-06-14 12:45:25,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:25,843:INFO:Checking exceptions
2023-06-14 12:45:25,843:INFO:Importing libraries
2023-06-14 12:45:25,843:INFO:Copying training dataset
2023-06-14 12:45:25,848:INFO:Defining folds
2023-06-14 12:45:25,848:INFO:Declaring metric variables
2023-06-14 12:45:25,848:INFO:Importing untrained model
2023-06-14 12:45:25,848:INFO:Least Angle Regression Imported successfully
2023-06-14 12:45:25,849:INFO:Starting cross validation
2023-06-14 12:45:25,850:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:25,996:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.481e-01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:25,998:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=4.288e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,003:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=4.324e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,005:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=4.220e-01, with an active set of 83 regressors, and the smallest cholesky pivot element being 6.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,005:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=4.185e-01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,007:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=4.154e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,008:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=4.135e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 6.474e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,008:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=4.126e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,009:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=4.156e-01, with an active set of 87 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,010:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.740e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,012:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=4.067e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,013:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=4.053e-01, with an active set of 93 regressors, and the smallest cholesky pivot element being 5.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,014:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=3.961e-01, with an active set of 94 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,016:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.612e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,018:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=3.921e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,022:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=4.040e-01, with an active set of 105 regressors, and the smallest cholesky pivot element being 7.911e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,023:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=3.915e-01, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,023:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=3.915e-01, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,027:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=4.089e-01, with an active set of 109 regressors, and the smallest cholesky pivot element being 6.929e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,027:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=9.425e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.385e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,028:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.293e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,029:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=9.022e-01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,031:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.525e-01, with an active set of 64 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,036:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.173e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,039:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=5.600e-01, with an active set of 56 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,041:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.268e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,041:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=8.332e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,041:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=5.544e-01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,046:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.764e-01, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,050:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=4.458e-01, with an active set of 76 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,050:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=4.458e-01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,050:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=8.405e-01, with an active set of 99 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,051:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=9.001e-01, with an active set of 58 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,052:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=8.119e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,053:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=8.676e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,055:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=9.043e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,057:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=8.967e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,060:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.453e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,060:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=5.492e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,068:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=9.629e-01, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,069:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.218e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,074:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=6.773e-01, with an active set of 64 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=6.643e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.310e+00, with an active set of 107 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,079:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.430e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,080:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.310e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,084:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.572e-01, with an active set of 63 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,085:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.572e-01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,085:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=5.664e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,090:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=5.278e-01, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,091:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.093e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,098:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=6.851e-01, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,100:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=4.122e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,102:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=6.844e-01, with an active set of 107 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,102:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.352e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,105:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.518e+00, with an active set of 86 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,105:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=6.876e-01, with an active set of 110 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,106:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.518e+00, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,108:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.643e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,109:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.612e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,109:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.582e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,110:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.568e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,110:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.564e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,111:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.561e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,111:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.558e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,111:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.467e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,111:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.462e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,113:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.432e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,114:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.424e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,114:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.399e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,115:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.389e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,115:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.375e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,115:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.356e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 5.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,116:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.348e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,117:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.346e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,117:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.341e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.029e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,117:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.533e+00, with an active set of 103 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,117:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.330e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,117:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.502e+00, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,118:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.533e+00, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,118:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.314e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,118:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.313e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.306e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.298e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.298e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.294e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.292e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 6.189e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.287e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=3.473e+00, with an active set of 109 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,121:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.276e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,121:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.267e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.998e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,122:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.266e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,122:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.262e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.098e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,123:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.259e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,123:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.257e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,123:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=3.470e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,123:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.254e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,124:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.253e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,124:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.250e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,125:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.247e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,125:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.243e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,125:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.240e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,126:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.234e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,126:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=8.668e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,126:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.220e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,126:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=8.667e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,126:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.219e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,126:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=8.660e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,127:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.212e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,127:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.205e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,127:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=8.262e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,127:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=8.091e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,127:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.205e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,128:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.767e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,128:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.203e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,128:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.658e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,128:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.196e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,129:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.539e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,129:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.185e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,129:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.427e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,129:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.403e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,129:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.388e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,130:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.310e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,130:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.164e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,130:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.169e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,131:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.160e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,131:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.126e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,131:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.159e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,131:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.056e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,131:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.156e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,132:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.945e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.819e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,132:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.140e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,132:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.896e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,132:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.884e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.585e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,133:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.844e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,133:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.126e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,133:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.843e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,133:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.121e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 8.396e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,133:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.789e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,134:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.117e+00, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,134:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.730e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.312e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,134:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.713e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.622e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,135:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.661e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.706e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,135:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.651e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.086e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,135:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.540e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,135:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.134e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,136:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.515e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,136:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.104e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,136:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.509e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.366e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,136:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.103e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.536e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,137:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.507e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.485e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,137:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.096e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,137:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.497e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,138:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.085e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,138:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.355e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,138:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=8.236e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,138:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.052e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,138:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.350e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,138:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=8.236e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,138:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.279e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,139:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.048e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,139:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.709e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,139:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.265e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,139:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.040e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,139:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.236e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,139:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.030e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,139:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.647e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,140:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.072e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,140:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.569e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,140:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.886e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,140:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.489e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,141:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.843e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,141:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.411e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,141:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.005e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,141:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.704e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,141:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.225e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,141:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.002e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,142:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.695e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,142:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.001e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,142:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.199e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,142:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.688e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,142:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.978e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,142:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.674e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,143:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.856e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,143:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.603e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,143:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.790e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,143:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.576e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,143:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.764e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,143:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.481e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,144:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.761e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,144:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.759e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,144:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.710e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,144:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.464e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,144:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.708e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,144:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.450e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,144:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.375e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,145:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.404e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,145:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=7.238e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.622e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,145:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.692e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,145:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.673e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,146:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.383e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,146:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.373e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,146:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.576e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,146:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.326e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,147:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.559e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.608e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,147:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.435e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,147:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.356e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,147:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.292e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,148:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.321e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,148:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.212e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.121e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,148:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.303e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,149:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.210e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,149:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.297e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,149:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.205e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,149:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.291e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,149:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.165e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,149:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.255e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,150:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.149e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,150:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.243e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,150:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.019e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,150:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.963e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,150:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.079e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,151:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.811e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,151:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=5.048e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,151:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.986e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,152:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.972e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,152:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.757e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,152:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.961e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,152:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.748e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,153:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.912e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,153:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.693e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,153:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.886e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,153:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.645e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,153:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.727e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.549e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.723e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.511e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.704e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.494e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.682e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.412e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.606e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,155:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.298e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,155:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.599e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,155:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.268e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,155:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.596e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.247e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,155:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.180e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,156:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.574e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,156:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.114e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,156:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.038e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,156:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.483e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,156:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.026e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,156:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.472e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,157:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.447e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,157:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.962e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,157:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.422e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,157:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.943e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,158:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.408e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,158:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.937e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,158:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.390e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,158:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.905e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,159:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.273e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.928e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,159:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.881e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,159:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.246e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,160:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.197e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.435e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,160:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.189e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,161:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.082e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.591e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,161:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.855e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,161:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.849e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,161:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.077e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,162:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.835e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,162:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.029e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,162:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.818e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,162:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.028e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.255e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,163:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.800e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,163:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.027e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,163:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.530e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.608e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,163:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=4.004e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,163:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.529e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,164:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=3.964e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,164:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.518e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,164:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=3.959e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,164:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.480e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,165:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=3.952e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,165:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.469e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,165:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=3.935e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,165:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.362e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,165:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.325e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,166:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.325e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.638e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,166:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.930e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.274e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.930e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.222e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.020e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.013e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.890e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.047e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,169:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.842e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.844e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,169:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.829e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,168:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.000e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.949e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,169:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.729e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,170:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.983e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,170:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.660e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.183e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,171:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.877e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,171:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.659e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.660e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,171:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.876e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.006e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,171:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.861e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,172:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.657e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,172:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.852e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.800e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,172:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.640e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,172:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.842e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,172:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.612e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,172:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.835e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,173:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.547e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,173:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.809e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,173:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.535e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,173:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.801e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.369e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,173:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.533e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,173:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.431e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,174:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.509e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.098e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,174:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.493e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.737e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,174:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.429e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.903e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,174:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.469e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.558e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,174:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.377e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,175:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.461e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,175:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.280e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,175:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.444e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.385e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,175:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.254e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,175:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.440e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.321e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,176:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.222e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 8.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,176:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.388e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,176:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.220e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,176:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.388e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,176:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.219e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,176:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.318e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.187e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.280e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.162e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.153e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.091e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.039e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.501e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,179:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.984e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,179:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.965e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,179:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.906e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.590e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.890e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.860e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.854e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,181:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.815e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,181:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.783e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,181:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.750e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.747e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.681e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.610e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.602e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.541e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.534e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.501e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.468e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.448e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.442e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.400e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.319e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.301e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.283e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.140e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.102e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.055e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.958e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,189:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.957e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.787e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,189:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.938e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,189:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.852e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,190:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.831e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,190:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.730e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,190:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.653e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.639e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.627e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.569e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.545e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,193:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.486e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,193:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.460e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.451e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.434e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.426e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.405e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.396e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.381e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.257e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,197:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.205e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,197:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.181e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,197:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.108e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.103e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.090e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.954e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.952e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.940e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.931e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,201:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.925e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,201:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.878e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.868e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.861e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.809e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,203:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.798e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.761e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.736e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.650e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.506e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.998e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.440e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,207:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.437e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,207:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.397e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.380e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.348e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.330e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.314e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.300e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.244e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.914e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.244e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.226e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.129e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.074e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.032e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.013e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.188e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.905e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.006e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.895e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.771e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.714e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.691e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.640e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.611e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.819e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.550e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.094e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.548e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.499e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.806e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.441e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.403e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.343e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.328e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.174e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.150e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.149e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.143e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.114e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.099e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.078e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.204e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.048e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,223:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.018e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,223:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.980e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,224:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.949e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,224:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.949e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 8.737e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,225:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.881e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,225:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.881e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,226:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.842e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.207e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,226:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.779e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,227:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.718e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,227:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.680e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.655e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.652e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.763e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.641e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.633e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.553e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.491e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.763e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.480e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.188e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.174e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,231:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.120e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,231:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.105e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.085e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.781e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.741e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.406e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.260e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.250e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.979e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.733e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.564e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.449e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.860e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.552e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.466e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.235e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.715e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.663e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.282e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=5.079e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.904e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.775e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,239:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.775e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,239:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.701e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,239:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.579e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.446e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.225e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.278e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.929e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.815e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.766e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.985e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,242:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.918e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,242:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.887e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,243:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.869e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,243:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.848e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,244:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.782e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 6.949e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,244:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.731e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,244:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.667e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,245:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.627e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,245:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.548e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,245:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.538e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,246:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.510e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,246:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.463e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,246:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.357e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,247:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.355e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,247:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.332e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,247:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.301e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,247:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.286e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,248:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.217e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,248:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.057e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,250:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.050e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.723e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,250:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.031e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.010e-02, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.424e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,252:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.252e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.936e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,252:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.075e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.753e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.337e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,254:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.200e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,254:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=8.127e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,254:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.363e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,255:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=6.264e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,255:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.183e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.610e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=3.427e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.919e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.665e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.575e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.414e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.193e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,257:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.175e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,259:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.174e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,259:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.143e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,259:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.137e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,260:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.056e-03, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,260:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.983e-04, with an active set of 126 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,260:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.829e-04, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,261:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=7.948e-04, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,261:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.917e-04, with an active set of 126 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,261:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.565e-04, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:26,262:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=2.655e-04, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,301:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:45:27,582:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=6.657e-01, with an active set of 48 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,591:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.770e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,593:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.746e-01, with an active set of 68 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,602:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=4.350e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,607:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=4.693e-01, with an active set of 89 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,621:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=6.523e-01, with an active set of 111 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,624:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=6.649e-01, with an active set of 115 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,636:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=1.467e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.189e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,637:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.403e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,638:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.367e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,638:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.340e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,639:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.317e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,641:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.227e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,641:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.216e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,641:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.175e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,642:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.165e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,962:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.847e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,972:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.049e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,980:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=6.624e-01, with an active set of 69 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,980:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=6.462e-01, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,980:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=6.462e-01, with an active set of 69 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,989:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=5.908e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,991:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=9.202e-01, with an active set of 108 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,991:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=9.202e-01, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:27,995:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=1.014e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:29,501:INFO:Calculating mean and std
2023-06-14 12:45:29,502:INFO:Creating metrics dataframe
2023-06-14 12:45:30,293:INFO:Uploading results into container
2023-06-14 12:45:30,293:INFO:Uploading model into container now
2023-06-14 12:45:30,293:INFO:_master_model_container: 5
2023-06-14 12:45:30,293:INFO:_display_container: 2
2023-06-14 12:45:30,293:INFO:Lars(random_state=8186)
2023-06-14 12:45:30,293:INFO:create_model() successfully completed......................................
2023-06-14 12:45:30,355:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:30,355:INFO:Creating metrics dataframe
2023-06-14 12:45:30,359:INFO:Initializing Lasso Least Angle Regression
2023-06-14 12:45:30,359:INFO:Total runtime is 0.34570960998535155 minutes
2023-06-14 12:45:30,359:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:30,359:INFO:Initializing create_model()
2023-06-14 12:45:30,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:30,359:INFO:Checking exceptions
2023-06-14 12:45:30,359:INFO:Importing libraries
2023-06-14 12:45:30,360:INFO:Copying training dataset
2023-06-14 12:45:30,365:INFO:Defining folds
2023-06-14 12:45:30,365:INFO:Declaring metric variables
2023-06-14 12:45:30,365:INFO:Importing untrained model
2023-06-14 12:45:30,365:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 12:45:30,365:INFO:Starting cross validation
2023-06-14 12:45:30,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:30,500:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.740e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:30,507:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.439e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:30,509:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:678: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 40 iterations, alpha=1.149e+00, previous alpha=1.110e+00, with an active set of 37 regressors.
  warnings.warn(

2023-06-14 12:45:30,524:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.049e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:30,529:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.612e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:30,576:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.268e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:30,585:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.453e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:30,593:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.218e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:31,275:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.847e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:45:32,921:INFO:Calculating mean and std
2023-06-14 12:45:32,922:INFO:Creating metrics dataframe
2023-06-14 12:45:33,244:INFO:Uploading results into container
2023-06-14 12:45:33,245:INFO:Uploading model into container now
2023-06-14 12:45:33,245:INFO:_master_model_container: 6
2023-06-14 12:45:33,245:INFO:_display_container: 2
2023-06-14 12:45:33,245:INFO:LassoLars(random_state=8186)
2023-06-14 12:45:33,245:INFO:create_model() successfully completed......................................
2023-06-14 12:45:33,303:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:33,303:INFO:Creating metrics dataframe
2023-06-14 12:45:33,307:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 12:45:33,307:INFO:Total runtime is 0.3948549389839172 minutes
2023-06-14 12:45:33,307:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:33,307:INFO:Initializing create_model()
2023-06-14 12:45:33,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:33,307:INFO:Checking exceptions
2023-06-14 12:45:33,307:INFO:Importing libraries
2023-06-14 12:45:33,307:INFO:Copying training dataset
2023-06-14 12:45:33,313:INFO:Defining folds
2023-06-14 12:45:33,313:INFO:Declaring metric variables
2023-06-14 12:45:33,313:INFO:Importing untrained model
2023-06-14 12:45:33,313:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 12:45:33,313:INFO:Starting cross validation
2023-06-14 12:45:33,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:35,847:INFO:Calculating mean and std
2023-06-14 12:45:35,847:INFO:Creating metrics dataframe
2023-06-14 12:45:36,176:INFO:Uploading results into container
2023-06-14 12:45:36,176:INFO:Uploading model into container now
2023-06-14 12:45:36,177:INFO:_master_model_container: 7
2023-06-14 12:45:36,177:INFO:_display_container: 2
2023-06-14 12:45:36,177:INFO:OrthogonalMatchingPursuit()
2023-06-14 12:45:36,177:INFO:create_model() successfully completed......................................
2023-06-14 12:45:36,235:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:36,235:INFO:Creating metrics dataframe
2023-06-14 12:45:36,239:INFO:Initializing Bayesian Ridge
2023-06-14 12:45:36,240:INFO:Total runtime is 0.44373872280120846 minutes
2023-06-14 12:45:36,240:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:36,240:INFO:Initializing create_model()
2023-06-14 12:45:36,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:36,240:INFO:Checking exceptions
2023-06-14 12:45:36,240:INFO:Importing libraries
2023-06-14 12:45:36,240:INFO:Copying training dataset
2023-06-14 12:45:36,245:INFO:Defining folds
2023-06-14 12:45:36,245:INFO:Declaring metric variables
2023-06-14 12:45:36,246:INFO:Importing untrained model
2023-06-14 12:45:36,246:INFO:Bayesian Ridge Imported successfully
2023-06-14 12:45:36,246:INFO:Starting cross validation
2023-06-14 12:45:36,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:38,810:INFO:Calculating mean and std
2023-06-14 12:45:38,810:INFO:Creating metrics dataframe
2023-06-14 12:45:39,135:INFO:Uploading results into container
2023-06-14 12:45:39,135:INFO:Uploading model into container now
2023-06-14 12:45:39,136:INFO:_master_model_container: 8
2023-06-14 12:45:39,136:INFO:_display_container: 2
2023-06-14 12:45:39,136:INFO:BayesianRidge()
2023-06-14 12:45:39,136:INFO:create_model() successfully completed......................................
2023-06-14 12:45:39,196:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:39,196:INFO:Creating metrics dataframe
2023-06-14 12:45:39,200:INFO:Initializing Passive Aggressive Regressor
2023-06-14 12:45:39,200:INFO:Total runtime is 0.4930718819300333 minutes
2023-06-14 12:45:39,200:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:39,200:INFO:Initializing create_model()
2023-06-14 12:45:39,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:39,200:INFO:Checking exceptions
2023-06-14 12:45:39,201:INFO:Importing libraries
2023-06-14 12:45:39,201:INFO:Copying training dataset
2023-06-14 12:45:39,206:INFO:Defining folds
2023-06-14 12:45:39,207:INFO:Declaring metric variables
2023-06-14 12:45:39,207:INFO:Importing untrained model
2023-06-14 12:45:39,207:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 12:45:39,208:INFO:Starting cross validation
2023-06-14 12:45:39,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:41,821:INFO:Calculating mean and std
2023-06-14 12:45:41,822:INFO:Creating metrics dataframe
2023-06-14 12:45:42,163:INFO:Uploading results into container
2023-06-14 12:45:42,163:INFO:Uploading model into container now
2023-06-14 12:45:42,163:INFO:_master_model_container: 9
2023-06-14 12:45:42,164:INFO:_display_container: 2
2023-06-14 12:45:42,164:INFO:PassiveAggressiveRegressor(random_state=8186)
2023-06-14 12:45:42,164:INFO:create_model() successfully completed......................................
2023-06-14 12:45:42,225:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:42,225:INFO:Creating metrics dataframe
2023-06-14 12:45:42,230:INFO:Initializing Huber Regressor
2023-06-14 12:45:42,230:INFO:Total runtime is 0.543563707669576 minutes
2023-06-14 12:45:42,231:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:42,231:INFO:Initializing create_model()
2023-06-14 12:45:42,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:42,231:INFO:Checking exceptions
2023-06-14 12:45:42,231:INFO:Importing libraries
2023-06-14 12:45:42,231:INFO:Copying training dataset
2023-06-14 12:45:42,236:INFO:Defining folds
2023-06-14 12:45:42,236:INFO:Declaring metric variables
2023-06-14 12:45:42,236:INFO:Importing untrained model
2023-06-14 12:45:42,236:INFO:Huber Regressor Imported successfully
2023-06-14 12:45:42,236:INFO:Starting cross validation
2023-06-14 12:45:42,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:42,510:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:45:42,533:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:45:42,578:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:45:42,583:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:45:42,589:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:45:43,283:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:45:43,640:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:45:45,192:INFO:Calculating mean and std
2023-06-14 12:45:45,192:INFO:Creating metrics dataframe
2023-06-14 12:45:45,521:INFO:Uploading results into container
2023-06-14 12:45:45,521:INFO:Uploading model into container now
2023-06-14 12:45:45,521:INFO:_master_model_container: 10
2023-06-14 12:45:45,522:INFO:_display_container: 2
2023-06-14 12:45:45,522:INFO:HuberRegressor()
2023-06-14 12:45:45,522:INFO:create_model() successfully completed......................................
2023-06-14 12:45:45,580:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:45,582:INFO:Creating metrics dataframe
2023-06-14 12:45:45,586:INFO:Initializing K Neighbors Regressor
2023-06-14 12:45:45,586:INFO:Total runtime is 0.5994952400525411 minutes
2023-06-14 12:45:45,586:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:45,587:INFO:Initializing create_model()
2023-06-14 12:45:45,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:45,587:INFO:Checking exceptions
2023-06-14 12:45:45,587:INFO:Importing libraries
2023-06-14 12:45:45,587:INFO:Copying training dataset
2023-06-14 12:45:45,591:INFO:Defining folds
2023-06-14 12:45:45,591:INFO:Declaring metric variables
2023-06-14 12:45:45,591:INFO:Importing untrained model
2023-06-14 12:45:45,591:INFO:K Neighbors Regressor Imported successfully
2023-06-14 12:45:45,592:INFO:Starting cross validation
2023-06-14 12:45:45,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:48,370:INFO:Calculating mean and std
2023-06-14 12:45:48,370:INFO:Creating metrics dataframe
2023-06-14 12:45:48,688:INFO:Uploading results into container
2023-06-14 12:45:48,690:INFO:Uploading model into container now
2023-06-14 12:45:48,690:INFO:_master_model_container: 11
2023-06-14 12:45:48,691:INFO:_display_container: 2
2023-06-14 12:45:48,691:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 12:45:48,691:INFO:create_model() successfully completed......................................
2023-06-14 12:45:48,753:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:48,753:INFO:Creating metrics dataframe
2023-06-14 12:45:48,757:INFO:Initializing Decision Tree Regressor
2023-06-14 12:45:48,757:INFO:Total runtime is 0.6523530562718709 minutes
2023-06-14 12:45:48,757:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:48,757:INFO:Initializing create_model()
2023-06-14 12:45:48,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:48,759:INFO:Checking exceptions
2023-06-14 12:45:48,759:INFO:Importing libraries
2023-06-14 12:45:48,759:INFO:Copying training dataset
2023-06-14 12:45:48,764:INFO:Defining folds
2023-06-14 12:45:48,764:INFO:Declaring metric variables
2023-06-14 12:45:48,764:INFO:Importing untrained model
2023-06-14 12:45:48,764:INFO:Decision Tree Regressor Imported successfully
2023-06-14 12:45:48,764:INFO:Starting cross validation
2023-06-14 12:45:48,766:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:51,340:INFO:Calculating mean and std
2023-06-14 12:45:51,340:INFO:Creating metrics dataframe
2023-06-14 12:45:51,672:INFO:Uploading results into container
2023-06-14 12:45:51,673:INFO:Uploading model into container now
2023-06-14 12:45:51,673:INFO:_master_model_container: 12
2023-06-14 12:45:51,674:INFO:_display_container: 2
2023-06-14 12:45:51,674:INFO:DecisionTreeRegressor(random_state=8186)
2023-06-14 12:45:51,674:INFO:create_model() successfully completed......................................
2023-06-14 12:45:51,732:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:51,732:INFO:Creating metrics dataframe
2023-06-14 12:45:51,737:INFO:Initializing Random Forest Regressor
2023-06-14 12:45:51,737:INFO:Total runtime is 0.7020164370536804 minutes
2023-06-14 12:45:51,737:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:51,737:INFO:Initializing create_model()
2023-06-14 12:45:51,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:51,737:INFO:Checking exceptions
2023-06-14 12:45:51,737:INFO:Importing libraries
2023-06-14 12:45:51,737:INFO:Copying training dataset
2023-06-14 12:45:51,743:INFO:Defining folds
2023-06-14 12:45:51,743:INFO:Declaring metric variables
2023-06-14 12:45:51,743:INFO:Importing untrained model
2023-06-14 12:45:51,743:INFO:Random Forest Regressor Imported successfully
2023-06-14 12:45:51,744:INFO:Starting cross validation
2023-06-14 12:45:51,745:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:53,072:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:45:55,843:INFO:Calculating mean and std
2023-06-14 12:45:55,844:INFO:Creating metrics dataframe
2023-06-14 12:45:56,184:INFO:Uploading results into container
2023-06-14 12:45:56,184:INFO:Uploading model into container now
2023-06-14 12:45:56,184:INFO:_master_model_container: 13
2023-06-14 12:45:56,185:INFO:_display_container: 2
2023-06-14 12:45:56,185:INFO:RandomForestRegressor(n_jobs=-1, random_state=8186)
2023-06-14 12:45:56,185:INFO:create_model() successfully completed......................................
2023-06-14 12:45:56,246:INFO:SubProcess create_model() end ==================================
2023-06-14 12:45:56,246:INFO:Creating metrics dataframe
2023-06-14 12:45:56,251:INFO:Initializing Extra Trees Regressor
2023-06-14 12:45:56,251:INFO:Total runtime is 0.777249276638031 minutes
2023-06-14 12:45:56,251:INFO:SubProcess create_model() called ==================================
2023-06-14 12:45:56,251:INFO:Initializing create_model()
2023-06-14 12:45:56,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:45:56,252:INFO:Checking exceptions
2023-06-14 12:45:56,252:INFO:Importing libraries
2023-06-14 12:45:56,252:INFO:Copying training dataset
2023-06-14 12:45:56,255:INFO:Defining folds
2023-06-14 12:45:56,255:INFO:Declaring metric variables
2023-06-14 12:45:56,256:INFO:Importing untrained model
2023-06-14 12:45:56,256:INFO:Extra Trees Regressor Imported successfully
2023-06-14 12:45:56,256:INFO:Starting cross validation
2023-06-14 12:45:56,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:45:57,487:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:46:00,317:INFO:Calculating mean and std
2023-06-14 12:46:00,317:INFO:Creating metrics dataframe
2023-06-14 12:46:00,655:INFO:Uploading results into container
2023-06-14 12:46:00,655:INFO:Uploading model into container now
2023-06-14 12:46:00,656:INFO:_master_model_container: 14
2023-06-14 12:46:00,656:INFO:_display_container: 2
2023-06-14 12:46:00,656:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8186)
2023-06-14 12:46:00,656:INFO:create_model() successfully completed......................................
2023-06-14 12:46:00,715:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:00,715:INFO:Creating metrics dataframe
2023-06-14 12:46:00,719:INFO:Initializing AdaBoost Regressor
2023-06-14 12:46:00,719:INFO:Total runtime is 0.8517187158266704 minutes
2023-06-14 12:46:00,719:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:00,719:INFO:Initializing create_model()
2023-06-14 12:46:00,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:00,719:INFO:Checking exceptions
2023-06-14 12:46:00,720:INFO:Importing libraries
2023-06-14 12:46:00,720:INFO:Copying training dataset
2023-06-14 12:46:00,725:INFO:Defining folds
2023-06-14 12:46:00,725:INFO:Declaring metric variables
2023-06-14 12:46:00,725:INFO:Importing untrained model
2023-06-14 12:46:00,726:INFO:AdaBoost Regressor Imported successfully
2023-06-14 12:46:00,726:INFO:Starting cross validation
2023-06-14 12:46:00,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:04,104:INFO:Calculating mean and std
2023-06-14 12:46:04,105:INFO:Creating metrics dataframe
2023-06-14 12:46:04,478:INFO:Uploading results into container
2023-06-14 12:46:04,480:INFO:Uploading model into container now
2023-06-14 12:46:04,480:INFO:_master_model_container: 15
2023-06-14 12:46:04,481:INFO:_display_container: 2
2023-06-14 12:46:04,481:INFO:AdaBoostRegressor(random_state=8186)
2023-06-14 12:46:04,481:INFO:create_model() successfully completed......................................
2023-06-14 12:46:04,538:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:04,538:INFO:Creating metrics dataframe
2023-06-14 12:46:04,544:INFO:Initializing Gradient Boosting Regressor
2023-06-14 12:46:04,544:INFO:Total runtime is 0.915462855497996 minutes
2023-06-14 12:46:04,544:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:04,544:INFO:Initializing create_model()
2023-06-14 12:46:04,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:04,544:INFO:Checking exceptions
2023-06-14 12:46:04,545:INFO:Importing libraries
2023-06-14 12:46:04,545:INFO:Copying training dataset
2023-06-14 12:46:04,549:INFO:Defining folds
2023-06-14 12:46:04,549:INFO:Declaring metric variables
2023-06-14 12:46:04,550:INFO:Importing untrained model
2023-06-14 12:46:04,550:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 12:46:04,550:INFO:Starting cross validation
2023-06-14 12:46:04,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:08,170:INFO:Calculating mean and std
2023-06-14 12:46:08,171:INFO:Creating metrics dataframe
2023-06-14 12:46:08,523:INFO:Uploading results into container
2023-06-14 12:46:08,524:INFO:Uploading model into container now
2023-06-14 12:46:08,524:INFO:_master_model_container: 16
2023-06-14 12:46:08,524:INFO:_display_container: 2
2023-06-14 12:46:08,524:INFO:GradientBoostingRegressor(random_state=8186)
2023-06-14 12:46:08,524:INFO:create_model() successfully completed......................................
2023-06-14 12:46:08,582:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:08,583:INFO:Creating metrics dataframe
2023-06-14 12:46:08,587:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 12:46:08,587:INFO:Total runtime is 0.9828527847925822 minutes
2023-06-14 12:46:08,587:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:08,587:INFO:Initializing create_model()
2023-06-14 12:46:08,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:08,587:INFO:Checking exceptions
2023-06-14 12:46:08,587:INFO:Importing libraries
2023-06-14 12:46:08,587:INFO:Copying training dataset
2023-06-14 12:46:08,592:INFO:Defining folds
2023-06-14 12:46:08,592:INFO:Declaring metric variables
2023-06-14 12:46:08,592:INFO:Importing untrained model
2023-06-14 12:46:08,592:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 12:46:08,593:INFO:Starting cross validation
2023-06-14 12:46:08,594:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:11,319:INFO:Calculating mean and std
2023-06-14 12:46:11,320:INFO:Creating metrics dataframe
2023-06-14 12:46:11,664:INFO:Uploading results into container
2023-06-14 12:46:11,665:INFO:Uploading model into container now
2023-06-14 12:46:11,665:INFO:_master_model_container: 17
2023-06-14 12:46:11,666:INFO:_display_container: 2
2023-06-14 12:46:11,666:INFO:LGBMRegressor(random_state=8186)
2023-06-14 12:46:11,666:INFO:create_model() successfully completed......................................
2023-06-14 12:46:11,726:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:11,726:INFO:Creating metrics dataframe
2023-06-14 12:46:11,730:INFO:Initializing Dummy Regressor
2023-06-14 12:46:11,730:INFO:Total runtime is 1.0352391719818115 minutes
2023-06-14 12:46:11,730:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:11,730:INFO:Initializing create_model()
2023-06-14 12:46:11,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CDFCC12F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:11,731:INFO:Checking exceptions
2023-06-14 12:46:11,731:INFO:Importing libraries
2023-06-14 12:46:11,731:INFO:Copying training dataset
2023-06-14 12:46:11,736:INFO:Defining folds
2023-06-14 12:46:11,736:INFO:Declaring metric variables
2023-06-14 12:46:11,736:INFO:Importing untrained model
2023-06-14 12:46:11,737:INFO:Dummy Regressor Imported successfully
2023-06-14 12:46:11,737:INFO:Starting cross validation
2023-06-14 12:46:11,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:14,371:INFO:Calculating mean and std
2023-06-14 12:46:14,372:INFO:Creating metrics dataframe
2023-06-14 12:46:14,722:INFO:Uploading results into container
2023-06-14 12:46:14,723:INFO:Uploading model into container now
2023-06-14 12:46:14,723:INFO:_master_model_container: 18
2023-06-14 12:46:14,723:INFO:_display_container: 2
2023-06-14 12:46:14,723:INFO:DummyRegressor()
2023-06-14 12:46:14,723:INFO:create_model() successfully completed......................................
2023-06-14 12:46:14,783:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:14,783:INFO:Creating metrics dataframe
2023-06-14 12:46:14,789:INFO:Initializing create_model()
2023-06-14 12:46:14,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CDFC92E9B0>, estimator=AdaBoostRegressor(random_state=8186), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:14,789:INFO:Checking exceptions
2023-06-14 12:46:14,790:INFO:Importing libraries
2023-06-14 12:46:14,790:INFO:Copying training dataset
2023-06-14 12:46:14,794:INFO:Defining folds
2023-06-14 12:46:14,795:INFO:Declaring metric variables
2023-06-14 12:46:14,795:INFO:Importing untrained model
2023-06-14 12:46:14,795:INFO:Declaring custom model
2023-06-14 12:46:14,796:INFO:AdaBoost Regressor Imported successfully
2023-06-14 12:46:14,797:INFO:Cross validation set to False
2023-06-14 12:46:14,797:INFO:Fitting Model
2023-06-14 12:46:15,417:INFO:AdaBoostRegressor(random_state=8186)
2023-06-14 12:46:15,417:INFO:create_model() successfully completed......................................
2023-06-14 12:46:15,490:INFO:_master_model_container: 18
2023-06-14 12:46:15,490:INFO:_display_container: 2
2023-06-14 12:46:15,490:INFO:AdaBoostRegressor(random_state=8186)
2023-06-14 12:46:15,491:INFO:compare_models() successfully completed......................................
2023-06-14 12:46:23,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:46:23,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:46:23,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:46:23,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:46:23,660:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:46:24,403:INFO:PyCaret RegressionExperiment
2023-06-14 12:46:24,405:INFO:Logging name: reg-default-name
2023-06-14 12:46:24,405:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 12:46:24,405:INFO:version 3.0.2
2023-06-14 12:46:24,405:INFO:Initializing setup()
2023-06-14 12:46:24,405:INFO:self.USI: 9ad5
2023-06-14 12:46:24,405:INFO:self._variable_keys: {'y_train', 'exp_name_log', '_available_plots', 'seed', 'fold_shuffle_param', 'fold_generator', 'X_train', 'data', 'pipeline', 'gpu_param', 'logging_param', 'log_plots_param', 'gpu_n_jobs_param', 'exp_id', 'fold_groups_param', 'X_test', 'memory', 'html_param', 'transform_target_param', 'target_param', 'X', 'y', '_ml_usecase', 'n_jobs_param', 'idx', 'y_test', 'USI'}
2023-06-14 12:46:24,405:INFO:Checking environment
2023-06-14 12:46:24,405:INFO:python_version: 3.10.11
2023-06-14 12:46:24,405:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-06-14 12:46:24,405:INFO:machine: AMD64
2023-06-14 12:46:24,417:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 12:46:24,421:INFO:Memory: svmem(total=17013329920, available=3462438912, percent=79.6, used=13550891008, free=3462438912)
2023-06-14 12:46:24,422:INFO:Physical Core: 4
2023-06-14 12:46:24,422:INFO:Logical Core: 8
2023-06-14 12:46:24,422:INFO:Checking libraries
2023-06-14 12:46:24,422:INFO:System:
2023-06-14 12:46:24,422:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-06-14 12:46:24,422:INFO:executable: E:\Machine learning\mini\adam\Scripts\python.exe
2023-06-14 12:46:24,422:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 12:46:24,422:INFO:PyCaret required dependencies:
2023-06-14 12:46:24,422:INFO:                 pip: 23.0.1
2023-06-14 12:46:24,422:INFO:          setuptools: 65.5.0
2023-06-14 12:46:24,422:INFO:             pycaret: 3.0.2
2023-06-14 12:46:24,422:INFO:             IPython: 8.14.0
2023-06-14 12:46:24,422:INFO:          ipywidgets: 8.0.6
2023-06-14 12:46:24,422:INFO:                tqdm: 4.65.0
2023-06-14 12:46:24,422:INFO:               numpy: 1.23.5
2023-06-14 12:46:24,422:INFO:              pandas: 1.5.3
2023-06-14 12:46:24,422:INFO:              jinja2: 3.1.2
2023-06-14 12:46:24,422:INFO:               scipy: 1.10.1
2023-06-14 12:46:24,423:INFO:              joblib: 1.2.0
2023-06-14 12:46:24,423:INFO:             sklearn: 1.2.2
2023-06-14 12:46:24,423:INFO:                pyod: 1.0.9
2023-06-14 12:46:24,423:INFO:            imblearn: 0.10.1
2023-06-14 12:46:24,423:INFO:   category_encoders: 2.6.1
2023-06-14 12:46:24,423:INFO:            lightgbm: 3.3.5
2023-06-14 12:46:24,423:INFO:               numba: 0.57.0
2023-06-14 12:46:24,423:INFO:            requests: 2.31.0
2023-06-14 12:46:24,423:INFO:          matplotlib: 3.7.1
2023-06-14 12:46:24,423:INFO:          scikitplot: 0.3.7
2023-06-14 12:46:24,423:INFO:         yellowbrick: 1.5
2023-06-14 12:46:24,423:INFO:              plotly: 5.15.0
2023-06-14 12:46:24,423:INFO:             kaleido: 0.2.1
2023-06-14 12:46:24,423:INFO:         statsmodels: 0.14.0
2023-06-14 12:46:24,423:INFO:              sktime: 0.17.0
2023-06-14 12:46:24,423:INFO:               tbats: 1.1.3
2023-06-14 12:46:24,423:INFO:            pmdarima: 2.0.3
2023-06-14 12:46:24,423:INFO:              psutil: 5.9.5
2023-06-14 12:46:24,423:INFO:PyCaret optional dependencies:
2023-06-14 12:46:24,436:INFO:                shap: Not installed
2023-06-14 12:46:24,436:INFO:           interpret: Not installed
2023-06-14 12:46:24,436:INFO:                umap: Not installed
2023-06-14 12:46:24,436:INFO:    pandas_profiling: Not installed
2023-06-14 12:46:24,436:INFO:  explainerdashboard: Not installed
2023-06-14 12:46:24,436:INFO:             autoviz: Not installed
2023-06-14 12:46:24,436:INFO:           fairlearn: Not installed
2023-06-14 12:46:24,436:INFO:             xgboost: Not installed
2023-06-14 12:46:24,436:INFO:            catboost: Not installed
2023-06-14 12:46:24,436:INFO:              kmodes: Not installed
2023-06-14 12:46:24,436:INFO:             mlxtend: Not installed
2023-06-14 12:46:24,436:INFO:       statsforecast: Not installed
2023-06-14 12:46:24,436:INFO:        tune_sklearn: Not installed
2023-06-14 12:46:24,436:INFO:                 ray: Not installed
2023-06-14 12:46:24,437:INFO:            hyperopt: Not installed
2023-06-14 12:46:24,437:INFO:              optuna: Not installed
2023-06-14 12:46:24,437:INFO:               skopt: Not installed
2023-06-14 12:46:24,437:INFO:              mlflow: Not installed
2023-06-14 12:46:24,437:INFO:              gradio: Not installed
2023-06-14 12:46:24,437:INFO:             fastapi: Not installed
2023-06-14 12:46:24,437:INFO:             uvicorn: Not installed
2023-06-14 12:46:24,437:INFO:              m2cgen: Not installed
2023-06-14 12:46:24,437:INFO:           evidently: Not installed
2023-06-14 12:46:24,437:INFO:               fugue: Not installed
2023-06-14 12:46:24,437:INFO:           streamlit: Not installed
2023-06-14 12:46:24,437:INFO:             prophet: Not installed
2023-06-14 12:46:24,437:INFO:None
2023-06-14 12:46:24,437:INFO:Set up data.
2023-06-14 12:46:24,561:INFO:Set up train/test split.
2023-06-14 12:46:24,568:INFO:Set up index.
2023-06-14 12:46:24,568:INFO:Set up folding strategy.
2023-06-14 12:46:24,569:INFO:Assigning column types.
2023-06-14 12:46:24,573:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 12:46:24,573:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,578:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,583:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,636:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,685:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:24,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:24,707:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,715:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,722:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,785:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,827:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:24,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:24,828:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 12:46:24,833:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,837:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,898:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,939:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,940:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:24,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:24,945:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:46:24,950:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,003:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,043:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 12:46:25,053:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,104:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,144:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,244:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,245:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 12:46:25,304:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,345:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,446:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 12:46:25,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,550:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:46:25,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,661:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 12:46:25,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:25,866:INFO:Preparing preprocessing pipeline...
2023-06-14 12:46:25,866:INFO:Set up simple imputation.
2023-06-14 12:46:25,906:INFO:Finished creating preprocessing pipeline.
2023-06-14 12:46:25,913:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\adamr\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bid_amount', '0', '1', '2', '3',
                                             '4', '5', '6', '7', '8', '9', '10',
                                             '11', '12', '13', '14', '15', '16',
                                             '17', '18', '19', '20', '21', '22',
                                             '23', '24', '25', '26', '27', '28', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-06-14 12:46:25,913:INFO:Creating final display dataframe.
2023-06-14 12:46:26,089:INFO:Setup _display_container:                     Description             Value
0                    Session id              4834
1                        Target    combined_score
2                   Target type        Regression
3           Original data shape        (211, 597)
4        Transformed data shape        (211, 597)
5   Transformed train set shape        (147, 597)
6    Transformed test set shape         (64, 597)
7              Numeric features               596
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              9ad5
2023-06-14 12:46:26,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:26,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:26,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:26,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:46:26,303:INFO:setup() successfully completed in 2.13s...............
2023-06-14 12:46:26,303:INFO:Initializing compare_models()
2023-06-14 12:46:26,303:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 12:46:26,303:INFO:Checking exceptions
2023-06-14 12:46:26,305:INFO:Preparing display monitor
2023-06-14 12:46:26,307:INFO:Initializing Linear Regression
2023-06-14 12:46:26,307:INFO:Total runtime is 0.0 minutes
2023-06-14 12:46:26,308:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:26,308:INFO:Initializing create_model()
2023-06-14 12:46:26,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:26,308:INFO:Checking exceptions
2023-06-14 12:46:26,308:INFO:Importing libraries
2023-06-14 12:46:26,308:INFO:Copying training dataset
2023-06-14 12:46:26,312:INFO:Defining folds
2023-06-14 12:46:26,313:INFO:Declaring metric variables
2023-06-14 12:46:26,313:INFO:Importing untrained model
2023-06-14 12:46:26,313:INFO:Linear Regression Imported successfully
2023-06-14 12:46:26,313:INFO:Starting cross validation
2023-06-14 12:46:26,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:34,533:INFO:Calculating mean and std
2023-06-14 12:46:34,534:INFO:Creating metrics dataframe
2023-06-14 12:46:34,937:INFO:Uploading results into container
2023-06-14 12:46:34,937:INFO:Uploading model into container now
2023-06-14 12:46:34,938:INFO:_master_model_container: 1
2023-06-14 12:46:34,938:INFO:_display_container: 2
2023-06-14 12:46:34,938:INFO:LinearRegression(n_jobs=-1)
2023-06-14 12:46:34,938:INFO:create_model() successfully completed......................................
2023-06-14 12:46:35,001:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:35,001:INFO:Creating metrics dataframe
2023-06-14 12:46:35,005:INFO:Initializing Lasso Regression
2023-06-14 12:46:35,005:INFO:Total runtime is 0.14497814973195394 minutes
2023-06-14 12:46:35,005:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:35,005:INFO:Initializing create_model()
2023-06-14 12:46:35,005:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:35,005:INFO:Checking exceptions
2023-06-14 12:46:35,005:INFO:Importing libraries
2023-06-14 12:46:35,005:INFO:Copying training dataset
2023-06-14 12:46:35,010:INFO:Defining folds
2023-06-14 12:46:35,010:INFO:Declaring metric variables
2023-06-14 12:46:35,010:INFO:Importing untrained model
2023-06-14 12:46:35,011:INFO:Lasso Regression Imported successfully
2023-06-14 12:46:35,011:INFO:Starting cross validation
2023-06-14 12:46:35,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:37,761:INFO:Calculating mean and std
2023-06-14 12:46:37,762:INFO:Creating metrics dataframe
2023-06-14 12:46:38,121:INFO:Uploading results into container
2023-06-14 12:46:38,122:INFO:Uploading model into container now
2023-06-14 12:46:38,122:INFO:_master_model_container: 2
2023-06-14 12:46:38,122:INFO:_display_container: 2
2023-06-14 12:46:38,122:INFO:Lasso(random_state=4834)
2023-06-14 12:46:38,122:INFO:create_model() successfully completed......................................
2023-06-14 12:46:38,178:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:38,178:INFO:Creating metrics dataframe
2023-06-14 12:46:38,184:INFO:Initializing Ridge Regression
2023-06-14 12:46:38,184:INFO:Total runtime is 0.19794785579045615 minutes
2023-06-14 12:46:38,184:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:38,184:INFO:Initializing create_model()
2023-06-14 12:46:38,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:38,184:INFO:Checking exceptions
2023-06-14 12:46:38,185:INFO:Importing libraries
2023-06-14 12:46:38,185:INFO:Copying training dataset
2023-06-14 12:46:38,189:INFO:Defining folds
2023-06-14 12:46:38,189:INFO:Declaring metric variables
2023-06-14 12:46:38,189:INFO:Importing untrained model
2023-06-14 12:46:38,190:INFO:Ridge Regression Imported successfully
2023-06-14 12:46:38,190:INFO:Starting cross validation
2023-06-14 12:46:38,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:41,089:INFO:Calculating mean and std
2023-06-14 12:46:41,090:INFO:Creating metrics dataframe
2023-06-14 12:46:41,439:INFO:Uploading results into container
2023-06-14 12:46:41,440:INFO:Uploading model into container now
2023-06-14 12:46:41,440:INFO:_master_model_container: 3
2023-06-14 12:46:41,440:INFO:_display_container: 2
2023-06-14 12:46:41,441:INFO:Ridge(random_state=4834)
2023-06-14 12:46:41,441:INFO:create_model() successfully completed......................................
2023-06-14 12:46:41,498:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:41,498:INFO:Creating metrics dataframe
2023-06-14 12:46:41,503:INFO:Initializing Elastic Net
2023-06-14 12:46:41,503:INFO:Total runtime is 0.25326553583145145 minutes
2023-06-14 12:46:41,504:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:41,504:INFO:Initializing create_model()
2023-06-14 12:46:41,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:41,504:INFO:Checking exceptions
2023-06-14 12:46:41,504:INFO:Importing libraries
2023-06-14 12:46:41,504:INFO:Copying training dataset
2023-06-14 12:46:41,508:INFO:Defining folds
2023-06-14 12:46:41,508:INFO:Declaring metric variables
2023-06-14 12:46:41,509:INFO:Importing untrained model
2023-06-14 12:46:41,509:INFO:Elastic Net Imported successfully
2023-06-14 12:46:41,509:INFO:Starting cross validation
2023-06-14 12:46:41,511:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:44,225:INFO:Calculating mean and std
2023-06-14 12:46:44,225:INFO:Creating metrics dataframe
2023-06-14 12:46:44,585:INFO:Uploading results into container
2023-06-14 12:46:44,586:INFO:Uploading model into container now
2023-06-14 12:46:44,586:INFO:_master_model_container: 4
2023-06-14 12:46:44,586:INFO:_display_container: 2
2023-06-14 12:46:44,586:INFO:ElasticNet(random_state=4834)
2023-06-14 12:46:44,587:INFO:create_model() successfully completed......................................
2023-06-14 12:46:44,644:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:44,644:INFO:Creating metrics dataframe
2023-06-14 12:46:44,648:INFO:Initializing Least Angle Regression
2023-06-14 12:46:44,648:INFO:Total runtime is 0.3056938211123149 minutes
2023-06-14 12:46:44,648:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:44,648:INFO:Initializing create_model()
2023-06-14 12:46:44,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:44,648:INFO:Checking exceptions
2023-06-14 12:46:44,648:INFO:Importing libraries
2023-06-14 12:46:44,648:INFO:Copying training dataset
2023-06-14 12:46:44,654:INFO:Defining folds
2023-06-14 12:46:44,654:INFO:Declaring metric variables
2023-06-14 12:46:44,654:INFO:Importing untrained model
2023-06-14 12:46:44,655:INFO:Least Angle Regression Imported successfully
2023-06-14 12:46:44,655:INFO:Starting cross validation
2023-06-14 12:46:44,657:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:44,779:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.444e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,786:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.732e-01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,787:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=8.364e-01, with an active set of 50 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,792:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=7.766e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,801:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=7.638e-01, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,804:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.330e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,807:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.633e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,809:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.423e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,810:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.825e-01, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,811:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.385e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,812:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.136e+00, with an active set of 87 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,813:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.134e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,813:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.170e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,814:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.447e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,816:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.102e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,820:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=5.408e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 4.312e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,821:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=5.349e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,822:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=5.524e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,825:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=5.411e-01, with an active set of 76 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,826:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.267e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,826:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=5.361e-01, with an active set of 77 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,831:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=7.111e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,831:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.513e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,832:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.024e-01, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,833:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.126e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,834:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=5.015e-01, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,836:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.605e+00, with an active set of 123 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,838:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.799e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,839:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=1.736e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,839:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.740e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,839:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.710e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 8.705e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,840:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.672e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,840:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.645e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,841:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.636e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,841:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.594e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,841:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.588e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,842:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.582e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,842:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=6.918e-01, with an active set of 60 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,842:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.559e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,842:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=5.235e-01, with an active set of 104 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,842:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.558e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.843e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,842:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.530e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,843:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.530e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,843:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.530e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,845:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.514e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,845:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.212e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,849:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.872e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.439e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,849:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.753e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.938e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,849:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.601e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,849:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.993e+00, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,849:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=7.774e-01, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,851:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=7.713e-01, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.326e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,853:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 137 iterations, i.e. alpha=5.783e-01, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,854:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.405e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,855:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=7.602e-01, with an active set of 107 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,855:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=7.602e-01, with an active set of 107 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,856:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=5.871e-01, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,859:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=8.064e-01, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,860:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.445e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,863:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=8.089e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,863:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=8.089e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,863:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.167e+00, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,863:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.996e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,864:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.913e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,864:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.814e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,865:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.750e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,865:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.680e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,865:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.567e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.135e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,866:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.479e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.135e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,866:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.275e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.949e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,866:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.258e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 9.800e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,866:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.212e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.201e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.166e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.119e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.112e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=2.040e+00, with an active set of 71 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=5.111e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=7.941e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,871:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=2.037e+00, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,872:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=2.037e+00, with an active set of 75 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,873:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=5.213e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,874:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.155e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,874:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=5.213e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,874:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.036e+00, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,875:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=7.909e-01, with an active set of 97 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.952e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.920e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.344e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.890e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.022e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.890e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,886:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=8.111e-01, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,888:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=8.107e-01, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,890:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.642e+00, with an active set of 105 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,890:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.580e+00, with an active set of 105 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,892:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=8.262e-01, with an active set of 119 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,893:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.014e+00, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=1.005e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=8.361e-01, with an active set of 122 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,897:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=9.965e-01, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,905:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=9.932e-01, with an active set of 104 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,907:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=4.388e+00, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:44,922:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=1.424e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:46,401:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:46:47,327:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.128e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,335:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.428e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.488e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,343:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=7.943e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,353:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.304e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,372:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=8.590e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,377:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=7.991e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,377:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=7.991e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,380:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=8.035e-01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,389:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=8.270e-01, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,397:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=1.146e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,401:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.146e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,405:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=1.618e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.522e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,407:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.522e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,407:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.279e-01, with an active set of 124 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,411:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=9.267e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,412:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.573e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,412:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=9.269e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.076e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,413:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=9.263e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.601e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,416:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=9.261e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.890e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,417:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=9.145e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,417:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=9.125e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,418:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.871e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,419:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.865e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,419:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.747e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,419:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.608e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,420:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.546e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,420:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.477e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,420:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.443e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,421:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.235e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,421:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.225e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,421:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.155e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,421:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=8.128e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,422:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=7.931e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.099e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,422:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=7.916e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,423:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=7.893e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,423:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=7.780e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,424:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=7.708e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,424:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=7.617e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:47,425:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=7.602e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:49,707:INFO:Calculating mean and std
2023-06-14 12:46:49,708:INFO:Creating metrics dataframe
2023-06-14 12:46:50,101:INFO:Uploading results into container
2023-06-14 12:46:50,101:INFO:Uploading model into container now
2023-06-14 12:46:50,102:INFO:_master_model_container: 5
2023-06-14 12:46:50,102:INFO:_display_container: 2
2023-06-14 12:46:50,102:INFO:Lars(random_state=4834)
2023-06-14 12:46:50,102:INFO:create_model() successfully completed......................................
2023-06-14 12:46:50,177:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:50,177:INFO:Creating metrics dataframe
2023-06-14 12:46:50,182:INFO:Initializing Lasso Least Angle Regression
2023-06-14 12:46:50,182:INFO:Total runtime is 0.3979162534077963 minutes
2023-06-14 12:46:50,183:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:50,183:INFO:Initializing create_model()
2023-06-14 12:46:50,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:50,183:INFO:Checking exceptions
2023-06-14 12:46:50,183:INFO:Importing libraries
2023-06-14 12:46:50,183:INFO:Copying training dataset
2023-06-14 12:46:50,188:INFO:Defining folds
2023-06-14 12:46:50,188:INFO:Declaring metric variables
2023-06-14 12:46:50,188:INFO:Importing untrained model
2023-06-14 12:46:50,189:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 12:46:50,190:INFO:Starting cross validation
2023-06-14 12:46:50,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:50,376:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.342e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,380:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.330e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,387:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.423e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,388:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.170e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,395:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.385e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.447e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,416:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.612e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,425:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.267e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,434:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.123e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,437:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.063e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,447:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.861e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,469:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.405e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:50,474:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.445e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:51,330:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.128e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:51,334:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.428e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:51,345:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.488e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:46:53,433:INFO:Calculating mean and std
2023-06-14 12:46:53,434:INFO:Creating metrics dataframe
2023-06-14 12:46:53,820:INFO:Uploading results into container
2023-06-14 12:46:53,821:INFO:Uploading model into container now
2023-06-14 12:46:53,822:INFO:_master_model_container: 6
2023-06-14 12:46:53,822:INFO:_display_container: 2
2023-06-14 12:46:53,822:INFO:LassoLars(random_state=4834)
2023-06-14 12:46:53,822:INFO:create_model() successfully completed......................................
2023-06-14 12:46:53,882:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:53,882:INFO:Creating metrics dataframe
2023-06-14 12:46:53,887:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 12:46:53,887:INFO:Total runtime is 0.45966653823852544 minutes
2023-06-14 12:46:53,887:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:53,888:INFO:Initializing create_model()
2023-06-14 12:46:53,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:53,888:INFO:Checking exceptions
2023-06-14 12:46:53,888:INFO:Importing libraries
2023-06-14 12:46:53,888:INFO:Copying training dataset
2023-06-14 12:46:53,893:INFO:Defining folds
2023-06-14 12:46:53,893:INFO:Declaring metric variables
2023-06-14 12:46:53,893:INFO:Importing untrained model
2023-06-14 12:46:53,893:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 12:46:53,893:INFO:Starting cross validation
2023-06-14 12:46:53,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:56,956:INFO:Calculating mean and std
2023-06-14 12:46:56,975:INFO:Creating metrics dataframe
2023-06-14 12:46:57,340:INFO:Uploading results into container
2023-06-14 12:46:57,340:INFO:Uploading model into container now
2023-06-14 12:46:57,341:INFO:_master_model_container: 7
2023-06-14 12:46:57,341:INFO:_display_container: 2
2023-06-14 12:46:57,341:INFO:OrthogonalMatchingPursuit()
2023-06-14 12:46:57,341:INFO:create_model() successfully completed......................................
2023-06-14 12:46:57,411:INFO:SubProcess create_model() end ==================================
2023-06-14 12:46:57,411:INFO:Creating metrics dataframe
2023-06-14 12:46:57,417:INFO:Initializing Bayesian Ridge
2023-06-14 12:46:57,417:INFO:Total runtime is 0.5185108423233032 minutes
2023-06-14 12:46:57,417:INFO:SubProcess create_model() called ==================================
2023-06-14 12:46:57,417:INFO:Initializing create_model()
2023-06-14 12:46:57,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:46:57,417:INFO:Checking exceptions
2023-06-14 12:46:57,417:INFO:Importing libraries
2023-06-14 12:46:57,418:INFO:Copying training dataset
2023-06-14 12:46:57,424:INFO:Defining folds
2023-06-14 12:46:57,424:INFO:Declaring metric variables
2023-06-14 12:46:57,424:INFO:Importing untrained model
2023-06-14 12:46:57,424:INFO:Bayesian Ridge Imported successfully
2023-06-14 12:46:57,425:INFO:Starting cross validation
2023-06-14 12:46:57,429:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:46:58,534:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 12:47:01,169:INFO:Calculating mean and std
2023-06-14 12:47:01,170:INFO:Creating metrics dataframe
2023-06-14 12:47:01,588:INFO:Uploading results into container
2023-06-14 12:47:01,589:INFO:Uploading model into container now
2023-06-14 12:47:01,589:INFO:_master_model_container: 8
2023-06-14 12:47:01,589:INFO:_display_container: 2
2023-06-14 12:47:01,589:INFO:BayesianRidge()
2023-06-14 12:47:01,589:INFO:create_model() successfully completed......................................
2023-06-14 12:47:01,650:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:01,650:INFO:Creating metrics dataframe
2023-06-14 12:47:01,655:INFO:Initializing Passive Aggressive Regressor
2023-06-14 12:47:01,655:INFO:Total runtime is 0.5891311367352804 minutes
2023-06-14 12:47:01,655:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:01,655:INFO:Initializing create_model()
2023-06-14 12:47:01,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:01,655:INFO:Checking exceptions
2023-06-14 12:47:01,655:INFO:Importing libraries
2023-06-14 12:47:01,655:INFO:Copying training dataset
2023-06-14 12:47:01,660:INFO:Defining folds
2023-06-14 12:47:01,660:INFO:Declaring metric variables
2023-06-14 12:47:01,660:INFO:Importing untrained model
2023-06-14 12:47:01,660:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 12:47:01,661:INFO:Starting cross validation
2023-06-14 12:47:01,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:47:04,891:INFO:Calculating mean and std
2023-06-14 12:47:04,892:INFO:Creating metrics dataframe
2023-06-14 12:47:05,347:INFO:Uploading results into container
2023-06-14 12:47:05,348:INFO:Uploading model into container now
2023-06-14 12:47:05,348:INFO:_master_model_container: 9
2023-06-14 12:47:05,348:INFO:_display_container: 2
2023-06-14 12:47:05,348:INFO:PassiveAggressiveRegressor(random_state=4834)
2023-06-14 12:47:05,348:INFO:create_model() successfully completed......................................
2023-06-14 12:47:05,417:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:05,417:INFO:Creating metrics dataframe
2023-06-14 12:47:05,422:INFO:Initializing Huber Regressor
2023-06-14 12:47:05,422:INFO:Total runtime is 0.6519238273302714 minutes
2023-06-14 12:47:05,422:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:05,422:INFO:Initializing create_model()
2023-06-14 12:47:05,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:05,422:INFO:Checking exceptions
2023-06-14 12:47:05,422:INFO:Importing libraries
2023-06-14 12:47:05,423:INFO:Copying training dataset
2023-06-14 12:47:05,427:INFO:Defining folds
2023-06-14 12:47:05,427:INFO:Declaring metric variables
2023-06-14 12:47:05,427:INFO:Importing untrained model
2023-06-14 12:47:05,427:INFO:Huber Regressor Imported successfully
2023-06-14 12:47:05,428:INFO:Starting cross validation
2023-06-14 12:47:05,431:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:47:05,738:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:47:05,768:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:47:05,777:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:47:05,804:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:47:05,865:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:47:05,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:47:05,880:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:47:05,892:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:47:07,169:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:47:09,250:INFO:Calculating mean and std
2023-06-14 12:47:09,251:INFO:Creating metrics dataframe
2023-06-14 12:47:09,671:INFO:Uploading results into container
2023-06-14 12:47:09,672:INFO:Uploading model into container now
2023-06-14 12:47:09,673:INFO:_master_model_container: 10
2023-06-14 12:47:09,673:INFO:_display_container: 2
2023-06-14 12:47:09,673:INFO:HuberRegressor()
2023-06-14 12:47:09,673:INFO:create_model() successfully completed......................................
2023-06-14 12:47:09,743:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:09,744:INFO:Creating metrics dataframe
2023-06-14 12:47:09,749:INFO:Initializing K Neighbors Regressor
2023-06-14 12:47:09,749:INFO:Total runtime is 0.72403857310613 minutes
2023-06-14 12:47:09,749:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:09,749:INFO:Initializing create_model()
2023-06-14 12:47:09,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:09,750:INFO:Checking exceptions
2023-06-14 12:47:09,750:INFO:Importing libraries
2023-06-14 12:47:09,750:INFO:Copying training dataset
2023-06-14 12:47:09,754:INFO:Defining folds
2023-06-14 12:47:09,754:INFO:Declaring metric variables
2023-06-14 12:47:09,755:INFO:Importing untrained model
2023-06-14 12:47:09,755:INFO:K Neighbors Regressor Imported successfully
2023-06-14 12:47:09,755:INFO:Starting cross validation
2023-06-14 12:47:09,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:47:13,004:INFO:Calculating mean and std
2023-06-14 12:47:13,005:INFO:Creating metrics dataframe
2023-06-14 12:47:13,361:INFO:Uploading results into container
2023-06-14 12:47:13,362:INFO:Uploading model into container now
2023-06-14 12:47:13,362:INFO:_master_model_container: 11
2023-06-14 12:47:13,362:INFO:_display_container: 2
2023-06-14 12:47:13,362:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 12:47:13,362:INFO:create_model() successfully completed......................................
2023-06-14 12:47:13,420:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:13,421:INFO:Creating metrics dataframe
2023-06-14 12:47:13,425:INFO:Initializing Decision Tree Regressor
2023-06-14 12:47:13,425:INFO:Total runtime is 0.7853015979131063 minutes
2023-06-14 12:47:13,425:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:13,425:INFO:Initializing create_model()
2023-06-14 12:47:13,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:13,426:INFO:Checking exceptions
2023-06-14 12:47:13,426:INFO:Importing libraries
2023-06-14 12:47:13,426:INFO:Copying training dataset
2023-06-14 12:47:13,430:INFO:Defining folds
2023-06-14 12:47:13,430:INFO:Declaring metric variables
2023-06-14 12:47:13,430:INFO:Importing untrained model
2023-06-14 12:47:13,431:INFO:Decision Tree Regressor Imported successfully
2023-06-14 12:47:13,431:INFO:Starting cross validation
2023-06-14 12:47:13,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:47:16,378:INFO:Calculating mean and std
2023-06-14 12:47:16,379:INFO:Creating metrics dataframe
2023-06-14 12:47:16,760:INFO:Uploading results into container
2023-06-14 12:47:16,760:INFO:Uploading model into container now
2023-06-14 12:47:16,761:INFO:_master_model_container: 12
2023-06-14 12:47:16,761:INFO:_display_container: 2
2023-06-14 12:47:16,761:INFO:DecisionTreeRegressor(random_state=4834)
2023-06-14 12:47:16,761:INFO:create_model() successfully completed......................................
2023-06-14 12:47:16,820:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:16,820:INFO:Creating metrics dataframe
2023-06-14 12:47:16,825:INFO:Initializing Random Forest Regressor
2023-06-14 12:47:16,825:INFO:Total runtime is 0.8419724861780802 minutes
2023-06-14 12:47:16,825:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:16,825:INFO:Initializing create_model()
2023-06-14 12:47:16,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:16,825:INFO:Checking exceptions
2023-06-14 12:47:16,825:INFO:Importing libraries
2023-06-14 12:47:16,825:INFO:Copying training dataset
2023-06-14 12:47:16,830:INFO:Defining folds
2023-06-14 12:47:16,830:INFO:Declaring metric variables
2023-06-14 12:47:16,831:INFO:Importing untrained model
2023-06-14 12:47:16,831:INFO:Random Forest Regressor Imported successfully
2023-06-14 12:47:16,831:INFO:Starting cross validation
2023-06-14 12:47:16,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:47:18,324:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:47:18,325:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:47:18,328:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:47:21,613:INFO:Calculating mean and std
2023-06-14 12:47:21,614:INFO:Creating metrics dataframe
2023-06-14 12:47:22,018:INFO:Uploading results into container
2023-06-14 12:47:22,018:INFO:Uploading model into container now
2023-06-14 12:47:22,018:INFO:_master_model_container: 13
2023-06-14 12:47:22,019:INFO:_display_container: 2
2023-06-14 12:47:22,019:INFO:RandomForestRegressor(n_jobs=-1, random_state=4834)
2023-06-14 12:47:22,019:INFO:create_model() successfully completed......................................
2023-06-14 12:47:22,137:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:22,137:INFO:Creating metrics dataframe
2023-06-14 12:47:22,146:INFO:Initializing Extra Trees Regressor
2023-06-14 12:47:22,146:INFO:Total runtime is 0.9306616028149922 minutes
2023-06-14 12:47:22,146:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:22,147:INFO:Initializing create_model()
2023-06-14 12:47:22,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:22,147:INFO:Checking exceptions
2023-06-14 12:47:22,147:INFO:Importing libraries
2023-06-14 12:47:22,147:INFO:Copying training dataset
2023-06-14 12:47:22,155:INFO:Defining folds
2023-06-14 12:47:22,155:INFO:Declaring metric variables
2023-06-14 12:47:22,155:INFO:Importing untrained model
2023-06-14 12:47:22,155:INFO:Extra Trees Regressor Imported successfully
2023-06-14 12:47:22,156:INFO:Starting cross validation
2023-06-14 12:47:22,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:47:23,505:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:47:23,525:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:47:23,567:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:47:24,499:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 12:47:27,490:INFO:Calculating mean and std
2023-06-14 12:47:27,491:INFO:Creating metrics dataframe
2023-06-14 12:47:27,885:INFO:Uploading results into container
2023-06-14 12:47:27,886:INFO:Uploading model into container now
2023-06-14 12:47:27,887:INFO:_master_model_container: 14
2023-06-14 12:47:27,887:INFO:_display_container: 2
2023-06-14 12:47:27,887:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4834)
2023-06-14 12:47:27,887:INFO:create_model() successfully completed......................................
2023-06-14 12:47:27,964:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:27,966:INFO:Creating metrics dataframe
2023-06-14 12:47:27,970:INFO:Initializing AdaBoost Regressor
2023-06-14 12:47:27,971:INFO:Total runtime is 1.0277434825897216 minutes
2023-06-14 12:47:27,971:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:27,971:INFO:Initializing create_model()
2023-06-14 12:47:27,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:27,971:INFO:Checking exceptions
2023-06-14 12:47:27,971:INFO:Importing libraries
2023-06-14 12:47:27,971:INFO:Copying training dataset
2023-06-14 12:47:27,978:INFO:Defining folds
2023-06-14 12:47:27,979:INFO:Declaring metric variables
2023-06-14 12:47:27,979:INFO:Importing untrained model
2023-06-14 12:47:27,979:INFO:AdaBoost Regressor Imported successfully
2023-06-14 12:47:27,980:INFO:Starting cross validation
2023-06-14 12:47:27,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:47:31,981:INFO:Calculating mean and std
2023-06-14 12:47:31,983:INFO:Creating metrics dataframe
2023-06-14 12:47:32,454:INFO:Uploading results into container
2023-06-14 12:47:32,454:INFO:Uploading model into container now
2023-06-14 12:47:32,455:INFO:_master_model_container: 15
2023-06-14 12:47:32,455:INFO:_display_container: 2
2023-06-14 12:47:32,455:INFO:AdaBoostRegressor(random_state=4834)
2023-06-14 12:47:32,455:INFO:create_model() successfully completed......................................
2023-06-14 12:47:32,518:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:32,518:INFO:Creating metrics dataframe
2023-06-14 12:47:32,523:INFO:Initializing Gradient Boosting Regressor
2023-06-14 12:47:32,524:INFO:Total runtime is 1.1036217212677002 minutes
2023-06-14 12:47:32,524:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:32,524:INFO:Initializing create_model()
2023-06-14 12:47:32,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:32,524:INFO:Checking exceptions
2023-06-14 12:47:32,524:INFO:Importing libraries
2023-06-14 12:47:32,524:INFO:Copying training dataset
2023-06-14 12:47:32,529:INFO:Defining folds
2023-06-14 12:47:32,529:INFO:Declaring metric variables
2023-06-14 12:47:32,529:INFO:Importing untrained model
2023-06-14 12:47:32,530:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 12:47:32,530:INFO:Starting cross validation
2023-06-14 12:47:32,532:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:47:33,725:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:47:37,009:INFO:Calculating mean and std
2023-06-14 12:47:37,010:INFO:Creating metrics dataframe
2023-06-14 12:47:37,398:INFO:Uploading results into container
2023-06-14 12:47:37,399:INFO:Uploading model into container now
2023-06-14 12:47:37,399:INFO:_master_model_container: 16
2023-06-14 12:47:37,399:INFO:_display_container: 2
2023-06-14 12:47:37,400:INFO:GradientBoostingRegressor(random_state=4834)
2023-06-14 12:47:37,400:INFO:create_model() successfully completed......................................
2023-06-14 12:47:37,458:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:37,458:INFO:Creating metrics dataframe
2023-06-14 12:47:37,463:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 12:47:37,463:INFO:Total runtime is 1.1859428922335307 minutes
2023-06-14 12:47:37,463:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:37,464:INFO:Initializing create_model()
2023-06-14 12:47:37,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:37,464:INFO:Checking exceptions
2023-06-14 12:47:37,464:INFO:Importing libraries
2023-06-14 12:47:37,464:INFO:Copying training dataset
2023-06-14 12:47:37,469:INFO:Defining folds
2023-06-14 12:47:37,469:INFO:Declaring metric variables
2023-06-14 12:47:37,469:INFO:Importing untrained model
2023-06-14 12:47:37,470:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 12:47:37,470:INFO:Starting cross validation
2023-06-14 12:47:37,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:47:40,530:INFO:Calculating mean and std
2023-06-14 12:47:40,532:INFO:Creating metrics dataframe
2023-06-14 12:47:40,906:INFO:Uploading results into container
2023-06-14 12:47:40,906:INFO:Uploading model into container now
2023-06-14 12:47:40,907:INFO:_master_model_container: 17
2023-06-14 12:47:40,907:INFO:_display_container: 2
2023-06-14 12:47:40,907:INFO:LGBMRegressor(random_state=4834)
2023-06-14 12:47:40,907:INFO:create_model() successfully completed......................................
2023-06-14 12:47:40,966:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:40,966:INFO:Creating metrics dataframe
2023-06-14 12:47:40,971:INFO:Initializing Dummy Regressor
2023-06-14 12:47:40,971:INFO:Total runtime is 1.2444048245747883 minutes
2023-06-14 12:47:40,971:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:40,971:INFO:Initializing create_model()
2023-06-14 12:47:40,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F145212F20>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:40,971:INFO:Checking exceptions
2023-06-14 12:47:40,971:INFO:Importing libraries
2023-06-14 12:47:40,972:INFO:Copying training dataset
2023-06-14 12:47:40,976:INFO:Defining folds
2023-06-14 12:47:40,976:INFO:Declaring metric variables
2023-06-14 12:47:40,977:INFO:Importing untrained model
2023-06-14 12:47:40,977:INFO:Dummy Regressor Imported successfully
2023-06-14 12:47:40,977:INFO:Starting cross validation
2023-06-14 12:47:40,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:47:44,039:INFO:Calculating mean and std
2023-06-14 12:47:44,040:INFO:Creating metrics dataframe
2023-06-14 12:47:44,453:INFO:Uploading results into container
2023-06-14 12:47:44,453:INFO:Uploading model into container now
2023-06-14 12:47:44,453:INFO:_master_model_container: 18
2023-06-14 12:47:44,454:INFO:_display_container: 2
2023-06-14 12:47:44,454:INFO:DummyRegressor()
2023-06-14 12:47:44,454:INFO:create_model() successfully completed......................................
2023-06-14 12:47:44,514:INFO:SubProcess create_model() end ==================================
2023-06-14 12:47:44,514:INFO:Creating metrics dataframe
2023-06-14 12:47:44,520:INFO:Initializing create_model()
2023-06-14 12:47:44,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F144F2E9B0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=4834), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:44,520:INFO:Checking exceptions
2023-06-14 12:47:44,520:INFO:Importing libraries
2023-06-14 12:47:44,521:INFO:Copying training dataset
2023-06-14 12:47:44,525:INFO:Defining folds
2023-06-14 12:47:44,525:INFO:Declaring metric variables
2023-06-14 12:47:44,525:INFO:Importing untrained model
2023-06-14 12:47:44,525:INFO:Declaring custom model
2023-06-14 12:47:44,526:INFO:Extra Trees Regressor Imported successfully
2023-06-14 12:47:44,528:INFO:Cross validation set to False
2023-06-14 12:47:44,528:INFO:Fitting Model
2023-06-14 12:47:45,251:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4834)
2023-06-14 12:47:45,251:INFO:create_model() successfully completed......................................
2023-06-14 12:47:45,325:INFO:_master_model_container: 18
2023-06-14 12:47:45,325:INFO:_display_container: 2
2023-06-14 12:47:45,326:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4834)
2023-06-14 12:47:45,326:INFO:compare_models() successfully completed......................................
2023-06-14 12:47:54,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:47:54,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:47:54,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:47:54,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:47:55,318:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:47:56,112:INFO:PyCaret RegressionExperiment
2023-06-14 12:47:56,112:INFO:Logging name: reg-default-name
2023-06-14 12:47:56,112:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 12:47:56,112:INFO:version 3.0.2
2023-06-14 12:47:56,112:INFO:Initializing setup()
2023-06-14 12:47:56,112:INFO:self.USI: 3195
2023-06-14 12:47:56,112:INFO:self._variable_keys: {'logging_param', 'n_jobs_param', 'USI', 'log_plots_param', '_available_plots', 'fold_groups_param', 'fold_generator', 'target_param', 'y', 'exp_id', 'gpu_n_jobs_param', 'memory', 'X', 'seed', 'transform_target_param', 'html_param', 'X_train', 'fold_shuffle_param', 'exp_name_log', 'y_train', 'y_test', 'gpu_param', 'data', 'pipeline', '_ml_usecase', 'X_test', 'idx'}
2023-06-14 12:47:56,112:INFO:Checking environment
2023-06-14 12:47:56,112:INFO:python_version: 3.10.11
2023-06-14 12:47:56,112:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-06-14 12:47:56,112:INFO:machine: AMD64
2023-06-14 12:47:56,124:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 12:47:56,129:INFO:Memory: svmem(total=17013329920, available=3674419200, percent=78.4, used=13338910720, free=3674419200)
2023-06-14 12:47:56,129:INFO:Physical Core: 4
2023-06-14 12:47:56,129:INFO:Logical Core: 8
2023-06-14 12:47:56,129:INFO:Checking libraries
2023-06-14 12:47:56,130:INFO:System:
2023-06-14 12:47:56,130:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-06-14 12:47:56,130:INFO:executable: E:\Machine learning\mini\adam\Scripts\python.exe
2023-06-14 12:47:56,130:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 12:47:56,130:INFO:PyCaret required dependencies:
2023-06-14 12:47:56,130:INFO:                 pip: 23.0.1
2023-06-14 12:47:56,130:INFO:          setuptools: 65.5.0
2023-06-14 12:47:56,130:INFO:             pycaret: 3.0.2
2023-06-14 12:47:56,130:INFO:             IPython: 8.14.0
2023-06-14 12:47:56,130:INFO:          ipywidgets: 8.0.6
2023-06-14 12:47:56,130:INFO:                tqdm: 4.65.0
2023-06-14 12:47:56,130:INFO:               numpy: 1.23.5
2023-06-14 12:47:56,130:INFO:              pandas: 1.5.3
2023-06-14 12:47:56,130:INFO:              jinja2: 3.1.2
2023-06-14 12:47:56,130:INFO:               scipy: 1.10.1
2023-06-14 12:47:56,130:INFO:              joblib: 1.2.0
2023-06-14 12:47:56,130:INFO:             sklearn: 1.2.2
2023-06-14 12:47:56,130:INFO:                pyod: 1.0.9
2023-06-14 12:47:56,130:INFO:            imblearn: 0.10.1
2023-06-14 12:47:56,130:INFO:   category_encoders: 2.6.1
2023-06-14 12:47:56,130:INFO:            lightgbm: 3.3.5
2023-06-14 12:47:56,130:INFO:               numba: 0.57.0
2023-06-14 12:47:56,130:INFO:            requests: 2.31.0
2023-06-14 12:47:56,130:INFO:          matplotlib: 3.7.1
2023-06-14 12:47:56,131:INFO:          scikitplot: 0.3.7
2023-06-14 12:47:56,131:INFO:         yellowbrick: 1.5
2023-06-14 12:47:56,131:INFO:              plotly: 5.15.0
2023-06-14 12:47:56,131:INFO:             kaleido: 0.2.1
2023-06-14 12:47:56,131:INFO:         statsmodels: 0.14.0
2023-06-14 12:47:56,131:INFO:              sktime: 0.17.0
2023-06-14 12:47:56,131:INFO:               tbats: 1.1.3
2023-06-14 12:47:56,131:INFO:            pmdarima: 2.0.3
2023-06-14 12:47:56,131:INFO:              psutil: 5.9.5
2023-06-14 12:47:56,131:INFO:PyCaret optional dependencies:
2023-06-14 12:47:56,143:INFO:                shap: Not installed
2023-06-14 12:47:56,143:INFO:           interpret: Not installed
2023-06-14 12:47:56,143:INFO:                umap: Not installed
2023-06-14 12:47:56,143:INFO:    pandas_profiling: Not installed
2023-06-14 12:47:56,144:INFO:  explainerdashboard: Not installed
2023-06-14 12:47:56,144:INFO:             autoviz: Not installed
2023-06-14 12:47:56,144:INFO:           fairlearn: Not installed
2023-06-14 12:47:56,144:INFO:             xgboost: Not installed
2023-06-14 12:47:56,144:INFO:            catboost: Not installed
2023-06-14 12:47:56,144:INFO:              kmodes: Not installed
2023-06-14 12:47:56,144:INFO:             mlxtend: Not installed
2023-06-14 12:47:56,144:INFO:       statsforecast: Not installed
2023-06-14 12:47:56,144:INFO:        tune_sklearn: Not installed
2023-06-14 12:47:56,144:INFO:                 ray: Not installed
2023-06-14 12:47:56,144:INFO:            hyperopt: Not installed
2023-06-14 12:47:56,144:INFO:              optuna: Not installed
2023-06-14 12:47:56,144:INFO:               skopt: Not installed
2023-06-14 12:47:56,144:INFO:              mlflow: Not installed
2023-06-14 12:47:56,144:INFO:              gradio: Not installed
2023-06-14 12:47:56,144:INFO:             fastapi: Not installed
2023-06-14 12:47:56,144:INFO:             uvicorn: Not installed
2023-06-14 12:47:56,144:INFO:              m2cgen: Not installed
2023-06-14 12:47:56,144:INFO:           evidently: Not installed
2023-06-14 12:47:56,144:INFO:               fugue: Not installed
2023-06-14 12:47:56,144:INFO:           streamlit: Not installed
2023-06-14 12:47:56,144:INFO:             prophet: Not installed
2023-06-14 12:47:56,144:INFO:None
2023-06-14 12:47:56,144:INFO:Set up data.
2023-06-14 12:47:56,263:INFO:Set up train/test split.
2023-06-14 12:47:56,271:INFO:Set up index.
2023-06-14 12:47:56,272:INFO:Set up folding strategy.
2023-06-14 12:47:56,272:INFO:Assigning column types.
2023-06-14 12:47:56,276:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 12:47:56,276:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,280:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,285:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,388:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,392:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,396:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,447:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,486:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,487:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 12:47:56,491:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,591:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,595:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,646:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,687:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,688:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,688:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 12:47:56,697:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,795:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,850:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,889:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,890:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 12:47:56,950:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:47:56,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:56,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,051:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:47:57,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:47:57,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,095:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 12:47:57,156:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:47:57,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,255:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:47:57,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,296:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 12:47:57,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,497:INFO:Preparing preprocessing pipeline...
2023-06-14 12:47:57,497:INFO:Set up simple imputation.
2023-06-14 12:47:57,537:INFO:Finished creating preprocessing pipeline.
2023-06-14 12:47:57,545:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\adamr\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bid_amount', '0', '1', '2', '3',
                                             '4', '5', '6', '7', '8', '9', '10',
                                             '11', '12', '13', '14', '15', '16',
                                             '17', '18', '19', '20', '21', '22',
                                             '23', '24', '25', '26', '27', '28', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-06-14 12:47:57,545:INFO:Creating final display dataframe.
2023-06-14 12:47:57,708:INFO:Setup _display_container:                     Description             Value
0                    Session id              1372
1                        Target    combined_score
2                   Target type        Regression
3           Original data shape        (211, 597)
4        Transformed data shape        (211, 597)
5   Transformed train set shape        (147, 597)
6    Transformed test set shape         (64, 597)
7              Numeric features               596
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              3195
2023-06-14 12:47:57,812:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:47:57,912:INFO:setup() successfully completed in 2.06s...............
2023-06-14 12:47:57,912:INFO:Initializing compare_models()
2023-06-14 12:47:57,912:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 12:47:57,912:INFO:Checking exceptions
2023-06-14 12:47:57,914:INFO:Preparing display monitor
2023-06-14 12:47:57,917:INFO:Initializing Linear Regression
2023-06-14 12:47:57,917:INFO:Total runtime is 0.0 minutes
2023-06-14 12:47:57,917:INFO:SubProcess create_model() called ==================================
2023-06-14 12:47:57,918:INFO:Initializing create_model()
2023-06-14 12:47:57,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:47:57,918:INFO:Checking exceptions
2023-06-14 12:47:57,918:INFO:Importing libraries
2023-06-14 12:47:57,918:INFO:Copying training dataset
2023-06-14 12:47:57,922:INFO:Defining folds
2023-06-14 12:47:57,922:INFO:Declaring metric variables
2023-06-14 12:47:57,922:INFO:Importing untrained model
2023-06-14 12:47:57,922:INFO:Linear Regression Imported successfully
2023-06-14 12:47:57,922:INFO:Starting cross validation
2023-06-14 12:47:57,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:05,682:INFO:Calculating mean and std
2023-06-14 12:48:05,683:INFO:Creating metrics dataframe
2023-06-14 12:48:06,063:INFO:Uploading results into container
2023-06-14 12:48:06,064:INFO:Uploading model into container now
2023-06-14 12:48:06,064:INFO:_master_model_container: 1
2023-06-14 12:48:06,064:INFO:_display_container: 2
2023-06-14 12:48:06,064:INFO:LinearRegression(n_jobs=-1)
2023-06-14 12:48:06,064:INFO:create_model() successfully completed......................................
2023-06-14 12:48:06,124:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:06,124:INFO:Creating metrics dataframe
2023-06-14 12:48:06,129:INFO:Initializing Lasso Regression
2023-06-14 12:48:06,129:INFO:Total runtime is 0.13686962525049845 minutes
2023-06-14 12:48:06,129:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:06,129:INFO:Initializing create_model()
2023-06-14 12:48:06,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:06,129:INFO:Checking exceptions
2023-06-14 12:48:06,129:INFO:Importing libraries
2023-06-14 12:48:06,129:INFO:Copying training dataset
2023-06-14 12:48:06,135:INFO:Defining folds
2023-06-14 12:48:06,135:INFO:Declaring metric variables
2023-06-14 12:48:06,135:INFO:Importing untrained model
2023-06-14 12:48:06,136:INFO:Lasso Regression Imported successfully
2023-06-14 12:48:06,136:INFO:Starting cross validation
2023-06-14 12:48:06,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:09,271:INFO:Calculating mean and std
2023-06-14 12:48:09,272:INFO:Creating metrics dataframe
2023-06-14 12:48:09,654:INFO:Uploading results into container
2023-06-14 12:48:09,655:INFO:Uploading model into container now
2023-06-14 12:48:09,655:INFO:_master_model_container: 2
2023-06-14 12:48:09,655:INFO:_display_container: 2
2023-06-14 12:48:09,655:INFO:Lasso(random_state=1372)
2023-06-14 12:48:09,655:INFO:create_model() successfully completed......................................
2023-06-14 12:48:09,719:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:09,720:INFO:Creating metrics dataframe
2023-06-14 12:48:09,724:INFO:Initializing Ridge Regression
2023-06-14 12:48:09,724:INFO:Total runtime is 0.19678443670272827 minutes
2023-06-14 12:48:09,724:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:09,725:INFO:Initializing create_model()
2023-06-14 12:48:09,725:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:09,725:INFO:Checking exceptions
2023-06-14 12:48:09,725:INFO:Importing libraries
2023-06-14 12:48:09,725:INFO:Copying training dataset
2023-06-14 12:48:09,731:INFO:Defining folds
2023-06-14 12:48:09,731:INFO:Declaring metric variables
2023-06-14 12:48:09,731:INFO:Importing untrained model
2023-06-14 12:48:09,732:INFO:Ridge Regression Imported successfully
2023-06-14 12:48:09,732:INFO:Starting cross validation
2023-06-14 12:48:09,734:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:12,751:INFO:Calculating mean and std
2023-06-14 12:48:12,752:INFO:Creating metrics dataframe
2023-06-14 12:48:13,139:INFO:Uploading results into container
2023-06-14 12:48:13,140:INFO:Uploading model into container now
2023-06-14 12:48:13,140:INFO:_master_model_container: 3
2023-06-14 12:48:13,140:INFO:_display_container: 2
2023-06-14 12:48:13,141:INFO:Ridge(random_state=1372)
2023-06-14 12:48:13,141:INFO:create_model() successfully completed......................................
2023-06-14 12:48:13,199:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:13,199:INFO:Creating metrics dataframe
2023-06-14 12:48:13,203:INFO:Initializing Elastic Net
2023-06-14 12:48:13,203:INFO:Total runtime is 0.2547739505767822 minutes
2023-06-14 12:48:13,204:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:13,204:INFO:Initializing create_model()
2023-06-14 12:48:13,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:13,204:INFO:Checking exceptions
2023-06-14 12:48:13,204:INFO:Importing libraries
2023-06-14 12:48:13,204:INFO:Copying training dataset
2023-06-14 12:48:13,210:INFO:Defining folds
2023-06-14 12:48:13,210:INFO:Declaring metric variables
2023-06-14 12:48:13,210:INFO:Importing untrained model
2023-06-14 12:48:13,210:INFO:Elastic Net Imported successfully
2023-06-14 12:48:13,211:INFO:Starting cross validation
2023-06-14 12:48:13,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:16,256:INFO:Calculating mean and std
2023-06-14 12:48:16,257:INFO:Creating metrics dataframe
2023-06-14 12:48:16,640:INFO:Uploading results into container
2023-06-14 12:48:16,641:INFO:Uploading model into container now
2023-06-14 12:48:16,641:INFO:_master_model_container: 4
2023-06-14 12:48:16,641:INFO:_display_container: 2
2023-06-14 12:48:16,642:INFO:ElasticNet(random_state=1372)
2023-06-14 12:48:16,642:INFO:create_model() successfully completed......................................
2023-06-14 12:48:16,699:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:16,699:INFO:Creating metrics dataframe
2023-06-14 12:48:16,704:INFO:Initializing Least Angle Regression
2023-06-14 12:48:16,704:INFO:Total runtime is 0.313117508093516 minutes
2023-06-14 12:48:16,704:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:16,704:INFO:Initializing create_model()
2023-06-14 12:48:16,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:16,705:INFO:Checking exceptions
2023-06-14 12:48:16,705:INFO:Importing libraries
2023-06-14 12:48:16,705:INFO:Copying training dataset
2023-06-14 12:48:16,711:INFO:Defining folds
2023-06-14 12:48:16,711:INFO:Declaring metric variables
2023-06-14 12:48:16,711:INFO:Importing untrained model
2023-06-14 12:48:16,711:INFO:Least Angle Regression Imported successfully
2023-06-14 12:48:16,711:INFO:Starting cross validation
2023-06-14 12:48:16,713:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:16,857:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.405e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 4.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,859:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.405e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,859:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.362e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,860:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.358e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,867:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.213e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,871:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.416e+00, with an active set of 61 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,875:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=1.392e+00, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.372e+00, with an active set of 75 regressors, and the smallest cholesky pivot element being 4.785e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,878:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.372e+00, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,882:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.508e+00, with an active set of 82 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=6.559e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 3.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,891:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=1.584e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,901:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.432e+00, with an active set of 64 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,901:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.432e+00, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,906:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=2.377e+00, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,908:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.818e+00, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,911:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=5.030e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,914:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=5.025e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.967e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.846e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.967e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 3.969e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.829e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.824e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=2.866e+00, with an active set of 84 regressors, and the smallest cholesky pivot element being 3.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.674e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.554e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.519e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.007e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 3.808e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=2.756e+00, with an active set of 84 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.422e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.925e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.418e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.282e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.249e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.237e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.192e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.081e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.069e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,920:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.021e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,920:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.954e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.312e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,920:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.954e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,921:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.937e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,921:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.906e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,922:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.905e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,922:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.856e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,922:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.833e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.798e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.783e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.262e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.761e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.242e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.743e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,924:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.742e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,924:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.739e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,924:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.737e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,925:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.704e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,925:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.688e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.671e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.671e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.618e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.608e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.810e+00, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,926:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.796e+00, with an active set of 51 regressors, and the smallest cholesky pivot element being 3.969e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.606e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.582e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.580e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=4.744e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.572e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.570e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.559e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.559e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.550e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.861e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.748e+00, with an active set of 56 regressors, and the smallest cholesky pivot element being 3.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,930:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.545e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,930:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.529e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,930:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.501e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.139e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,931:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.497e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.708e+00, with an active set of 60 regressors, and the smallest cholesky pivot element being 4.030e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.493e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.488e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.482e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.690e+00, with an active set of 61 regressors, and the smallest cholesky pivot element being 4.264e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=4.933e+00, with an active set of 107 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.479e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.326e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.478e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.388e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.475e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.682e+00, with an active set of 62 regressors, and the smallest cholesky pivot element being 3.969e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.791e-01, with an active set of 65 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-06-14 12:48:16,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.469e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,935:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.448e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,935:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.791e-01, with an active set of 65 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,935:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.440e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,935:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.439e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.699e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,936:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.429e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,936:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.406e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,937:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.390e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.269e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,937:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.383e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,937:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=5.102e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 4.563e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,938:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.381e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,939:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.366e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,939:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.361e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,939:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.359e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,940:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.354e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,940:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.349e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,940:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.342e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,940:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.706e+00, with an active set of 72 regressors, and the smallest cholesky pivot element being 3.808e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,941:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.335e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,941:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.326e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.102e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,942:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=5.096e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,942:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.657e+00, with an active set of 74 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,942:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.325e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,942:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.308e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,943:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.304e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,943:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.299e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.928e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,943:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=5.096e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,943:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.288e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.287e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.029e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=9.925e-01, with an active set of 93 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.282e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=5.507e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.281e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.914e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,945:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.277e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,945:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.272e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.637e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,945:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.268e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.647e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,946:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.251e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,946:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.239e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,946:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.237e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.737e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,947:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.235e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,948:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.234e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.890e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,948:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=9.964e-01, with an active set of 97 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,949:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.209e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,949:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.855e-01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,950:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.196e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,950:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.192e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,950:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.174e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,951:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.172e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,951:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.655e+00, with an active set of 91 regressors, and the smallest cholesky pivot element being 3.969e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,951:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.163e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,951:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.655e+00, with an active set of 91 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,951:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.163e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,951:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.655e+00, with an active set of 91 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,952:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.654e+00, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,952:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.146e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,952:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.145e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,953:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.142e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,953:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.138e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,953:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.132e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.135e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,954:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.132e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,954:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=1.945e+01, with an active set of 127 regressors, and the smallest cholesky pivot element being 9.599e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,954:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.114e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,954:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=1.945e+01, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,954:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.106e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,955:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.095e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,955:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.092e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,956:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.080e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.445e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,956:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=1.983e+01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.278e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,956:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=4.414e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,956:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=2.696e+00, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,956:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=4.410e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,956:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.078e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,957:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.065e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,957:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=1.869e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,957:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.063e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.937e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,957:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.027e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,958:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.023e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,958:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.021e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,958:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.017e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,959:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.009e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,959:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.008e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,959:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=8.895e-01, with an active set of 63 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,960:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.003e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,960:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=4.870e-01, with an active set of 84 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,960:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.995e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,961:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.960e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.538e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,961:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.804e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,961:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.803e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,962:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.742e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,962:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.675e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.226e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,962:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.844e-01, with an active set of 88 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,964:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.675e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,964:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.494e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,964:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=2.568e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,964:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.486e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,965:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.414e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,966:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=2.566e+00, with an active set of 110 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,966:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.307e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,966:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.267e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,967:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.222e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,968:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.173e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,969:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.164e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,969:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.983e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.183e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,970:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.968e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,970:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=2.561e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,970:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.886e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,971:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.749e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,971:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.657e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,971:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.553e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,972:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=1.237e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,972:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.491e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,972:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.388e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,972:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=1.586e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.608e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,973:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.262e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,973:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=1.586e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,973:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.135e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,973:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=1.580e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,973:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.917e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,973:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.864e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,973:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=1.473e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,974:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.833e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,974:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.761e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.567e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,975:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=1.432e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,975:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.717e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,975:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.683e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,975:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=1.384e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,975:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.667e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,976:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.634e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,976:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.541e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,976:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.311e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,976:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.245e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.757e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,978:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.119e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,978:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.229e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,978:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.102e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,979:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.899e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,979:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.897e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,979:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.856e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,979:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.775e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.914e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,980:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.712e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,980:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.256e+01, with an active set of 105 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,980:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.656e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,980:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.639e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,981:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.604e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.660e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,981:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.588e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,982:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.547e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,982:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.530e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,982:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.430e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,983:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.302e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,983:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.238e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,983:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.193e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.169e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.157e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.139e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,986:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.019e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,986:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=1.270e+01, with an active set of 113 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,986:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.895e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,986:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.861e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,987:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.834e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.033e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,987:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.805e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,987:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.777e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,988:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.719e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.499e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,988:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.548e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,988:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.540e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.890e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,988:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.484e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.353e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,989:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.321e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,989:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.315e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,989:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.310e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,990:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.303e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.998e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,990:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.076e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,990:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.070e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,991:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.033e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,991:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.028e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,992:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.026e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,992:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.993e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,992:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.973e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,993:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.946e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,993:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.842e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.737e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,994:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.832e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,994:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.810e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,994:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.810e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,995:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.673e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,995:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.671e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,995:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.591e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:16,996:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=4.575e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.321e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,000:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.777e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,000:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.236e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.532e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,000:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.158e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,000:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.777e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,001:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.135e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.479e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,001:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=6.637e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,001:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=6.624e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,002:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=6.138e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,002:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=5.981e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.156e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,003:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=5.567e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.347e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,003:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=5.349e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,004:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=5.147e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,004:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=4.969e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,004:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=4.966e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.467e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,005:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=4.843e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,005:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=4.814e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,006:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.657e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,007:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.654e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.347e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,007:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.597e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,007:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.573e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,008:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.564e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,008:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.558e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.817e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,008:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.425e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 9.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,009:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.356e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.076e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,011:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.253e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 8.592e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,011:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.239e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,011:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.167e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,014:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=2.076e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:17,014:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.774e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:19,039:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.337e-01, with an active set of 51 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:19,053:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.135e+00, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:19,053:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=6.318e-01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:19,054:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.120e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:19,054:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.120e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:19,056:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=6.266e-01, with an active set of 89 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:19,064:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=6.662e-01, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:19,069:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=1.310e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:19,071:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.307e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:19,073:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.719e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:21,235:INFO:Calculating mean and std
2023-06-14 12:48:21,236:INFO:Creating metrics dataframe
2023-06-14 12:48:21,655:INFO:Uploading results into container
2023-06-14 12:48:21,656:INFO:Uploading model into container now
2023-06-14 12:48:21,656:INFO:_master_model_container: 5
2023-06-14 12:48:21,656:INFO:_display_container: 2
2023-06-14 12:48:21,657:INFO:Lars(random_state=1372)
2023-06-14 12:48:21,657:INFO:create_model() successfully completed......................................
2023-06-14 12:48:21,716:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:21,716:INFO:Creating metrics dataframe
2023-06-14 12:48:21,721:INFO:Initializing Lasso Least Angle Regression
2023-06-14 12:48:21,722:INFO:Total runtime is 0.3967462460199992 minutes
2023-06-14 12:48:21,722:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:21,722:INFO:Initializing create_model()
2023-06-14 12:48:21,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:21,722:INFO:Checking exceptions
2023-06-14 12:48:21,722:INFO:Importing libraries
2023-06-14 12:48:21,722:INFO:Copying training dataset
2023-06-14 12:48:21,727:INFO:Defining folds
2023-06-14 12:48:21,727:INFO:Declaring metric variables
2023-06-14 12:48:21,728:INFO:Importing untrained model
2023-06-14 12:48:21,728:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 12:48:21,728:INFO:Starting cross validation
2023-06-14 12:48:21,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:21,885:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.213e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:48:24,847:INFO:Calculating mean and std
2023-06-14 12:48:24,848:INFO:Creating metrics dataframe
2023-06-14 12:48:25,255:INFO:Uploading results into container
2023-06-14 12:48:25,256:INFO:Uploading model into container now
2023-06-14 12:48:25,256:INFO:_master_model_container: 6
2023-06-14 12:48:25,256:INFO:_display_container: 2
2023-06-14 12:48:25,256:INFO:LassoLars(random_state=1372)
2023-06-14 12:48:25,256:INFO:create_model() successfully completed......................................
2023-06-14 12:48:25,316:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:25,316:INFO:Creating metrics dataframe
2023-06-14 12:48:25,320:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 12:48:25,320:INFO:Total runtime is 0.4567211906115214 minutes
2023-06-14 12:48:25,320:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:25,321:INFO:Initializing create_model()
2023-06-14 12:48:25,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:25,321:INFO:Checking exceptions
2023-06-14 12:48:25,321:INFO:Importing libraries
2023-06-14 12:48:25,321:INFO:Copying training dataset
2023-06-14 12:48:25,326:INFO:Defining folds
2023-06-14 12:48:25,326:INFO:Declaring metric variables
2023-06-14 12:48:25,326:INFO:Importing untrained model
2023-06-14 12:48:25,326:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 12:48:25,328:INFO:Starting cross validation
2023-06-14 12:48:25,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:28,424:INFO:Calculating mean and std
2023-06-14 12:48:28,425:INFO:Creating metrics dataframe
2023-06-14 12:48:28,829:INFO:Uploading results into container
2023-06-14 12:48:28,830:INFO:Uploading model into container now
2023-06-14 12:48:28,831:INFO:_master_model_container: 7
2023-06-14 12:48:28,831:INFO:_display_container: 2
2023-06-14 12:48:28,831:INFO:OrthogonalMatchingPursuit()
2023-06-14 12:48:28,831:INFO:create_model() successfully completed......................................
2023-06-14 12:48:28,889:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:28,889:INFO:Creating metrics dataframe
2023-06-14 12:48:28,893:INFO:Initializing Bayesian Ridge
2023-06-14 12:48:28,894:INFO:Total runtime is 0.5162816166877746 minutes
2023-06-14 12:48:28,894:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:28,894:INFO:Initializing create_model()
2023-06-14 12:48:28,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:28,894:INFO:Checking exceptions
2023-06-14 12:48:28,894:INFO:Importing libraries
2023-06-14 12:48:28,894:INFO:Copying training dataset
2023-06-14 12:48:28,898:INFO:Defining folds
2023-06-14 12:48:28,898:INFO:Declaring metric variables
2023-06-14 12:48:28,899:INFO:Importing untrained model
2023-06-14 12:48:28,899:INFO:Bayesian Ridge Imported successfully
2023-06-14 12:48:28,899:INFO:Starting cross validation
2023-06-14 12:48:28,901:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:32,046:INFO:Calculating mean and std
2023-06-14 12:48:32,046:INFO:Creating metrics dataframe
2023-06-14 12:48:32,454:INFO:Uploading results into container
2023-06-14 12:48:32,454:INFO:Uploading model into container now
2023-06-14 12:48:32,455:INFO:_master_model_container: 8
2023-06-14 12:48:32,455:INFO:_display_container: 2
2023-06-14 12:48:32,455:INFO:BayesianRidge()
2023-06-14 12:48:32,455:INFO:create_model() successfully completed......................................
2023-06-14 12:48:32,516:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:32,516:INFO:Creating metrics dataframe
2023-06-14 12:48:32,520:INFO:Initializing Passive Aggressive Regressor
2023-06-14 12:48:32,521:INFO:Total runtime is 0.5767290075620015 minutes
2023-06-14 12:48:32,521:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:32,521:INFO:Initializing create_model()
2023-06-14 12:48:32,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:32,521:INFO:Checking exceptions
2023-06-14 12:48:32,521:INFO:Importing libraries
2023-06-14 12:48:32,521:INFO:Copying training dataset
2023-06-14 12:48:32,526:INFO:Defining folds
2023-06-14 12:48:32,526:INFO:Declaring metric variables
2023-06-14 12:48:32,526:INFO:Importing untrained model
2023-06-14 12:48:32,526:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 12:48:32,527:INFO:Starting cross validation
2023-06-14 12:48:32,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:35,621:INFO:Calculating mean and std
2023-06-14 12:48:35,622:INFO:Creating metrics dataframe
2023-06-14 12:48:36,011:INFO:Uploading results into container
2023-06-14 12:48:36,011:INFO:Uploading model into container now
2023-06-14 12:48:36,012:INFO:_master_model_container: 9
2023-06-14 12:48:36,012:INFO:_display_container: 2
2023-06-14 12:48:36,012:INFO:PassiveAggressiveRegressor(random_state=1372)
2023-06-14 12:48:36,012:INFO:create_model() successfully completed......................................
2023-06-14 12:48:36,070:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:36,071:INFO:Creating metrics dataframe
2023-06-14 12:48:36,075:INFO:Initializing Huber Regressor
2023-06-14 12:48:36,075:INFO:Total runtime is 0.6359596610069275 minutes
2023-06-14 12:48:36,076:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:36,076:INFO:Initializing create_model()
2023-06-14 12:48:36,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:36,076:INFO:Checking exceptions
2023-06-14 12:48:36,076:INFO:Importing libraries
2023-06-14 12:48:36,076:INFO:Copying training dataset
2023-06-14 12:48:36,082:INFO:Defining folds
2023-06-14 12:48:36,082:INFO:Declaring metric variables
2023-06-14 12:48:36,082:INFO:Importing untrained model
2023-06-14 12:48:36,082:INFO:Huber Regressor Imported successfully
2023-06-14 12:48:36,083:INFO:Starting cross validation
2023-06-14 12:48:36,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:36,407:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:48:36,419:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:48:36,435:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:48:36,445:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:48:37,666:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:48:39,664:INFO:Calculating mean and std
2023-06-14 12:48:39,665:INFO:Creating metrics dataframe
2023-06-14 12:48:40,058:INFO:Uploading results into container
2023-06-14 12:48:40,058:INFO:Uploading model into container now
2023-06-14 12:48:40,058:INFO:_master_model_container: 10
2023-06-14 12:48:40,059:INFO:_display_container: 2
2023-06-14 12:48:40,059:INFO:HuberRegressor()
2023-06-14 12:48:40,059:INFO:create_model() successfully completed......................................
2023-06-14 12:48:40,116:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:40,116:INFO:Creating metrics dataframe
2023-06-14 12:48:40,122:INFO:Initializing K Neighbors Regressor
2023-06-14 12:48:40,122:INFO:Total runtime is 0.7034135341644286 minutes
2023-06-14 12:48:40,122:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:40,122:INFO:Initializing create_model()
2023-06-14 12:48:40,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:40,122:INFO:Checking exceptions
2023-06-14 12:48:40,122:INFO:Importing libraries
2023-06-14 12:48:40,122:INFO:Copying training dataset
2023-06-14 12:48:40,128:INFO:Defining folds
2023-06-14 12:48:40,128:INFO:Declaring metric variables
2023-06-14 12:48:40,128:INFO:Importing untrained model
2023-06-14 12:48:40,128:INFO:K Neighbors Regressor Imported successfully
2023-06-14 12:48:40,128:INFO:Starting cross validation
2023-06-14 12:48:40,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:43,370:INFO:Calculating mean and std
2023-06-14 12:48:43,371:INFO:Creating metrics dataframe
2023-06-14 12:48:43,775:INFO:Uploading results into container
2023-06-14 12:48:43,776:INFO:Uploading model into container now
2023-06-14 12:48:43,776:INFO:_master_model_container: 11
2023-06-14 12:48:43,776:INFO:_display_container: 2
2023-06-14 12:48:43,776:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 12:48:43,776:INFO:create_model() successfully completed......................................
2023-06-14 12:48:43,835:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:43,835:INFO:Creating metrics dataframe
2023-06-14 12:48:43,840:INFO:Initializing Decision Tree Regressor
2023-06-14 12:48:43,840:INFO:Total runtime is 0.7653828938802083 minutes
2023-06-14 12:48:43,840:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:43,841:INFO:Initializing create_model()
2023-06-14 12:48:43,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:43,841:INFO:Checking exceptions
2023-06-14 12:48:43,841:INFO:Importing libraries
2023-06-14 12:48:43,841:INFO:Copying training dataset
2023-06-14 12:48:43,846:INFO:Defining folds
2023-06-14 12:48:43,846:INFO:Declaring metric variables
2023-06-14 12:48:43,846:INFO:Importing untrained model
2023-06-14 12:48:43,846:INFO:Decision Tree Regressor Imported successfully
2023-06-14 12:48:43,846:INFO:Starting cross validation
2023-06-14 12:48:43,848:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:46,956:INFO:Calculating mean and std
2023-06-14 12:48:46,957:INFO:Creating metrics dataframe
2023-06-14 12:48:47,354:INFO:Uploading results into container
2023-06-14 12:48:47,354:INFO:Uploading model into container now
2023-06-14 12:48:47,355:INFO:_master_model_container: 12
2023-06-14 12:48:47,355:INFO:_display_container: 2
2023-06-14 12:48:47,355:INFO:DecisionTreeRegressor(random_state=1372)
2023-06-14 12:48:47,355:INFO:create_model() successfully completed......................................
2023-06-14 12:48:47,417:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:47,417:INFO:Creating metrics dataframe
2023-06-14 12:48:47,421:INFO:Initializing Random Forest Regressor
2023-06-14 12:48:47,421:INFO:Total runtime is 0.8250622510910034 minutes
2023-06-14 12:48:47,421:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:47,422:INFO:Initializing create_model()
2023-06-14 12:48:47,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:47,422:INFO:Checking exceptions
2023-06-14 12:48:47,422:INFO:Importing libraries
2023-06-14 12:48:47,422:INFO:Copying training dataset
2023-06-14 12:48:47,428:INFO:Defining folds
2023-06-14 12:48:47,428:INFO:Declaring metric variables
2023-06-14 12:48:47,428:INFO:Importing untrained model
2023-06-14 12:48:47,428:INFO:Random Forest Regressor Imported successfully
2023-06-14 12:48:47,428:INFO:Starting cross validation
2023-06-14 12:48:47,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:48,858:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:48:48,858:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:48:52,322:INFO:Calculating mean and std
2023-06-14 12:48:52,322:INFO:Creating metrics dataframe
2023-06-14 12:48:52,736:INFO:Uploading results into container
2023-06-14 12:48:52,738:INFO:Uploading model into container now
2023-06-14 12:48:52,738:INFO:_master_model_container: 13
2023-06-14 12:48:52,738:INFO:_display_container: 2
2023-06-14 12:48:52,738:INFO:RandomForestRegressor(n_jobs=-1, random_state=1372)
2023-06-14 12:48:52,738:INFO:create_model() successfully completed......................................
2023-06-14 12:48:52,796:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:52,796:INFO:Creating metrics dataframe
2023-06-14 12:48:52,800:INFO:Initializing Extra Trees Regressor
2023-06-14 12:48:52,801:INFO:Total runtime is 0.9147255619366963 minutes
2023-06-14 12:48:52,801:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:52,801:INFO:Initializing create_model()
2023-06-14 12:48:52,801:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:52,801:INFO:Checking exceptions
2023-06-14 12:48:52,801:INFO:Importing libraries
2023-06-14 12:48:52,801:INFO:Copying training dataset
2023-06-14 12:48:52,806:INFO:Defining folds
2023-06-14 12:48:52,806:INFO:Declaring metric variables
2023-06-14 12:48:52,806:INFO:Importing untrained model
2023-06-14 12:48:52,807:INFO:Extra Trees Regressor Imported successfully
2023-06-14 12:48:52,807:INFO:Starting cross validation
2023-06-14 12:48:52,808:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:48:54,109:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:48:54,126:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:48:54,131:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:48:57,495:INFO:Calculating mean and std
2023-06-14 12:48:57,495:INFO:Creating metrics dataframe
2023-06-14 12:48:57,904:INFO:Uploading results into container
2023-06-14 12:48:57,904:INFO:Uploading model into container now
2023-06-14 12:48:57,904:INFO:_master_model_container: 14
2023-06-14 12:48:57,904:INFO:_display_container: 2
2023-06-14 12:48:57,904:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1372)
2023-06-14 12:48:57,904:INFO:create_model() successfully completed......................................
2023-06-14 12:48:57,963:INFO:SubProcess create_model() end ==================================
2023-06-14 12:48:57,963:INFO:Creating metrics dataframe
2023-06-14 12:48:57,967:INFO:Initializing AdaBoost Regressor
2023-06-14 12:48:57,967:INFO:Total runtime is 1.00082604487737 minutes
2023-06-14 12:48:57,967:INFO:SubProcess create_model() called ==================================
2023-06-14 12:48:57,968:INFO:Initializing create_model()
2023-06-14 12:48:57,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:48:57,968:INFO:Checking exceptions
2023-06-14 12:48:57,968:INFO:Importing libraries
2023-06-14 12:48:57,968:INFO:Copying training dataset
2023-06-14 12:48:57,972:INFO:Defining folds
2023-06-14 12:48:57,972:INFO:Declaring metric variables
2023-06-14 12:48:57,972:INFO:Importing untrained model
2023-06-14 12:48:57,972:INFO:AdaBoost Regressor Imported successfully
2023-06-14 12:48:57,972:INFO:Starting cross validation
2023-06-14 12:48:57,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:01,996:INFO:Calculating mean and std
2023-06-14 12:49:01,996:INFO:Creating metrics dataframe
2023-06-14 12:49:02,412:INFO:Uploading results into container
2023-06-14 12:49:02,413:INFO:Uploading model into container now
2023-06-14 12:49:02,413:INFO:_master_model_container: 15
2023-06-14 12:49:02,413:INFO:_display_container: 2
2023-06-14 12:49:02,414:INFO:AdaBoostRegressor(random_state=1372)
2023-06-14 12:49:02,414:INFO:create_model() successfully completed......................................
2023-06-14 12:49:02,473:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:02,473:INFO:Creating metrics dataframe
2023-06-14 12:49:02,478:INFO:Initializing Gradient Boosting Regressor
2023-06-14 12:49:02,478:INFO:Total runtime is 1.076011017958323 minutes
2023-06-14 12:49:02,478:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:02,478:INFO:Initializing create_model()
2023-06-14 12:49:02,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:02,478:INFO:Checking exceptions
2023-06-14 12:49:02,478:INFO:Importing libraries
2023-06-14 12:49:02,478:INFO:Copying training dataset
2023-06-14 12:49:02,482:INFO:Defining folds
2023-06-14 12:49:02,482:INFO:Declaring metric variables
2023-06-14 12:49:02,482:INFO:Importing untrained model
2023-06-14 12:49:02,483:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 12:49:02,483:INFO:Starting cross validation
2023-06-14 12:49:02,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:06,774:INFO:Calculating mean and std
2023-06-14 12:49:06,774:INFO:Creating metrics dataframe
2023-06-14 12:49:07,206:INFO:Uploading results into container
2023-06-14 12:49:07,206:INFO:Uploading model into container now
2023-06-14 12:49:07,207:INFO:_master_model_container: 16
2023-06-14 12:49:07,207:INFO:_display_container: 2
2023-06-14 12:49:07,207:INFO:GradientBoostingRegressor(random_state=1372)
2023-06-14 12:49:07,207:INFO:create_model() successfully completed......................................
2023-06-14 12:49:07,266:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:07,266:INFO:Creating metrics dataframe
2023-06-14 12:49:07,270:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 12:49:07,270:INFO:Total runtime is 1.155888032913208 minutes
2023-06-14 12:49:07,270:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:07,270:INFO:Initializing create_model()
2023-06-14 12:49:07,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:07,270:INFO:Checking exceptions
2023-06-14 12:49:07,270:INFO:Importing libraries
2023-06-14 12:49:07,271:INFO:Copying training dataset
2023-06-14 12:49:07,275:INFO:Defining folds
2023-06-14 12:49:07,275:INFO:Declaring metric variables
2023-06-14 12:49:07,275:INFO:Importing untrained model
2023-06-14 12:49:07,276:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 12:49:07,276:INFO:Starting cross validation
2023-06-14 12:49:07,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:10,789:INFO:Calculating mean and std
2023-06-14 12:49:10,789:INFO:Creating metrics dataframe
2023-06-14 12:49:11,218:INFO:Uploading results into container
2023-06-14 12:49:11,218:INFO:Uploading model into container now
2023-06-14 12:49:11,219:INFO:_master_model_container: 17
2023-06-14 12:49:11,219:INFO:_display_container: 2
2023-06-14 12:49:11,219:INFO:LGBMRegressor(random_state=1372)
2023-06-14 12:49:11,219:INFO:create_model() successfully completed......................................
2023-06-14 12:49:11,280:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:11,281:INFO:Creating metrics dataframe
2023-06-14 12:49:11,285:INFO:Initializing Dummy Regressor
2023-06-14 12:49:11,285:INFO:Total runtime is 1.222808067003886 minutes
2023-06-14 12:49:11,285:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:11,285:INFO:Initializing create_model()
2023-06-14 12:49:11,285:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E985B55150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:11,286:INFO:Checking exceptions
2023-06-14 12:49:11,286:INFO:Importing libraries
2023-06-14 12:49:11,286:INFO:Copying training dataset
2023-06-14 12:49:11,292:INFO:Defining folds
2023-06-14 12:49:11,292:INFO:Declaring metric variables
2023-06-14 12:49:11,293:INFO:Importing untrained model
2023-06-14 12:49:11,293:INFO:Dummy Regressor Imported successfully
2023-06-14 12:49:11,293:INFO:Starting cross validation
2023-06-14 12:49:11,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:14,557:INFO:Calculating mean and std
2023-06-14 12:49:14,558:INFO:Creating metrics dataframe
2023-06-14 12:49:14,981:INFO:Uploading results into container
2023-06-14 12:49:14,982:INFO:Uploading model into container now
2023-06-14 12:49:14,982:INFO:_master_model_container: 18
2023-06-14 12:49:14,982:INFO:_display_container: 2
2023-06-14 12:49:14,982:INFO:DummyRegressor()
2023-06-14 12:49:14,982:INFO:create_model() successfully completed......................................
2023-06-14 12:49:15,041:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:15,041:INFO:Creating metrics dataframe
2023-06-14 12:49:15,047:INFO:Initializing create_model()
2023-06-14 12:49:15,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E985A2AB90>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=1372), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:15,047:INFO:Checking exceptions
2023-06-14 12:49:15,048:INFO:Importing libraries
2023-06-14 12:49:15,048:INFO:Copying training dataset
2023-06-14 12:49:15,052:INFO:Defining folds
2023-06-14 12:49:15,052:INFO:Declaring metric variables
2023-06-14 12:49:15,052:INFO:Importing untrained model
2023-06-14 12:49:15,053:INFO:Declaring custom model
2023-06-14 12:49:15,053:INFO:Extra Trees Regressor Imported successfully
2023-06-14 12:49:15,055:INFO:Cross validation set to False
2023-06-14 12:49:15,055:INFO:Fitting Model
2023-06-14 12:49:15,831:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1372)
2023-06-14 12:49:15,831:INFO:create_model() successfully completed......................................
2023-06-14 12:49:15,904:INFO:_master_model_container: 18
2023-06-14 12:49:15,904:INFO:_display_container: 2
2023-06-14 12:49:15,904:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1372)
2023-06-14 12:49:15,904:INFO:compare_models() successfully completed......................................
2023-06-14 12:49:18,109:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:49:18,109:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:49:18,109:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:49:18,109:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:49:18,543:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:49:19,374:INFO:PyCaret RegressionExperiment
2023-06-14 12:49:19,374:INFO:Logging name: reg-default-name
2023-06-14 12:49:19,374:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 12:49:19,374:INFO:version 3.0.2
2023-06-14 12:49:19,374:INFO:Initializing setup()
2023-06-14 12:49:19,374:INFO:self.USI: 3b00
2023-06-14 12:49:19,374:INFO:self._variable_keys: {'idx', 'log_plots_param', 'seed', 'USI', 'pipeline', 'html_param', 'gpu_n_jobs_param', 'target_param', 'y_train', '_ml_usecase', 'exp_name_log', 'transform_target_param', 'X', 'y', 'fold_generator', 'fold_shuffle_param', 'exp_id', 'memory', '_available_plots', 'y_test', 'fold_groups_param', 'X_train', 'gpu_param', 'data', 'logging_param', 'X_test', 'n_jobs_param'}
2023-06-14 12:49:19,374:INFO:Checking environment
2023-06-14 12:49:19,374:INFO:python_version: 3.10.11
2023-06-14 12:49:19,374:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-06-14 12:49:19,374:INFO:machine: AMD64
2023-06-14 12:49:19,386:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 12:49:19,392:INFO:Memory: svmem(total=17013329920, available=2481385472, percent=85.4, used=14531944448, free=2481385472)
2023-06-14 12:49:19,392:INFO:Physical Core: 4
2023-06-14 12:49:19,392:INFO:Logical Core: 8
2023-06-14 12:49:19,392:INFO:Checking libraries
2023-06-14 12:49:19,392:INFO:System:
2023-06-14 12:49:19,392:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-06-14 12:49:19,392:INFO:executable: E:\Machine learning\mini\adam\Scripts\python.exe
2023-06-14 12:49:19,392:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 12:49:19,392:INFO:PyCaret required dependencies:
2023-06-14 12:49:19,392:INFO:                 pip: 23.0.1
2023-06-14 12:49:19,393:INFO:          setuptools: 65.5.0
2023-06-14 12:49:19,393:INFO:             pycaret: 3.0.2
2023-06-14 12:49:19,393:INFO:             IPython: 8.14.0
2023-06-14 12:49:19,393:INFO:          ipywidgets: 8.0.6
2023-06-14 12:49:19,393:INFO:                tqdm: 4.65.0
2023-06-14 12:49:19,393:INFO:               numpy: 1.23.5
2023-06-14 12:49:19,393:INFO:              pandas: 1.5.3
2023-06-14 12:49:19,393:INFO:              jinja2: 3.1.2
2023-06-14 12:49:19,393:INFO:               scipy: 1.10.1
2023-06-14 12:49:19,393:INFO:              joblib: 1.2.0
2023-06-14 12:49:19,393:INFO:             sklearn: 1.2.2
2023-06-14 12:49:19,393:INFO:                pyod: 1.0.9
2023-06-14 12:49:19,393:INFO:            imblearn: 0.10.1
2023-06-14 12:49:19,393:INFO:   category_encoders: 2.6.1
2023-06-14 12:49:19,393:INFO:            lightgbm: 3.3.5
2023-06-14 12:49:19,393:INFO:               numba: 0.57.0
2023-06-14 12:49:19,393:INFO:            requests: 2.31.0
2023-06-14 12:49:19,393:INFO:          matplotlib: 3.7.1
2023-06-14 12:49:19,393:INFO:          scikitplot: 0.3.7
2023-06-14 12:49:19,393:INFO:         yellowbrick: 1.5
2023-06-14 12:49:19,393:INFO:              plotly: 5.15.0
2023-06-14 12:49:19,393:INFO:             kaleido: 0.2.1
2023-06-14 12:49:19,393:INFO:         statsmodels: 0.14.0
2023-06-14 12:49:19,393:INFO:              sktime: 0.17.0
2023-06-14 12:49:19,393:INFO:               tbats: 1.1.3
2023-06-14 12:49:19,393:INFO:            pmdarima: 2.0.3
2023-06-14 12:49:19,394:INFO:              psutil: 5.9.5
2023-06-14 12:49:19,394:INFO:PyCaret optional dependencies:
2023-06-14 12:49:19,406:INFO:                shap: Not installed
2023-06-14 12:49:19,406:INFO:           interpret: Not installed
2023-06-14 12:49:19,406:INFO:                umap: Not installed
2023-06-14 12:49:19,406:INFO:    pandas_profiling: Not installed
2023-06-14 12:49:19,406:INFO:  explainerdashboard: Not installed
2023-06-14 12:49:19,406:INFO:             autoviz: Not installed
2023-06-14 12:49:19,406:INFO:           fairlearn: Not installed
2023-06-14 12:49:19,406:INFO:             xgboost: Not installed
2023-06-14 12:49:19,406:INFO:            catboost: Not installed
2023-06-14 12:49:19,406:INFO:              kmodes: Not installed
2023-06-14 12:49:19,406:INFO:             mlxtend: Not installed
2023-06-14 12:49:19,406:INFO:       statsforecast: Not installed
2023-06-14 12:49:19,406:INFO:        tune_sklearn: Not installed
2023-06-14 12:49:19,406:INFO:                 ray: Not installed
2023-06-14 12:49:19,406:INFO:            hyperopt: Not installed
2023-06-14 12:49:19,406:INFO:              optuna: Not installed
2023-06-14 12:49:19,406:INFO:               skopt: Not installed
2023-06-14 12:49:19,406:INFO:              mlflow: Not installed
2023-06-14 12:49:19,406:INFO:              gradio: Not installed
2023-06-14 12:49:19,406:INFO:             fastapi: Not installed
2023-06-14 12:49:19,406:INFO:             uvicorn: Not installed
2023-06-14 12:49:19,406:INFO:              m2cgen: Not installed
2023-06-14 12:49:19,406:INFO:           evidently: Not installed
2023-06-14 12:49:19,406:INFO:               fugue: Not installed
2023-06-14 12:49:19,406:INFO:           streamlit: Not installed
2023-06-14 12:49:19,406:INFO:             prophet: Not installed
2023-06-14 12:49:19,406:INFO:None
2023-06-14 12:49:19,406:INFO:Set up data.
2023-06-14 12:49:19,560:INFO:Set up train/test split.
2023-06-14 12:49:19,569:INFO:Set up index.
2023-06-14 12:49:19,569:INFO:Set up folding strategy.
2023-06-14 12:49:19,569:INFO:Assigning column types.
2023-06-14 12:49:19,575:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 12:49:19,575:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,583:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,598:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,665:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:19,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:19,718:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,723:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,727:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,781:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,823:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:19,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:19,825:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 12:49:19,829:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,833:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,886:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,930:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:19,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:19,935:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,939:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:49:19,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,034:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,035:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 12:49:20,043:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,096:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,138:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,147:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,250:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 12:49:20,312:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,461:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 12:49:20,523:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,564:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,564:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,628:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:49:20,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,676:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 12:49:20,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:20,882:INFO:Preparing preprocessing pipeline...
2023-06-14 12:49:20,882:INFO:Set up simple imputation.
2023-06-14 12:49:20,925:INFO:Finished creating preprocessing pipeline.
2023-06-14 12:49:20,932:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\adamr\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bid_amount', '0', '1', '2', '3',
                                             '4', '5', '6', '7', '8', '9', '10',
                                             '11', '12', '13', '14', '15', '16',
                                             '17', '18', '19', '20', '21', '22',
                                             '23', '24', '25', '26', '27', '28', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-06-14 12:49:20,932:INFO:Creating final display dataframe.
2023-06-14 12:49:21,104:INFO:Setup _display_container:                     Description             Value
0                    Session id              8628
1                        Target    combined_score
2                   Target type        Regression
3           Original data shape        (211, 597)
4        Transformed data shape        (211, 597)
5   Transformed train set shape        (147, 597)
6    Transformed test set shape         (64, 597)
7              Numeric features               596
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              3b00
2023-06-14 12:49:21,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:21,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:21,365:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:21,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:49:21,366:INFO:setup() successfully completed in 2.28s...............
2023-06-14 12:49:21,366:INFO:Initializing compare_models()
2023-06-14 12:49:21,366:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 12:49:21,366:INFO:Checking exceptions
2023-06-14 12:49:21,368:INFO:Preparing display monitor
2023-06-14 12:49:21,371:INFO:Initializing Linear Regression
2023-06-14 12:49:21,371:INFO:Total runtime is 0.0 minutes
2023-06-14 12:49:21,371:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:21,371:INFO:Initializing create_model()
2023-06-14 12:49:21,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:21,372:INFO:Checking exceptions
2023-06-14 12:49:21,372:INFO:Importing libraries
2023-06-14 12:49:21,372:INFO:Copying training dataset
2023-06-14 12:49:21,377:INFO:Defining folds
2023-06-14 12:49:21,377:INFO:Declaring metric variables
2023-06-14 12:49:21,377:INFO:Importing untrained model
2023-06-14 12:49:21,377:INFO:Linear Regression Imported successfully
2023-06-14 12:49:21,378:INFO:Starting cross validation
2023-06-14 12:49:21,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:27,355:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 12:49:30,267:INFO:Calculating mean and std
2023-06-14 12:49:30,268:INFO:Creating metrics dataframe
2023-06-14 12:49:30,683:INFO:Uploading results into container
2023-06-14 12:49:30,684:INFO:Uploading model into container now
2023-06-14 12:49:30,684:INFO:_master_model_container: 1
2023-06-14 12:49:30,684:INFO:_display_container: 2
2023-06-14 12:49:30,684:INFO:LinearRegression(n_jobs=-1)
2023-06-14 12:49:30,685:INFO:create_model() successfully completed......................................
2023-06-14 12:49:30,744:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:30,744:INFO:Creating metrics dataframe
2023-06-14 12:49:30,749:INFO:Initializing Lasso Regression
2023-06-14 12:49:30,749:INFO:Total runtime is 0.15629122257232667 minutes
2023-06-14 12:49:30,749:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:30,749:INFO:Initializing create_model()
2023-06-14 12:49:30,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:30,749:INFO:Checking exceptions
2023-06-14 12:49:30,749:INFO:Importing libraries
2023-06-14 12:49:30,749:INFO:Copying training dataset
2023-06-14 12:49:30,754:INFO:Defining folds
2023-06-14 12:49:30,754:INFO:Declaring metric variables
2023-06-14 12:49:30,754:INFO:Importing untrained model
2023-06-14 12:49:30,754:INFO:Lasso Regression Imported successfully
2023-06-14 12:49:30,755:INFO:Starting cross validation
2023-06-14 12:49:30,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:34,024:INFO:Calculating mean and std
2023-06-14 12:49:34,025:INFO:Creating metrics dataframe
2023-06-14 12:49:34,448:INFO:Uploading results into container
2023-06-14 12:49:34,448:INFO:Uploading model into container now
2023-06-14 12:49:34,449:INFO:_master_model_container: 2
2023-06-14 12:49:34,449:INFO:_display_container: 2
2023-06-14 12:49:34,449:INFO:Lasso(random_state=8628)
2023-06-14 12:49:34,449:INFO:create_model() successfully completed......................................
2023-06-14 12:49:34,508:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:34,509:INFO:Creating metrics dataframe
2023-06-14 12:49:34,512:INFO:Initializing Ridge Regression
2023-06-14 12:49:34,513:INFO:Total runtime is 0.21902875900268554 minutes
2023-06-14 12:49:34,513:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:34,513:INFO:Initializing create_model()
2023-06-14 12:49:34,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:34,513:INFO:Checking exceptions
2023-06-14 12:49:34,513:INFO:Importing libraries
2023-06-14 12:49:34,513:INFO:Copying training dataset
2023-06-14 12:49:34,518:INFO:Defining folds
2023-06-14 12:49:34,518:INFO:Declaring metric variables
2023-06-14 12:49:34,518:INFO:Importing untrained model
2023-06-14 12:49:34,519:INFO:Ridge Regression Imported successfully
2023-06-14 12:49:34,519:INFO:Starting cross validation
2023-06-14 12:49:34,521:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:37,741:INFO:Calculating mean and std
2023-06-14 12:49:37,742:INFO:Creating metrics dataframe
2023-06-14 12:49:38,153:INFO:Uploading results into container
2023-06-14 12:49:38,153:INFO:Uploading model into container now
2023-06-14 12:49:38,155:INFO:_master_model_container: 3
2023-06-14 12:49:38,155:INFO:_display_container: 2
2023-06-14 12:49:38,155:INFO:Ridge(random_state=8628)
2023-06-14 12:49:38,155:INFO:create_model() successfully completed......................................
2023-06-14 12:49:38,213:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:38,213:INFO:Creating metrics dataframe
2023-06-14 12:49:38,217:INFO:Initializing Elastic Net
2023-06-14 12:49:38,217:INFO:Total runtime is 0.28075551986694336 minutes
2023-06-14 12:49:38,218:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:38,218:INFO:Initializing create_model()
2023-06-14 12:49:38,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:38,218:INFO:Checking exceptions
2023-06-14 12:49:38,218:INFO:Importing libraries
2023-06-14 12:49:38,218:INFO:Copying training dataset
2023-06-14 12:49:38,223:INFO:Defining folds
2023-06-14 12:49:38,223:INFO:Declaring metric variables
2023-06-14 12:49:38,224:INFO:Importing untrained model
2023-06-14 12:49:38,224:INFO:Elastic Net Imported successfully
2023-06-14 12:49:38,224:INFO:Starting cross validation
2023-06-14 12:49:38,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:41,417:INFO:Calculating mean and std
2023-06-14 12:49:41,417:INFO:Creating metrics dataframe
2023-06-14 12:49:41,831:INFO:Uploading results into container
2023-06-14 12:49:41,831:INFO:Uploading model into container now
2023-06-14 12:49:41,832:INFO:_master_model_container: 4
2023-06-14 12:49:41,832:INFO:_display_container: 2
2023-06-14 12:49:41,832:INFO:ElasticNet(random_state=8628)
2023-06-14 12:49:41,832:INFO:create_model() successfully completed......................................
2023-06-14 12:49:41,890:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:41,890:INFO:Creating metrics dataframe
2023-06-14 12:49:41,894:INFO:Initializing Least Angle Regression
2023-06-14 12:49:41,894:INFO:Total runtime is 0.34204833904902143 minutes
2023-06-14 12:49:41,894:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:41,894:INFO:Initializing create_model()
2023-06-14 12:49:41,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:41,894:INFO:Checking exceptions
2023-06-14 12:49:41,894:INFO:Importing libraries
2023-06-14 12:49:41,894:INFO:Copying training dataset
2023-06-14 12:49:41,900:INFO:Defining folds
2023-06-14 12:49:41,900:INFO:Declaring metric variables
2023-06-14 12:49:41,900:INFO:Importing untrained model
2023-06-14 12:49:41,900:INFO:Least Angle Regression Imported successfully
2023-06-14 12:49:41,901:INFO:Starting cross validation
2023-06-14 12:49:41,903:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:42,057:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.366e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.536e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,058:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.366e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,059:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=7.152e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,059:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=6.468e-01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,059:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.441e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,064:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=6.710e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,064:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=6.710e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,067:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.631e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,067:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.631e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,070:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=6.395e-01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,070:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=6.395e-01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,074:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=3.409e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,077:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.280e+00, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.273e+00, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.264e+00, with an active set of 79 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.250e+00, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=3.364e-01, with an active set of 92 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,079:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=8.192e-01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.634e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,080:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=8.148e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.634e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,081:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.464e-01, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,082:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.271e-01, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,083:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.037e+00, with an active set of 59 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,084:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=9.669e-01, with an active set of 59 regressors, and the smallest cholesky pivot element being 9.395e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,085:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=6.680e-01, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,085:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=3.844e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,085:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.342e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=6.673e-01, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=6.673e-01, with an active set of 109 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=3.816e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,088:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=6.664e-01, with an active set of 109 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,088:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=8.634e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,089:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=6.498e-01, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,089:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=8.627e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,089:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=8.627e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,090:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=6.417e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,090:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=5.942e-01, with an active set of 56 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,095:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.625e-01, with an active set of 47 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,095:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.774e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,096:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.595e+00, with an active set of 106 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,099:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=9.798e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 9.454e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,100:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=9.540e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 9.454e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,101:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.865e-01, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,102:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.124e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,103:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.701e-01, with an active set of 79 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.018e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.843e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,105:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.810e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 8.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,105:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.772e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,109:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.400e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,109:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=6.062e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,110:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=4.554e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,112:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=3.108e-01, with an active set of 94 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,118:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.654e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,118:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.352e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,118:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.340e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.277e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.719e-01, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.189e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,119:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.047e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,120:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.011e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,120:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=7.081e-01, with an active set of 109 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,121:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.906e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.622e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,121:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.832e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,122:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.805e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.132e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,122:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.805e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.321e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,123:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.776e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,124:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=7.078e-01, with an active set of 114 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,124:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=2.648e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,126:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=2.623e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,126:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=2.604e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,127:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=2.580e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,128:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=7.944e+00, with an active set of 111 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,128:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=2.536e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,128:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=4.080e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,128:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=2.460e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,129:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=2.428e+00, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,130:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=6.599e-01, with an active set of 110 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,132:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=7.974e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,134:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.031e+00, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,135:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=1.031e+00, with an active set of 117 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,137:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=8.962e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,139:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=3.808e-01, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,145:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=9.148e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,146:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.889e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.800e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,146:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=9.148e+00, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,146:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.532e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,146:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.524e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,148:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.510e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.242e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,148:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.481e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.970e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,148:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.445e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,149:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.400e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,149:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.348e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,150:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.343e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,150:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.340e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,151:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.337e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,151:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.337e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,151:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.337e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,152:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.316e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,152:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=1.274e+01, with an active set of 139 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,152:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.293e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.894e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,153:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.293e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.087e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,153:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.287e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.029e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,153:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.275e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.269e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.263e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=4.075e-01, with an active set of 115 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,154:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.198e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,155:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.193e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,155:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.186e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,156:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.176e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,156:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.163e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.925e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,156:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.157e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,157:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.147e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,158:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.145e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,158:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.141e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,158:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.121e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.554e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,158:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.112e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.744e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,159:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.102e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,159:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.092e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,159:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.084e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.512e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,160:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.079e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,160:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.067e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,161:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.065e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.969e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,161:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.063e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.086e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,162:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.028e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,162:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.027e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,163:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.002e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.099e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,163:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.867e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,163:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.810e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,164:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.802e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,164:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.730e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,165:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.639e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.660e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,165:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.417e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,166:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.194e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.800e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,166:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.186e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.321e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,166:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.148e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.927e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.843e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.920e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.909e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.365e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.770e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.357e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,168:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.748e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,168:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.702e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,168:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.570e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.536e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,169:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.560e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,169:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.552e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,169:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.437e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,170:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.434e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,170:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.342e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,170:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.322e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,171:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.296e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,171:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.204e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,172:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.197e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.744e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,172:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.188e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,173:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.148e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,173:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.022e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,173:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.003e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,174:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.901e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.328e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,174:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.879e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.726e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,175:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.868e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,175:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.848e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,175:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.836e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,175:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.801e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.785e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.800e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.748e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.677e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.655e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.652e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.398e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.257e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.224e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,179:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.170e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,179:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.156e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.075e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.819e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.846e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.261e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,181:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.836e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.782e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.182e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.723e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.720e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.705e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.691e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.608e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.410e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.377e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.264e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.211e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.128e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.043e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.165e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.021e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.998e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.794e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.737e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.094e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.710e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.551e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,189:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.667e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,189:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.663e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,190:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.571e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,190:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.456e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.423e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.374e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.638e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.327e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.660e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,193:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.255e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,193:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.234e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.228e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.222e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.194e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.161e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.035e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.478e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.035e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.918e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.007e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.669e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.990e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.943e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.930e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.264e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.925e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.920e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.899e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.865e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.200e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.848e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.834e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.622e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.808e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.696e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,201:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.684e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.554e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,201:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.631e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,201:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.545e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.454e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.504e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.660e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.464e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,203:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.464e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,203:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.425e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.135e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.411e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.375e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.302e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.285e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,206:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.266e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.166e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,206:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.219e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.874e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,206:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.218e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,207:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.152e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,207:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.152e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.343e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.141e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.133e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.485e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.075e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.057e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.010e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.986e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.961e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.924e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.902e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.894e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.861e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.827e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.347e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.807e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.343e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.774e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.704e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.698e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.681e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.669e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.645e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.607e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.580e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.183e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.450e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.434e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.421e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.631e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.411e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.385e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,220:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.381e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,220:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.379e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.328e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.204e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.295e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.285e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.513e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,222:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.209e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,222:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.182e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,223:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.099e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,223:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.037e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,224:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.981e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,224:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.980e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,225:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.934e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,225:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.927e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,226:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.892e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,226:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.789e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,227:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.763e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.674e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.595e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.534e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.536e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.530e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,231:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.525e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,231:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.445e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,231:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.339e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.320e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.298e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.281e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.239e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.238e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.209e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.206e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.157e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.123e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.106e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.084e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.069e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.060e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.051e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,238:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.046e-01, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.353e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.115e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,240:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.023e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.990e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,241:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.947e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,242:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.924e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,242:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.893e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,243:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.880e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,243:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.878e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,243:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.844e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.984e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,244:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.831e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,244:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.791e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,245:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.787e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,245:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.756e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.984e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,245:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.751e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,246:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.744e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,246:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.718e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,247:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.717e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,248:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.666e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,248:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.652e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,248:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.647e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,249:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.623e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.311e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,249:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.620e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,249:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.583e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,250:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.568e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.353e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.567e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.541e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.925e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,251:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.536e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,252:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.492e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,252:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.477e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.477e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,253:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.462e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,254:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.448e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,254:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.444e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.517e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,254:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.419e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,255:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.386e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,255:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.373e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,255:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.341e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.296e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.957e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.289e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.536e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.238e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.763e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.223e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,256:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.179e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,258:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.105e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,258:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.074e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,259:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.051e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,259:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.025e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,259:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.009e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,260:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.003e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,260:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.875e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,261:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.873e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,261:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.815e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,262:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.357e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,262:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.640e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,263:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.538e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.185e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,263:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.447e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,264:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.292e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,264:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.546e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.057e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,266:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.539e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,266:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.332e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,267:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.934e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,267:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.839e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,268:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.807e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,268:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.622e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,268:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.576e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,268:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.438e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,269:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.048e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,269:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.822e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,269:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.620e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.354e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.074e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,271:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.931e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,271:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.651e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,272:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.494e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,272:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.429e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.562e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,272:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.318e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.969e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,273:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.200e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,273:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.002e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,273:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.961e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,274:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.940e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,274:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.705e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.380e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,275:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.696e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,275:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.679e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,275:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.429e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,276:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.388e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,276:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.303e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,277:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.252e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.800e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,278:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.192e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,278:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.159e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,278:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.957e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.189e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,279:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.901e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.920e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,279:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.840e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,279:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.794e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.902e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.757e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.741e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.738e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.702e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.099e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,281:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.583e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,281:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.578e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,282:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.515e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,282:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.500e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,282:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.433e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,283:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.345e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,283:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.261e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,283:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.147e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.563e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,284:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.143e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,284:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.128e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,284:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.124e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.623e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,285:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.037e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,285:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.029e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,285:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.028e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,286:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.011e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.970e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,286:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.010e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,287:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.990e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,287:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.984e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,287:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.960e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,288:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.952e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,288:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.934e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,288:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.915e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,288:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.893e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,288:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.877e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,289:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.866e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.660e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,289:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.779e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,289:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.764e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.183e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,290:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.741e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.673e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,290:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.739e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,290:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.710e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,291:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.665e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,291:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.650e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.110e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,292:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.623e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,292:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.620e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,293:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.616e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,293:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.593e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,294:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.589e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,294:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.580e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,295:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.535e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.819e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,296:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.523e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,296:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.496e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.446e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,296:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.493e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,296:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.482e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,298:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.448e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,298:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.448e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,298:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.432e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.532e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,299:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.426e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,299:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.423e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.049e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,300:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.418e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,301:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.417e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,301:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.408e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,302:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.378e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,302:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.340e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,303:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.337e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,303:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.329e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,303:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.318e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,304:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.317e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,304:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.307e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,305:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.302e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,305:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.298e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,305:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.288e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,306:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.258e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.937e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,306:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.167e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,307:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.158e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.326e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,307:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.157e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,308:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.144e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,308:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.136e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,308:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.129e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,308:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.115e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,309:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.109e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,309:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.109e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,309:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.107e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,310:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.097e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,311:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.094e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,311:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.090e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,312:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.056e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,312:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.049e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,312:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.047e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,313:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.006e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,313:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.004e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,314:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.953e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,314:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.889e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,315:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.731e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,315:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.595e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,315:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.425e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,315:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.308e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.623e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,316:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.284e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,317:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.237e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,317:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.018e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.030e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,317:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.726e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.439e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,318:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.542e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,318:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.540e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,319:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.481e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,319:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.372e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.305e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,320:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.258e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,321:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.177e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,322:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.172e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.853e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,322:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.169e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,323:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.155e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,323:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.139e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,324:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.101e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,324:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.821e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,325:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.673e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,325:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.658e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.934e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,325:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.559e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.258e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,326:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.513e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,326:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.488e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,326:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.445e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,326:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.287e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,330:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.271e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,331:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.251e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,331:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.225e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,332:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.104e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,332:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.046e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,333:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.596e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,333:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.588e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.439e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,334:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.584e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.498e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,334:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.581e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,335:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.542e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.558e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,335:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.506e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,335:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.447e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,336:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.432e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,336:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.352e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.999e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,336:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.213e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,337:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.176e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,337:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.128e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,337:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.995e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.726e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.455e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.418e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.373e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,339:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.324e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,339:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.299e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,340:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.286e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.687e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,340:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.274e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,340:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.195e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,341:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.075e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,341:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.931e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.175e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,341:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.922e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,342:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.907e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,343:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.902e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,343:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.866e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,343:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.749e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,343:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.748e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,345:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.739e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,345:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.733e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,345:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.678e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,346:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.663e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,346:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.647e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,346:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.607e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.321e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,347:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.606e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.998e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,347:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.537e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,347:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.227e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.006e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,348:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.101e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,348:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.924e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.185e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,348:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.795e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,348:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.683e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.343e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,349:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.541e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,349:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.349e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,349:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.233e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,350:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.220e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,350:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.088e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,350:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.040e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,351:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.028e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,351:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.420e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,351:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.395e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,352:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.284e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,352:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.960e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,353:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.925e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,353:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.857e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,353:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.802e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,354:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.781e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,355:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.685e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,356:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.674e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,356:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.657e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,358:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.654e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.498e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,358:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.622e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,358:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.572e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,359:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.563e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,359:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.493e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.313e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,360:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.486e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,360:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.469e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,360:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.375e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,361:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.375e-03, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,361:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.838e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,361:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.319e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,361:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.065e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,361:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.236e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,362:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.087e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,362:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.438e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,362:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.151e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,363:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.744e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,363:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.558e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,363:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.292e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,364:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.282e-04, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:42,364:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.105e-05, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,782:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.392e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,784:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.343e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.061e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,795:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.402e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,799:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.372e+00, with an active set of 63 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,802:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.377e+00, with an active set of 68 regressors, and the smallest cholesky pivot element being 3.311e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,803:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=1.367e+00, with an active set of 69 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,806:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.320e+00, with an active set of 74 regressors, and the smallest cholesky pivot element being 3.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,808:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.306e+00, with an active set of 78 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,810:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.291e+00, with an active set of 81 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,812:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.282e+00, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,822:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=1.329e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,838:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=8.856e+00, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,848:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.083e+01, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,849:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.038e+01, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.500e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,850:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.843e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,850:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.651e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,850:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.582e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,851:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.451e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,851:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.440e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,852:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.259e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,852:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.967e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,852:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.439e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.532e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,853:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.398e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,853:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.397e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,853:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.324e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,854:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.273e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,854:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.197e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,855:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.917e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,855:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.874e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,855:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.767e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,856:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.659e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,856:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.657e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,857:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.592e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,857:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.504e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,858:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.391e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,858:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.379e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,859:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.347e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,859:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.291e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,859:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.115e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,859:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.095e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,860:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.090e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,860:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.058e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,861:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.995e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,861:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.911e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.727e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,861:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.873e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,862:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.686e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,862:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.580e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,862:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.530e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,863:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.357e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 6.757e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,863:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.244e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,864:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.183e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,864:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.156e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,864:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.102e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,865:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.042e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,865:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.025e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,866:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.932e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,866:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.921e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,866:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.891e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,867:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.890e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.888e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.772e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.621e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.030e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.599e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.577e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.463e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.431e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 8.847e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.403e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,871:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.388e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.204e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,871:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.384e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,872:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.355e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.594e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,872:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.353e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,873:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.060e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,873:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.032e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,873:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.988e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,874:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.932e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.928e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,874:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.887e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,874:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.687e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,875:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.670e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,875:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.656e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,875:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.621e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.543e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.500e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.509e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.501e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,877:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.492e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,877:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.491e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,877:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.428e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,877:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.383e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.202e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,877:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.365e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,879:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.352e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.047e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,879:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.349e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.914e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,880:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.347e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,880:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.280e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.857e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,880:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.202e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,881:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.198e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,881:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.154e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,881:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.040e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,882:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.946e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,882:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.888e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,882:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.869e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.838e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.825e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.809e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.787e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.779e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,885:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.769e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,885:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.701e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,886:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.699e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,886:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.609e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.861e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,886:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.607e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,887:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.568e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,888:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.551e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.061e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,888:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.536e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,888:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.499e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,888:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.491e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,889:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.472e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.326e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,889:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.449e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,889:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.401e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,890:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.391e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.182e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,890:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.358e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,890:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.316e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.645e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,891:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.301e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,891:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.297e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,892:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.294e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,892:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.282e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,892:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.241e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,894:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.234e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.763e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,894:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.201e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,894:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.200e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.199e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.167e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.166e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,896:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.159e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,896:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.144e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,896:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.122e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,897:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.117e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,897:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.111e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,897:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.050e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,898:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.008e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,898:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.007e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 9.155e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,898:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.005e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,899:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.963e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.631e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,899:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.911e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,899:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.904e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,900:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.820e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,900:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.797e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,901:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.790e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.400e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,901:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.711e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,902:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.654e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,902:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.654e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,902:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.641e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.844e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,903:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.618e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,903:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.612e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,903:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.581e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.439e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,903:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.544e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,904:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.519e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.813e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,904:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.491e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,904:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.473e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,905:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.441e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,905:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.416e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,905:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.405e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,906:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.353e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,906:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.340e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,907:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.328e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,907:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.306e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,908:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.271e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,908:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.206e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,908:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.188e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.910e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,909:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.158e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.727e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,910:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.144e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,911:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.130e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,911:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.084e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,911:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.075e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,912:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.054e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,912:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=2.024e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.813e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,913:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.938e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,913:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.923e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,913:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.904e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,914:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.894e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,914:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.880e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,914:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.873e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,914:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.859e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.820e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.809e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.369e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,915:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.759e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.734e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.728e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.703e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.699e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.634e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.590e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.576e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.562e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.523e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.518e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.518e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.510e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.508e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.502e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,920:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.482e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,920:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.476e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,920:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.467e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,921:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.451e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,921:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.410e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,921:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.408e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,922:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.400e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.937e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,922:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.377e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,922:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.376e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.362e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.359e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.356e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,924:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.350e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,924:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.342e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,924:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.260e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,925:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.252e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.903e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,925:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.246e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.890e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,925:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.235e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,927:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.224e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.844e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,927:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.209e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,927:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.196e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,927:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.196e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.181e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.170e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,928:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.159e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.150e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.141e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,929:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.140e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,930:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.128e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.813e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,930:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.110e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,930:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.104e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,931:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.082e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 6.969e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,931:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.077e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 6.099e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,931:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.063e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,932:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.054e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,932:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.054e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,932:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.039e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.032e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,933:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.003e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.369e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.925e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.895e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,935:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.880e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,935:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.762e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,935:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.653e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,936:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.533e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,936:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.471e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,937:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.405e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,937:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.395e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,937:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.353e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,937:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.258e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,939:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.224e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,939:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=9.216e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,939:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.973e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,939:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.793e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,939:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.745e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,939:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.736e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,940:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.684e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.006e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,940:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.661e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,941:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.555e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,941:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.278e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,941:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.866e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,941:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.687e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,942:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.479e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,942:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.431e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,942:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.237e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,942:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.236e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,942:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=7.200e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.912e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.841e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.728e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.615e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.936e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,945:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.421e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.554e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,945:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.349e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,945:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.209e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,946:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.167e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,946:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.753e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,946:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=5.179e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,946:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.977e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,947:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.740e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,947:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.659e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,947:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.612e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,948:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=4.196e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,948:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.833e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,949:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.447e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,949:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.233e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.006e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,951:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.159e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 4.312e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,951:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.120e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,951:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.109e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,952:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=2.948e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,953:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=2.684e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,953:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=2.446e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,954:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=2.189e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,954:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.868e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,954:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.734e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.645e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,955:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.639e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.513e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,955:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.378e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 6.189e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,955:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=1.163e-01, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,956:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=8.663e-02, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,956:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=8.102e-02, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,956:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=6.305e-02, with an active set of 133 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,957:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=5.657e-02, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:43,957:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=2.919e-02, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,156:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=6.710e-01, with an active set of 65 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,159:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=6.525e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,159:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=6.352e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,160:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=6.269e-01, with an active set of 77 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,166:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=6.883e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,168:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=6.774e-01, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,169:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=6.773e-01, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,170:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=6.701e-01, with an active set of 111 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.486e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.469e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,177:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.445e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.343e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.232e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.172e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.124e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.080e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.767e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,178:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.688e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,179:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.655e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,179:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.571e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,179:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.499e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,179:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.371e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.299e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.280e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.454e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.231e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.172e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.062e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.021e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,180:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.973e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,181:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.959e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,181:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.938e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,181:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.815e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,181:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.804e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,181:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.750e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.739e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.702e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.661e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.501e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.637e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.588e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.551e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.532e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.563e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.523e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.522e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.226e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.488e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.047e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.451e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,183:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.377e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.374e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.368e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.806e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.360e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.349e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.348e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,184:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.307e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.280e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.275e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.272e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.272e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.256e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,185:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.256e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.248e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.957e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.240e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.220e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.536e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.197e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.029e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.190e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.165e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.145e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.139e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.998e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,186:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.125e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.094e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.086e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.056e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.645e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.054e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.047e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.041e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.019e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.017e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.005e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.002e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.668e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.982e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.029e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,189:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.961e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,189:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.960e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,189:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.943e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,189:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.940e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,189:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.929e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.927e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.883e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.855e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.843e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.835e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.829e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.819e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.815e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.813e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.803e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.970e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.800e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.793e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.786e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.772e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.763e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.633e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.759e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.734e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.633e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.726e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.712e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.706e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.699e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.695e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.692e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,194:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.680e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.668e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.622e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.609e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.602e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.411e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.593e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.579e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.166e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,195:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.571e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.528e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.565e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.561e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.559e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.518e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.456e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,196:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.450e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.699e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,197:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.446e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,197:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.441e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,197:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.421e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,197:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.415e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,197:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.409e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,197:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.358e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.332e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.331e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.320e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.319e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.319e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.310e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.307e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.282e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,198:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.274e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.265e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.669e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.264e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.247e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.231e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.226e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.226e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,199:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.214e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.195e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.194e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.171e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.153e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.125e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,200:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.117e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,201:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.109e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.536e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,201:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.109e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,201:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.084e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.226e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,201:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.082e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.073e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.890e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.071e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.813e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.069e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.060e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.957e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.044e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,202:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.018e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,203:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.008e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,203:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.000e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,203:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.956e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.813e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,203:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.900e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,203:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.704e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,203:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.698e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.763e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.653e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.592e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.857e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.528e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.498e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.449e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.379e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.348e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.285e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.238e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,206:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.186e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,206:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.147e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,206:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.965e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,206:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.962e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,207:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.807e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,207:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.791e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,207:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.787e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.783e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.139e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.778e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.594e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.567e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.855e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.492e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.488e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.135e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.362e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.293e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.289e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.256e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.098e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.085e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.501e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.058e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.047e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.978e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.853e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.904e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.830e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.737e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.039e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.680e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.266e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,210:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.667e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.550e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.531e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.372e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.969e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.361e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.341e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.338e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.192e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.147e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.045e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.030e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.002e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.990e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.981e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.976e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.810e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.790e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.352e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.694e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.443e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.305e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.021e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.952e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.939e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.917e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.833e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.675e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.577e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.543e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.494e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.339e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.106e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.037e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.984e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.945e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.831e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.761e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.757e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.379e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.236e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.170e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.139e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.900e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.562e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.358e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.348e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.338e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.269e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.006e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.202e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.100e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.917e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,220:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.436e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,220:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.419e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,220:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.309e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,220:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.230e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,220:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.200e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,220:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.129e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.012e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.997e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.951e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.937e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.892e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,221:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.835e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,222:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.749e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,222:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.729e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,223:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.692e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,223:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.667e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,223:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.607e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,224:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.484e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,224:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.449e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,224:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.362e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,225:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.336e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,225:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.279e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,226:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.267e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,226:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.240e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.165e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,227:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.230e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,227:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.143e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.122e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.086e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.096e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,228:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.072e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.040e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.024e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,229:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.018e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.652e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.995e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=9.245e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.752e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,230:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.051e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,231:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.390e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,231:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.141e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=5.194e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.944e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,232:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.734e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.722e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.316e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.311e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.187e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,233:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=4.001e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=3.986e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.275e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.883e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.569e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,235:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.319e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=8.894e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=7.229e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,236:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.802e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:44,237:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.228e-02, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:49:46,247:INFO:Calculating mean and std
2023-06-14 12:49:46,247:INFO:Creating metrics dataframe
2023-06-14 12:49:46,674:INFO:Uploading results into container
2023-06-14 12:49:46,675:INFO:Uploading model into container now
2023-06-14 12:49:46,675:INFO:_master_model_container: 5
2023-06-14 12:49:46,675:INFO:_display_container: 2
2023-06-14 12:49:46,675:INFO:Lars(random_state=8628)
2023-06-14 12:49:46,675:INFO:create_model() successfully completed......................................
2023-06-14 12:49:46,743:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:46,744:INFO:Creating metrics dataframe
2023-06-14 12:49:46,748:INFO:Initializing Lasso Least Angle Regression
2023-06-14 12:49:46,749:INFO:Total runtime is 0.42295699119567876 minutes
2023-06-14 12:49:46,749:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:46,749:INFO:Initializing create_model()
2023-06-14 12:49:46,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:46,749:INFO:Checking exceptions
2023-06-14 12:49:46,749:INFO:Importing libraries
2023-06-14 12:49:46,749:INFO:Copying training dataset
2023-06-14 12:49:46,756:INFO:Defining folds
2023-06-14 12:49:46,756:INFO:Declaring metric variables
2023-06-14 12:49:46,756:INFO:Importing untrained model
2023-06-14 12:49:46,756:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 12:49:46,756:INFO:Starting cross validation
2023-06-14 12:49:46,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:50,021:INFO:Calculating mean and std
2023-06-14 12:49:50,021:INFO:Creating metrics dataframe
2023-06-14 12:49:50,446:INFO:Uploading results into container
2023-06-14 12:49:50,446:INFO:Uploading model into container now
2023-06-14 12:49:50,446:INFO:_master_model_container: 6
2023-06-14 12:49:50,448:INFO:_display_container: 2
2023-06-14 12:49:50,448:INFO:LassoLars(random_state=8628)
2023-06-14 12:49:50,448:INFO:create_model() successfully completed......................................
2023-06-14 12:49:50,506:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:50,506:INFO:Creating metrics dataframe
2023-06-14 12:49:50,511:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 12:49:50,511:INFO:Total runtime is 0.4856588919957479 minutes
2023-06-14 12:49:50,511:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:50,511:INFO:Initializing create_model()
2023-06-14 12:49:50,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:50,511:INFO:Checking exceptions
2023-06-14 12:49:50,511:INFO:Importing libraries
2023-06-14 12:49:50,511:INFO:Copying training dataset
2023-06-14 12:49:50,516:INFO:Defining folds
2023-06-14 12:49:50,516:INFO:Declaring metric variables
2023-06-14 12:49:50,516:INFO:Importing untrained model
2023-06-14 12:49:50,516:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 12:49:50,518:INFO:Starting cross validation
2023-06-14 12:49:50,519:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:53,738:INFO:Calculating mean and std
2023-06-14 12:49:53,739:INFO:Creating metrics dataframe
2023-06-14 12:49:54,169:INFO:Uploading results into container
2023-06-14 12:49:54,170:INFO:Uploading model into container now
2023-06-14 12:49:54,170:INFO:_master_model_container: 7
2023-06-14 12:49:54,170:INFO:_display_container: 2
2023-06-14 12:49:54,170:INFO:OrthogonalMatchingPursuit()
2023-06-14 12:49:54,170:INFO:create_model() successfully completed......................................
2023-06-14 12:49:54,228:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:54,228:INFO:Creating metrics dataframe
2023-06-14 12:49:54,233:INFO:Initializing Bayesian Ridge
2023-06-14 12:49:54,233:INFO:Total runtime is 0.5476932009061177 minutes
2023-06-14 12:49:54,233:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:54,233:INFO:Initializing create_model()
2023-06-14 12:49:54,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:54,233:INFO:Checking exceptions
2023-06-14 12:49:54,233:INFO:Importing libraries
2023-06-14 12:49:54,234:INFO:Copying training dataset
2023-06-14 12:49:54,239:INFO:Defining folds
2023-06-14 12:49:54,239:INFO:Declaring metric variables
2023-06-14 12:49:54,239:INFO:Importing untrained model
2023-06-14 12:49:54,239:INFO:Bayesian Ridge Imported successfully
2023-06-14 12:49:54,239:INFO:Starting cross validation
2023-06-14 12:49:54,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:49:57,506:INFO:Calculating mean and std
2023-06-14 12:49:57,506:INFO:Creating metrics dataframe
2023-06-14 12:49:57,925:INFO:Uploading results into container
2023-06-14 12:49:57,925:INFO:Uploading model into container now
2023-06-14 12:49:57,925:INFO:_master_model_container: 8
2023-06-14 12:49:57,925:INFO:_display_container: 2
2023-06-14 12:49:57,926:INFO:BayesianRidge()
2023-06-14 12:49:57,926:INFO:create_model() successfully completed......................................
2023-06-14 12:49:57,985:INFO:SubProcess create_model() end ==================================
2023-06-14 12:49:57,985:INFO:Creating metrics dataframe
2023-06-14 12:49:57,989:INFO:Initializing Passive Aggressive Regressor
2023-06-14 12:49:57,989:INFO:Total runtime is 0.6102976759274801 minutes
2023-06-14 12:49:57,989:INFO:SubProcess create_model() called ==================================
2023-06-14 12:49:57,990:INFO:Initializing create_model()
2023-06-14 12:49:57,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:49:57,990:INFO:Checking exceptions
2023-06-14 12:49:57,990:INFO:Importing libraries
2023-06-14 12:49:57,990:INFO:Copying training dataset
2023-06-14 12:49:57,995:INFO:Defining folds
2023-06-14 12:49:57,995:INFO:Declaring metric variables
2023-06-14 12:49:57,995:INFO:Importing untrained model
2023-06-14 12:49:57,995:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 12:49:57,996:INFO:Starting cross validation
2023-06-14 12:49:57,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:50:01,208:INFO:Calculating mean and std
2023-06-14 12:50:01,209:INFO:Creating metrics dataframe
2023-06-14 12:50:01,633:INFO:Uploading results into container
2023-06-14 12:50:01,633:INFO:Uploading model into container now
2023-06-14 12:50:01,634:INFO:_master_model_container: 9
2023-06-14 12:50:01,634:INFO:_display_container: 2
2023-06-14 12:50:01,634:INFO:PassiveAggressiveRegressor(random_state=8628)
2023-06-14 12:50:01,634:INFO:create_model() successfully completed......................................
2023-06-14 12:50:01,696:INFO:SubProcess create_model() end ==================================
2023-06-14 12:50:01,696:INFO:Creating metrics dataframe
2023-06-14 12:50:01,700:INFO:Initializing Huber Regressor
2023-06-14 12:50:01,701:INFO:Total runtime is 0.672161857287089 minutes
2023-06-14 12:50:01,701:INFO:SubProcess create_model() called ==================================
2023-06-14 12:50:01,701:INFO:Initializing create_model()
2023-06-14 12:50:01,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:50:01,702:INFO:Checking exceptions
2023-06-14 12:50:01,702:INFO:Importing libraries
2023-06-14 12:50:01,702:INFO:Copying training dataset
2023-06-14 12:50:01,706:INFO:Defining folds
2023-06-14 12:50:01,706:INFO:Declaring metric variables
2023-06-14 12:50:01,706:INFO:Importing untrained model
2023-06-14 12:50:01,706:INFO:Huber Regressor Imported successfully
2023-06-14 12:50:01,706:INFO:Starting cross validation
2023-06-14 12:50:01,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:50:01,979:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:50:02,051:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:50:02,056:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:50:02,056:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:50:02,067:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:50:02,074:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:50:03,263:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:50:05,402:INFO:Calculating mean and std
2023-06-14 12:50:05,403:INFO:Creating metrics dataframe
2023-06-14 12:50:05,826:INFO:Uploading results into container
2023-06-14 12:50:05,826:INFO:Uploading model into container now
2023-06-14 12:50:05,827:INFO:_master_model_container: 10
2023-06-14 12:50:05,827:INFO:_display_container: 2
2023-06-14 12:50:05,827:INFO:HuberRegressor()
2023-06-14 12:50:05,827:INFO:create_model() successfully completed......................................
2023-06-14 12:50:05,887:INFO:SubProcess create_model() end ==================================
2023-06-14 12:50:05,887:INFO:Creating metrics dataframe
2023-06-14 12:50:05,891:INFO:Initializing K Neighbors Regressor
2023-06-14 12:50:05,891:INFO:Total runtime is 0.7419939796129862 minutes
2023-06-14 12:50:05,891:INFO:SubProcess create_model() called ==================================
2023-06-14 12:50:05,891:INFO:Initializing create_model()
2023-06-14 12:50:05,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:50:05,893:INFO:Checking exceptions
2023-06-14 12:50:05,893:INFO:Importing libraries
2023-06-14 12:50:05,893:INFO:Copying training dataset
2023-06-14 12:50:05,897:INFO:Defining folds
2023-06-14 12:50:05,898:INFO:Declaring metric variables
2023-06-14 12:50:05,898:INFO:Importing untrained model
2023-06-14 12:50:05,898:INFO:K Neighbors Regressor Imported successfully
2023-06-14 12:50:05,898:INFO:Starting cross validation
2023-06-14 12:50:05,900:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:50:09,300:INFO:Calculating mean and std
2023-06-14 12:50:09,301:INFO:Creating metrics dataframe
2023-06-14 12:50:09,728:INFO:Uploading results into container
2023-06-14 12:50:09,728:INFO:Uploading model into container now
2023-06-14 12:50:09,728:INFO:_master_model_container: 11
2023-06-14 12:50:09,728:INFO:_display_container: 2
2023-06-14 12:50:09,728:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 12:50:09,728:INFO:create_model() successfully completed......................................
2023-06-14 12:50:09,791:INFO:SubProcess create_model() end ==================================
2023-06-14 12:50:09,791:INFO:Creating metrics dataframe
2023-06-14 12:50:09,795:INFO:Initializing Decision Tree Regressor
2023-06-14 12:50:09,796:INFO:Total runtime is 0.8070708314577738 minutes
2023-06-14 12:50:09,796:INFO:SubProcess create_model() called ==================================
2023-06-14 12:50:09,796:INFO:Initializing create_model()
2023-06-14 12:50:09,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:50:09,796:INFO:Checking exceptions
2023-06-14 12:50:09,796:INFO:Importing libraries
2023-06-14 12:50:09,796:INFO:Copying training dataset
2023-06-14 12:50:09,801:INFO:Defining folds
2023-06-14 12:50:09,801:INFO:Declaring metric variables
2023-06-14 12:50:09,801:INFO:Importing untrained model
2023-06-14 12:50:09,801:INFO:Decision Tree Regressor Imported successfully
2023-06-14 12:50:09,801:INFO:Starting cross validation
2023-06-14 12:50:09,803:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:50:13,028:INFO:Calculating mean and std
2023-06-14 12:50:13,030:INFO:Creating metrics dataframe
2023-06-14 12:50:13,488:INFO:Uploading results into container
2023-06-14 12:50:13,488:INFO:Uploading model into container now
2023-06-14 12:50:13,488:INFO:_master_model_container: 12
2023-06-14 12:50:13,489:INFO:_display_container: 2
2023-06-14 12:50:13,489:INFO:DecisionTreeRegressor(random_state=8628)
2023-06-14 12:50:13,489:INFO:create_model() successfully completed......................................
2023-06-14 12:50:13,546:INFO:SubProcess create_model() end ==================================
2023-06-14 12:50:13,546:INFO:Creating metrics dataframe
2023-06-14 12:50:13,551:INFO:Initializing Random Forest Regressor
2023-06-14 12:50:13,551:INFO:Total runtime is 0.8696591973304748 minutes
2023-06-14 12:50:13,551:INFO:SubProcess create_model() called ==================================
2023-06-14 12:50:13,551:INFO:Initializing create_model()
2023-06-14 12:50:13,551:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:50:13,551:INFO:Checking exceptions
2023-06-14 12:50:13,551:INFO:Importing libraries
2023-06-14 12:50:13,551:INFO:Copying training dataset
2023-06-14 12:50:13,556:INFO:Defining folds
2023-06-14 12:50:13,556:INFO:Declaring metric variables
2023-06-14 12:50:13,556:INFO:Importing untrained model
2023-06-14 12:50:13,556:INFO:Random Forest Regressor Imported successfully
2023-06-14 12:50:13,556:INFO:Starting cross validation
2023-06-14 12:50:13,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:50:14,899:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:50:18,509:INFO:Calculating mean and std
2023-06-14 12:50:18,509:INFO:Creating metrics dataframe
2023-06-14 12:50:18,940:INFO:Uploading results into container
2023-06-14 12:50:18,940:INFO:Uploading model into container now
2023-06-14 12:50:18,941:INFO:_master_model_container: 13
2023-06-14 12:50:18,941:INFO:_display_container: 2
2023-06-14 12:50:18,941:INFO:RandomForestRegressor(n_jobs=-1, random_state=8628)
2023-06-14 12:50:18,941:INFO:create_model() successfully completed......................................
2023-06-14 12:50:19,000:INFO:SubProcess create_model() end ==================================
2023-06-14 12:50:19,000:INFO:Creating metrics dataframe
2023-06-14 12:50:19,005:INFO:Initializing Extra Trees Regressor
2023-06-14 12:50:19,005:INFO:Total runtime is 0.9605527321497599 minutes
2023-06-14 12:50:19,005:INFO:SubProcess create_model() called ==================================
2023-06-14 12:50:19,005:INFO:Initializing create_model()
2023-06-14 12:50:19,005:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:50:19,005:INFO:Checking exceptions
2023-06-14 12:50:19,005:INFO:Importing libraries
2023-06-14 12:50:19,005:INFO:Copying training dataset
2023-06-14 12:50:19,010:INFO:Defining folds
2023-06-14 12:50:19,010:INFO:Declaring metric variables
2023-06-14 12:50:19,011:INFO:Importing untrained model
2023-06-14 12:50:19,011:INFO:Extra Trees Regressor Imported successfully
2023-06-14 12:50:19,011:INFO:Starting cross validation
2023-06-14 12:50:19,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:50:20,270:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:50:20,280:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:50:20,300:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:50:20,309:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:50:23,839:INFO:Calculating mean and std
2023-06-14 12:50:23,840:INFO:Creating metrics dataframe
2023-06-14 12:50:24,281:INFO:Uploading results into container
2023-06-14 12:50:24,282:INFO:Uploading model into container now
2023-06-14 12:50:24,282:INFO:_master_model_container: 14
2023-06-14 12:50:24,282:INFO:_display_container: 2
2023-06-14 12:50:24,282:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8628)
2023-06-14 12:50:24,283:INFO:create_model() successfully completed......................................
2023-06-14 12:50:24,340:INFO:SubProcess create_model() end ==================================
2023-06-14 12:50:24,342:INFO:Creating metrics dataframe
2023-06-14 12:50:24,346:INFO:Initializing AdaBoost Regressor
2023-06-14 12:50:24,346:INFO:Total runtime is 1.0495747804641724 minutes
2023-06-14 12:50:24,346:INFO:SubProcess create_model() called ==================================
2023-06-14 12:50:24,346:INFO:Initializing create_model()
2023-06-14 12:50:24,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:50:24,346:INFO:Checking exceptions
2023-06-14 12:50:24,346:INFO:Importing libraries
2023-06-14 12:50:24,346:INFO:Copying training dataset
2023-06-14 12:50:24,351:INFO:Defining folds
2023-06-14 12:50:24,351:INFO:Declaring metric variables
2023-06-14 12:50:24,351:INFO:Importing untrained model
2023-06-14 12:50:24,351:INFO:AdaBoost Regressor Imported successfully
2023-06-14 12:50:24,352:INFO:Starting cross validation
2023-06-14 12:50:24,354:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:50:28,416:INFO:Calculating mean and std
2023-06-14 12:50:28,417:INFO:Creating metrics dataframe
2023-06-14 12:50:28,860:INFO:Uploading results into container
2023-06-14 12:50:28,861:INFO:Uploading model into container now
2023-06-14 12:50:28,861:INFO:_master_model_container: 15
2023-06-14 12:50:28,861:INFO:_display_container: 2
2023-06-14 12:50:28,861:INFO:AdaBoostRegressor(random_state=8628)
2023-06-14 12:50:28,861:INFO:create_model() successfully completed......................................
2023-06-14 12:50:28,920:INFO:SubProcess create_model() end ==================================
2023-06-14 12:50:28,921:INFO:Creating metrics dataframe
2023-06-14 12:50:28,924:INFO:Initializing Gradient Boosting Regressor
2023-06-14 12:50:28,925:INFO:Total runtime is 1.1258955121040344 minutes
2023-06-14 12:50:28,925:INFO:SubProcess create_model() called ==================================
2023-06-14 12:50:28,925:INFO:Initializing create_model()
2023-06-14 12:50:28,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:50:28,925:INFO:Checking exceptions
2023-06-14 12:50:28,925:INFO:Importing libraries
2023-06-14 12:50:28,925:INFO:Copying training dataset
2023-06-14 12:50:28,930:INFO:Defining folds
2023-06-14 12:50:28,930:INFO:Declaring metric variables
2023-06-14 12:50:28,930:INFO:Importing untrained model
2023-06-14 12:50:28,931:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 12:50:28,931:INFO:Starting cross validation
2023-06-14 12:50:28,933:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:50:33,280:INFO:Calculating mean and std
2023-06-14 12:50:33,281:INFO:Creating metrics dataframe
2023-06-14 12:50:33,714:INFO:Uploading results into container
2023-06-14 12:50:33,715:INFO:Uploading model into container now
2023-06-14 12:50:33,715:INFO:_master_model_container: 16
2023-06-14 12:50:33,715:INFO:_display_container: 2
2023-06-14 12:50:33,715:INFO:GradientBoostingRegressor(random_state=8628)
2023-06-14 12:50:33,716:INFO:create_model() successfully completed......................................
2023-06-14 12:50:33,773:INFO:SubProcess create_model() end ==================================
2023-06-14 12:50:33,774:INFO:Creating metrics dataframe
2023-06-14 12:50:33,778:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 12:50:33,778:INFO:Total runtime is 1.2067678531010946 minutes
2023-06-14 12:50:33,779:INFO:SubProcess create_model() called ==================================
2023-06-14 12:50:33,779:INFO:Initializing create_model()
2023-06-14 12:50:33,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:50:33,779:INFO:Checking exceptions
2023-06-14 12:50:33,779:INFO:Importing libraries
2023-06-14 12:50:33,779:INFO:Copying training dataset
2023-06-14 12:50:33,783:INFO:Defining folds
2023-06-14 12:50:33,783:INFO:Declaring metric variables
2023-06-14 12:50:33,784:INFO:Importing untrained model
2023-06-14 12:50:33,784:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 12:50:33,784:INFO:Starting cross validation
2023-06-14 12:50:33,786:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:50:37,276:INFO:Calculating mean and std
2023-06-14 12:50:37,276:INFO:Creating metrics dataframe
2023-06-14 12:50:37,718:INFO:Uploading results into container
2023-06-14 12:50:37,719:INFO:Uploading model into container now
2023-06-14 12:50:37,719:INFO:_master_model_container: 17
2023-06-14 12:50:37,719:INFO:_display_container: 2
2023-06-14 12:50:37,720:INFO:LGBMRegressor(random_state=8628)
2023-06-14 12:50:37,720:INFO:create_model() successfully completed......................................
2023-06-14 12:50:37,778:INFO:SubProcess create_model() end ==================================
2023-06-14 12:50:37,779:INFO:Creating metrics dataframe
2023-06-14 12:50:37,784:INFO:Initializing Dummy Regressor
2023-06-14 12:50:37,784:INFO:Total runtime is 1.2735397775967916 minutes
2023-06-14 12:50:37,784:INFO:SubProcess create_model() called ==================================
2023-06-14 12:50:37,784:INFO:Initializing create_model()
2023-06-14 12:50:37,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002585CB5D150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:50:37,784:INFO:Checking exceptions
2023-06-14 12:50:37,784:INFO:Importing libraries
2023-06-14 12:50:37,784:INFO:Copying training dataset
2023-06-14 12:50:37,789:INFO:Defining folds
2023-06-14 12:50:37,789:INFO:Declaring metric variables
2023-06-14 12:50:37,789:INFO:Importing untrained model
2023-06-14 12:50:37,789:INFO:Dummy Regressor Imported successfully
2023-06-14 12:50:37,789:INFO:Starting cross validation
2023-06-14 12:50:37,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:50:41,212:INFO:Calculating mean and std
2023-06-14 12:50:41,213:INFO:Creating metrics dataframe
2023-06-14 12:50:41,654:INFO:Uploading results into container
2023-06-14 12:50:41,655:INFO:Uploading model into container now
2023-06-14 12:50:41,655:INFO:_master_model_container: 18
2023-06-14 12:50:41,655:INFO:_display_container: 2
2023-06-14 12:50:41,655:INFO:DummyRegressor()
2023-06-14 12:50:41,655:INFO:create_model() successfully completed......................................
2023-06-14 12:50:41,714:INFO:SubProcess create_model() end ==================================
2023-06-14 12:50:41,714:INFO:Creating metrics dataframe
2023-06-14 12:50:41,722:INFO:Initializing create_model()
2023-06-14 12:50:41,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002585CA2AB90>, estimator=GradientBoostingRegressor(random_state=8628), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:50:41,722:INFO:Checking exceptions
2023-06-14 12:50:41,723:INFO:Importing libraries
2023-06-14 12:50:41,723:INFO:Copying training dataset
2023-06-14 12:50:41,727:INFO:Defining folds
2023-06-14 12:50:41,727:INFO:Declaring metric variables
2023-06-14 12:50:41,728:INFO:Importing untrained model
2023-06-14 12:50:41,728:INFO:Declaring custom model
2023-06-14 12:50:41,728:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 12:50:41,730:INFO:Cross validation set to False
2023-06-14 12:50:41,730:INFO:Fitting Model
2023-06-14 12:50:42,552:INFO:GradientBoostingRegressor(random_state=8628)
2023-06-14 12:50:42,552:INFO:create_model() successfully completed......................................
2023-06-14 12:50:42,625:INFO:_master_model_container: 18
2023-06-14 12:50:42,625:INFO:_display_container: 2
2023-06-14 12:50:42,625:INFO:GradientBoostingRegressor(random_state=8628)
2023-06-14 12:50:42,625:INFO:compare_models() successfully completed......................................
2023-06-14 12:52:26,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:52:26,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:52:26,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:52:26,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:52:27,427:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:52:28,421:INFO:PyCaret RegressionExperiment
2023-06-14 12:52:28,421:INFO:Logging name: reg-default-name
2023-06-14 12:52:28,422:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 12:52:28,422:INFO:version 3.0.2
2023-06-14 12:52:28,422:INFO:Initializing setup()
2023-06-14 12:52:28,422:INFO:self.USI: 141f
2023-06-14 12:52:28,422:INFO:self._variable_keys: {'gpu_n_jobs_param', 'X_test', 'y', 'logging_param', 'fold_generator', 'n_jobs_param', '_ml_usecase', 'exp_name_log', '_available_plots', 'data', 'fold_groups_param', 'transform_target_param', 'idx', 'X', 'gpu_param', 'seed', 'pipeline', 'log_plots_param', 'exp_id', 'y_test', 'html_param', 'target_param', 'fold_shuffle_param', 'y_train', 'USI', 'X_train', 'memory'}
2023-06-14 12:52:28,422:INFO:Checking environment
2023-06-14 12:52:28,422:INFO:python_version: 3.10.11
2023-06-14 12:52:28,422:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-06-14 12:52:28,422:INFO:machine: AMD64
2023-06-14 12:52:28,436:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 12:52:28,441:INFO:Memory: svmem(total=17013329920, available=2118656000, percent=87.5, used=14894673920, free=2118656000)
2023-06-14 12:52:28,441:INFO:Physical Core: 4
2023-06-14 12:52:28,442:INFO:Logical Core: 8
2023-06-14 12:52:28,442:INFO:Checking libraries
2023-06-14 12:52:28,442:INFO:System:
2023-06-14 12:52:28,442:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-06-14 12:52:28,442:INFO:executable: E:\Machine learning\mini\adam\Scripts\python.exe
2023-06-14 12:52:28,442:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 12:52:28,442:INFO:PyCaret required dependencies:
2023-06-14 12:52:28,442:INFO:                 pip: 23.0.1
2023-06-14 12:52:28,443:INFO:          setuptools: 65.5.0
2023-06-14 12:52:28,443:INFO:             pycaret: 3.0.2
2023-06-14 12:52:28,443:INFO:             IPython: 8.14.0
2023-06-14 12:52:28,443:INFO:          ipywidgets: 8.0.6
2023-06-14 12:52:28,443:INFO:                tqdm: 4.65.0
2023-06-14 12:52:28,443:INFO:               numpy: 1.23.5
2023-06-14 12:52:28,443:INFO:              pandas: 1.5.3
2023-06-14 12:52:28,443:INFO:              jinja2: 3.1.2
2023-06-14 12:52:28,443:INFO:               scipy: 1.10.1
2023-06-14 12:52:28,443:INFO:              joblib: 1.2.0
2023-06-14 12:52:28,443:INFO:             sklearn: 1.2.2
2023-06-14 12:52:28,443:INFO:                pyod: 1.0.9
2023-06-14 12:52:28,443:INFO:            imblearn: 0.10.1
2023-06-14 12:52:28,443:INFO:   category_encoders: 2.6.1
2023-06-14 12:52:28,443:INFO:            lightgbm: 3.3.5
2023-06-14 12:52:28,443:INFO:               numba: 0.57.0
2023-06-14 12:52:28,444:INFO:            requests: 2.31.0
2023-06-14 12:52:28,444:INFO:          matplotlib: 3.7.1
2023-06-14 12:52:28,444:INFO:          scikitplot: 0.3.7
2023-06-14 12:52:28,444:INFO:         yellowbrick: 1.5
2023-06-14 12:52:28,444:INFO:              plotly: 5.15.0
2023-06-14 12:52:28,444:INFO:             kaleido: 0.2.1
2023-06-14 12:52:28,444:INFO:         statsmodels: 0.14.0
2023-06-14 12:52:28,444:INFO:              sktime: 0.17.0
2023-06-14 12:52:28,444:INFO:               tbats: 1.1.3
2023-06-14 12:52:28,444:INFO:            pmdarima: 2.0.3
2023-06-14 12:52:28,444:INFO:              psutil: 5.9.5
2023-06-14 12:52:28,444:INFO:PyCaret optional dependencies:
2023-06-14 12:52:28,466:INFO:                shap: Not installed
2023-06-14 12:52:28,466:INFO:           interpret: Not installed
2023-06-14 12:52:28,466:INFO:                umap: Not installed
2023-06-14 12:52:28,466:INFO:    pandas_profiling: Not installed
2023-06-14 12:52:28,466:INFO:  explainerdashboard: Not installed
2023-06-14 12:52:28,466:INFO:             autoviz: Not installed
2023-06-14 12:52:28,466:INFO:           fairlearn: Not installed
2023-06-14 12:52:28,466:INFO:             xgboost: Not installed
2023-06-14 12:52:28,466:INFO:            catboost: Not installed
2023-06-14 12:52:28,466:INFO:              kmodes: Not installed
2023-06-14 12:52:28,466:INFO:             mlxtend: Not installed
2023-06-14 12:52:28,466:INFO:       statsforecast: Not installed
2023-06-14 12:52:28,466:INFO:        tune_sklearn: Not installed
2023-06-14 12:52:28,466:INFO:                 ray: Not installed
2023-06-14 12:52:28,467:INFO:            hyperopt: Not installed
2023-06-14 12:52:28,467:INFO:              optuna: Not installed
2023-06-14 12:52:28,467:INFO:               skopt: Not installed
2023-06-14 12:52:28,467:INFO:              mlflow: Not installed
2023-06-14 12:52:28,467:INFO:              gradio: Not installed
2023-06-14 12:52:28,467:INFO:             fastapi: Not installed
2023-06-14 12:52:28,467:INFO:             uvicorn: Not installed
2023-06-14 12:52:28,467:INFO:              m2cgen: Not installed
2023-06-14 12:52:28,467:INFO:           evidently: Not installed
2023-06-14 12:52:28,467:INFO:               fugue: Not installed
2023-06-14 12:52:28,467:INFO:           streamlit: Not installed
2023-06-14 12:52:28,467:INFO:             prophet: Not installed
2023-06-14 12:52:28,467:INFO:None
2023-06-14 12:52:28,467:INFO:Set up data.
2023-06-14 12:52:28,616:INFO:Set up train/test split.
2023-06-14 12:52:28,623:INFO:Set up index.
2023-06-14 12:52:28,623:INFO:Set up folding strategy.
2023-06-14 12:52:28,623:INFO:Assigning column types.
2023-06-14 12:52:28,634:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 12:52:28,634:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,637:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,644:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:28,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:28,756:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,762:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,772:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,888:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:28,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:28,889:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 12:52:28,894:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,899:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:52:28,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:28,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:28,997:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,097:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 12:52:29,105:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,210:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,304:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 12:52:29,368:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,514:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,517:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 12:52:29,579:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:52:29,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,725:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 12:52:29,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:29,939:INFO:Preparing preprocessing pipeline...
2023-06-14 12:52:29,939:INFO:Set up simple imputation.
2023-06-14 12:52:29,985:INFO:Finished creating preprocessing pipeline.
2023-06-14 12:52:29,993:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\adamr\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bid_amount', '0', '1', '2', '3',
                                             '4', '5', '6', '7', '8', '9', '10',
                                             '11', '12', '13', '14', '15', '16',
                                             '17', '18', '19', '20', '21', '22',
                                             '23', '24', '25', '26', '27', '28', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-06-14 12:52:29,994:INFO:Creating final display dataframe.
2023-06-14 12:52:30,168:INFO:Setup _display_container:                     Description             Value
0                    Session id              7203
1                        Target    combined_score
2                   Target type        Regression
3           Original data shape        (211, 597)
4        Transformed data shape        (211, 597)
5   Transformed train set shape        (147, 597)
6    Transformed test set shape         (64, 597)
7              Numeric features               596
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              141f
2023-06-14 12:52:30,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:30,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:30,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:30,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:52:30,385:INFO:setup() successfully completed in 2.34s...............
2023-06-14 12:52:30,385:INFO:Initializing compare_models()
2023-06-14 12:52:30,386:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 12:52:30,386:INFO:Checking exceptions
2023-06-14 12:52:30,388:INFO:Preparing display monitor
2023-06-14 12:52:30,391:INFO:Initializing Linear Regression
2023-06-14 12:52:30,391:INFO:Total runtime is 0.0 minutes
2023-06-14 12:52:30,391:INFO:SubProcess create_model() called ==================================
2023-06-14 12:52:30,391:INFO:Initializing create_model()
2023-06-14 12:52:30,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:52:30,392:INFO:Checking exceptions
2023-06-14 12:52:30,392:INFO:Importing libraries
2023-06-14 12:52:30,392:INFO:Copying training dataset
2023-06-14 12:52:30,396:INFO:Defining folds
2023-06-14 12:52:30,396:INFO:Declaring metric variables
2023-06-14 12:52:30,396:INFO:Importing untrained model
2023-06-14 12:52:30,396:INFO:Linear Regression Imported successfully
2023-06-14 12:52:30,397:INFO:Starting cross validation
2023-06-14 12:52:30,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:52:39,813:INFO:Calculating mean and std
2023-06-14 12:52:39,814:INFO:Creating metrics dataframe
2023-06-14 12:52:40,268:INFO:Uploading results into container
2023-06-14 12:52:40,269:INFO:Uploading model into container now
2023-06-14 12:52:40,269:INFO:_master_model_container: 1
2023-06-14 12:52:40,269:INFO:_display_container: 2
2023-06-14 12:52:40,269:INFO:LinearRegression(n_jobs=-1)
2023-06-14 12:52:40,270:INFO:create_model() successfully completed......................................
2023-06-14 12:52:40,333:INFO:SubProcess create_model() end ==================================
2023-06-14 12:52:40,333:INFO:Creating metrics dataframe
2023-06-14 12:52:40,337:INFO:Initializing Lasso Regression
2023-06-14 12:52:40,337:INFO:Total runtime is 0.16577610969543458 minutes
2023-06-14 12:52:40,337:INFO:SubProcess create_model() called ==================================
2023-06-14 12:52:40,337:INFO:Initializing create_model()
2023-06-14 12:52:40,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:52:40,337:INFO:Checking exceptions
2023-06-14 12:52:40,338:INFO:Importing libraries
2023-06-14 12:52:40,338:INFO:Copying training dataset
2023-06-14 12:52:40,343:INFO:Defining folds
2023-06-14 12:52:40,343:INFO:Declaring metric variables
2023-06-14 12:52:40,343:INFO:Importing untrained model
2023-06-14 12:52:40,343:INFO:Lasso Regression Imported successfully
2023-06-14 12:52:40,344:INFO:Starting cross validation
2023-06-14 12:52:40,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:52:43,884:INFO:Calculating mean and std
2023-06-14 12:52:43,885:INFO:Creating metrics dataframe
2023-06-14 12:52:44,339:INFO:Uploading results into container
2023-06-14 12:52:44,340:INFO:Uploading model into container now
2023-06-14 12:52:44,340:INFO:_master_model_container: 2
2023-06-14 12:52:44,340:INFO:_display_container: 2
2023-06-14 12:52:44,341:INFO:Lasso(random_state=7203)
2023-06-14 12:52:44,341:INFO:create_model() successfully completed......................................
2023-06-14 12:52:44,401:INFO:SubProcess create_model() end ==================================
2023-06-14 12:52:44,401:INFO:Creating metrics dataframe
2023-06-14 12:52:44,405:INFO:Initializing Ridge Regression
2023-06-14 12:52:44,405:INFO:Total runtime is 0.23357293208440144 minutes
2023-06-14 12:52:44,405:INFO:SubProcess create_model() called ==================================
2023-06-14 12:52:44,405:INFO:Initializing create_model()
2023-06-14 12:52:44,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:52:44,406:INFO:Checking exceptions
2023-06-14 12:52:44,406:INFO:Importing libraries
2023-06-14 12:52:44,406:INFO:Copying training dataset
2023-06-14 12:52:44,411:INFO:Defining folds
2023-06-14 12:52:44,411:INFO:Declaring metric variables
2023-06-14 12:52:44,411:INFO:Importing untrained model
2023-06-14 12:52:44,412:INFO:Ridge Regression Imported successfully
2023-06-14 12:52:44,412:INFO:Starting cross validation
2023-06-14 12:52:44,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:52:47,870:INFO:Calculating mean and std
2023-06-14 12:52:47,870:INFO:Creating metrics dataframe
2023-06-14 12:52:48,326:INFO:Uploading results into container
2023-06-14 12:52:48,327:INFO:Uploading model into container now
2023-06-14 12:52:48,327:INFO:_master_model_container: 3
2023-06-14 12:52:48,327:INFO:_display_container: 2
2023-06-14 12:52:48,328:INFO:Ridge(random_state=7203)
2023-06-14 12:52:48,328:INFO:create_model() successfully completed......................................
2023-06-14 12:52:48,388:INFO:SubProcess create_model() end ==================================
2023-06-14 12:52:48,388:INFO:Creating metrics dataframe
2023-06-14 12:52:48,393:INFO:Initializing Elastic Net
2023-06-14 12:52:48,393:INFO:Total runtime is 0.30003997484842937 minutes
2023-06-14 12:52:48,393:INFO:SubProcess create_model() called ==================================
2023-06-14 12:52:48,393:INFO:Initializing create_model()
2023-06-14 12:52:48,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:52:48,393:INFO:Checking exceptions
2023-06-14 12:52:48,393:INFO:Importing libraries
2023-06-14 12:52:48,393:INFO:Copying training dataset
2023-06-14 12:52:48,398:INFO:Defining folds
2023-06-14 12:52:48,398:INFO:Declaring metric variables
2023-06-14 12:52:48,398:INFO:Importing untrained model
2023-06-14 12:52:48,399:INFO:Elastic Net Imported successfully
2023-06-14 12:52:48,399:INFO:Starting cross validation
2023-06-14 12:52:48,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:52:51,841:INFO:Calculating mean and std
2023-06-14 12:52:51,841:INFO:Creating metrics dataframe
2023-06-14 12:52:52,292:INFO:Uploading results into container
2023-06-14 12:52:52,293:INFO:Uploading model into container now
2023-06-14 12:52:52,293:INFO:_master_model_container: 4
2023-06-14 12:52:52,293:INFO:_display_container: 2
2023-06-14 12:52:52,294:INFO:ElasticNet(random_state=7203)
2023-06-14 12:52:52,294:INFO:create_model() successfully completed......................................
2023-06-14 12:52:52,357:INFO:SubProcess create_model() end ==================================
2023-06-14 12:52:52,388:INFO:Creating metrics dataframe
2023-06-14 12:52:52,393:INFO:Initializing Least Angle Regression
2023-06-14 12:52:52,393:INFO:Total runtime is 0.3667060971260071 minutes
2023-06-14 12:52:52,393:INFO:SubProcess create_model() called ==================================
2023-06-14 12:52:52,394:INFO:Initializing create_model()
2023-06-14 12:52:52,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:52:52,394:INFO:Checking exceptions
2023-06-14 12:52:52,394:INFO:Importing libraries
2023-06-14 12:52:52,394:INFO:Copying training dataset
2023-06-14 12:52:52,399:INFO:Defining folds
2023-06-14 12:52:52,399:INFO:Declaring metric variables
2023-06-14 12:52:52,399:INFO:Importing untrained model
2023-06-14 12:52:52,399:INFO:Least Angle Regression Imported successfully
2023-06-14 12:52:52,400:INFO:Starting cross validation
2023-06-14 12:52:52,401:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:52:52,525:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.413e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,531:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=6.324e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,533:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=6.156e-01, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,544:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=5.582e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,547:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.568e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,547:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=5.515e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,548:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.518e-01, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,548:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.169e+00, with an active set of 47 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,551:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.185e+00, with an active set of 52 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,553:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=5.500e-01, with an active set of 101 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,555:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=5.493e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,555:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=5.435e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,555:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=5.373e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,556:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=5.373e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,560:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.238e+00, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,561:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=5.551e-01, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,566:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.263e+00, with an active set of 75 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,566:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.016e+00, with an active set of 77 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,568:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.260e+00, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,570:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.194e-01, with an active set of 50 regressors, and the smallest cholesky pivot element being 4.439e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,571:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=8.022e-01, with an active set of 51 regressors, and the smallest cholesky pivot element being 4.563e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,574:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.068e+00, with an active set of 91 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,579:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.424e-01, with an active set of 58 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,580:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.282e+00, with an active set of 101 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,581:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.282e+00, with an active set of 101 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,584:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.468e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,584:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.468e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,584:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.426e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,585:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.384e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,585:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=6.629e-01, with an active set of 77 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,585:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.371e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.204e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,586:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.326e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,587:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.325e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,587:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.301e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,587:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.273e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,587:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=6.571e-01, with an active set of 79 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,587:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.260e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.813e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,587:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.251e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.266e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,588:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=7.637e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,588:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.244e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,588:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=6.542e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 4.532e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,588:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.182e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,589:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=6.538e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 4.439e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,589:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.168e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,589:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=6.538e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,589:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.155e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,590:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.139e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,590:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.129e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,590:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=1.975e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,591:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.123e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 4.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,591:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=1.120e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,592:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.105e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,593:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.096e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,593:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=7.109e-01, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,593:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.093e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,593:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.037e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,594:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.955e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,594:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.882e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,595:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.801e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.800e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,595:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.541e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,595:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.425e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,595:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.386e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,595:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=7.901e-01, with an active set of 59 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,597:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.305e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,597:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=1.775e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,599:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.233e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,599:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.133e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.321e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,600:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.024e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,600:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.925e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.857e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,600:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.922e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.851e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.379e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.841e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.786e-01, with an active set of 98 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.379e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.823e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.806e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.532e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.322e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.691e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.450e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,601:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.281e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,603:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.422e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,603:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.209e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,603:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.369e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.727e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,603:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.198e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,603:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.178e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.450e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,604:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.160e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,604:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.155e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.938e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,604:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.249e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.115e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,604:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=6.749e-01, with an active set of 102 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,604:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.075e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.076e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,604:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.133e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.185e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,605:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.128e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,605:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.042e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,605:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.993e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,605:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.982e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.763e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,605:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=6.881e-01, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,606:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=7.600e-01, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,606:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.963e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,606:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=2.041e+00, with an active set of 126 regressors, and the smallest cholesky pivot element being 5.551e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,606:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.049e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,606:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.029e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,606:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.952e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,607:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.013e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,607:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.945e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,607:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.889e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,607:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.000e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.076e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,608:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.878e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,608:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.864e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,608:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=6.749e-01, with an active set of 106 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,608:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.943e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,608:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.855e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,608:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=2.356e+00, with an active set of 127 regressors, and the smallest cholesky pivot element being 5.795e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,608:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.939e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,608:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.851e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,608:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.908e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,608:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.828e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,609:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.652e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,609:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.567e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,609:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.364e+00, with an active set of 54 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,609:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.804e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,610:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.447e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.514e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,610:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.802e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,610:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.438e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.970e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,610:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.790e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,610:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.361e+00, with an active set of 55 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,610:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=6.774e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,610:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 137 iterations, i.e. alpha=6.777e-01, with an active set of 110 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,610:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.772e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,610:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.332e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,611:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.762e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,611:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.759e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,611:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.329e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,611:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.759e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,611:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.256e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,612:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.183e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,611:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.715e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,613:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.152e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,613:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.695e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,613:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.344e+00, with an active set of 60 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,613:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.142e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,613:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.654e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,613:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.103e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,613:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.643e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.338e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,614:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.101e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,614:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.628e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,614:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=4.400e-01, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,614:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.037e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,614:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.624e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,614:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.014e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,614:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.623e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.385e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,615:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.958e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,615:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.621e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.843e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,615:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.594e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,615:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=6.984e-01, with an active set of 116 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,615:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.949e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,615:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.591e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,615:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.949e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,615:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.943e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,617:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.760e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,617:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.674e-01, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,617:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.709e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,617:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.674e-01, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,617:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.574e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.573e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.662e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=7.883e-01, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.528e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.640e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.514e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.601e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.507e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.601e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=7.878e-01, with an active set of 97 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.503e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,618:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.572e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,619:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.521e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,619:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.508e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,619:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.495e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,619:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.484e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,620:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.481e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.608e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,620:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.465e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,620:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.472e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,620:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.442e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,620:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=6.713e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,620:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.464e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,620:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.435e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,621:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.461e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.333e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,621:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.319e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,621:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.406e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,621:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.222e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,621:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.405e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.242e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,622:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.099e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,622:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.092e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,622:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.066e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,623:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.025e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,624:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.019e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,625:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=9.338e-01, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,625:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.949e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,625:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.318e+00, with an active set of 84 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,627:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.922e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,627:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=6.714e-01, with an active set of 109 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,627:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.907e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,627:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.894e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,628:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.818e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,628:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.679e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,629:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.596e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,629:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.588e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,629:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.571e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.007e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,630:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.553e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,630:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.487e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,630:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.361e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,631:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.356e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,631:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.302e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,631:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=1.321e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,631:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.146e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,632:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.040e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,632:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=6.664e-01, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,632:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.038e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,632:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.984e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,633:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.983e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.735e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,633:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.972e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,634:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.964e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.385e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,634:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.318e+00, with an active set of 94 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,634:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.957e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.608e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,634:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.954e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.779e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,635:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.946e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,635:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.943e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.439e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,635:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.898e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,635:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=1.174e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,635:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.870e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,635:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.783e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,636:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.763e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,637:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.713e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,637:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.712e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,637:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.699e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,638:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.695e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,638:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.175e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,638:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.683e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,638:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.675e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,639:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.653e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,639:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.643e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,640:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.626e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,640:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.595e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.936e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,641:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.552e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,641:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.550e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,641:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.547e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,642:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.501e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,642:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.489e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,642:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.484e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,643:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.481e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.513e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,643:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.464e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,643:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.457e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,643:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.339e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.984e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,644:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.310e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,644:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.259e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,644:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.244e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,645:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.224e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,645:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.345e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.972e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,645:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.177e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.821e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,645:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.122e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,645:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.161e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,645:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.003e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,647:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.106e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,647:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.803e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.452e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,647:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.065e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,647:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.765e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,647:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.720e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,648:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.010e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.660e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,648:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.657e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.343e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,648:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.998e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,648:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.656e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,648:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.985e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,649:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.615e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.338e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,649:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.933e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,649:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.561e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,649:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.914e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.135e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,649:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.434e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,649:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.902e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.343e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,649:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.404e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,649:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.878e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,650:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.851e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,650:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.369e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,650:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.847e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,650:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.358e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,650:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.784e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,651:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.317e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,651:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.732e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,651:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.298e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,651:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.674e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,651:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.664e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.685e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,651:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.252e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.435e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,653:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.250e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,653:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.655e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,653:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.222e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,653:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.612e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.263e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,654:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.197e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,654:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.587e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,654:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.578e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,655:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=1.163e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,655:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.433e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.843e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,655:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.382e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,655:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.368e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,656:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.358e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,656:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.351e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,657:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.307e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,658:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.148e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.936e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,658:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.224e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.185e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,658:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.077e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,658:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.210e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,659:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.020e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,659:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.152e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,659:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.151e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,660:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.994e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,660:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.149e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.726e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,660:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.968e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,660:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.143e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,660:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.953e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,661:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.138e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,661:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.941e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,661:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.137e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,661:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.122e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.132e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,662:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.929e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.226e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,662:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.116e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,662:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.923e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,662:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.105e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,662:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.868e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,663:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.095e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,663:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.822e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,663:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.095e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,663:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.777e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.189e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,663:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.078e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,663:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.747e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,664:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.069e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,664:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.745e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,664:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.065e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,664:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.629e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,664:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.614e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.798e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,665:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.056e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.185e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,665:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.055e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.737e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,665:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.597e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,665:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.582e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,665:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.050e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,666:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.574e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,666:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.032e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,666:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.566e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,666:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.654e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,666:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.547e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,666:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.613e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,666:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.612e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,666:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.545e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,667:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.532e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,667:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.533e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,667:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.528e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,667:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.494e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,667:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.424e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,668:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.474e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,668:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.411e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,668:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.464e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,668:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.225e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,668:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.439e+01, with an active set of 127 regressors, and the smallest cholesky pivot element being 9.216e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,668:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.217e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,668:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.135e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.957e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,668:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.360e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.222e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,670:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.307e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,670:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.113e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,670:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.291e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,670:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.064e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,670:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.290e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,671:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.852e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.723e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,671:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.288e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,671:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.597e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,671:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.409e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,671:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.283e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,672:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.367e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,672:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.168e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,672:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.155e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,672:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.308e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.795e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,672:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.122e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,673:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.119e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,673:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.976e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,673:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.173e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,674:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.958e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,674:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.110e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,674:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.018e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,675:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.834e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,675:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.944e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,675:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.922e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,675:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.786e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,676:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.859e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,676:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.713e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,676:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.625e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,676:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.768e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.554e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,676:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.615e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.990e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,676:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.741e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,676:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.577e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,677:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.663e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,677:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.485e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,677:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.618e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.787e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,677:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.482e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,677:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.589e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,678:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.392e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,678:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.537e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,678:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.383e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,678:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.436e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,678:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.376e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,678:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.424e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,679:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.374e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,679:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.409e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,679:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.328e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,679:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.307e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,679:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.274e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,680:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.292e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.499e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,680:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.289e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,680:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.250e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,681:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.277e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.321e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,681:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.153e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,681:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.273e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,681:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.140e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,681:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.270e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,682:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.085e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,682:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.214e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,682:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.010e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,683:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.200e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.767e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,683:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.928e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,683:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.182e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,683:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.893e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,683:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.151e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,684:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.880e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,684:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.149e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.442e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,684:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.872e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,684:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.137e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,684:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.792e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,684:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.126e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,685:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.782e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,685:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.100e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,685:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.766e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,685:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.728e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,686:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.670e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,686:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.050e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,687:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.667e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,687:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.023e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,687:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.644e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,687:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.850e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,687:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.633e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,687:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.818e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,688:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.579e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,688:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.746e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.251e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,688:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.522e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,688:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.506e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,688:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.422e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,689:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.493e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,689:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.281e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,689:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.063e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,689:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.466e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,690:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.508e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,690:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.374e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,691:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.967e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,691:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.765e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,691:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.439e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,692:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.435e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,692:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=7.290e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.353e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,692:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.426e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,693:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.926e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,693:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.362e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.738e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,693:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.892e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,693:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.360e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,693:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.295e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,694:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.245e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,694:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.217e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,694:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.220e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,694:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.138e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,694:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.017e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.469e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,694:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.126e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,695:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.862e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,695:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.118e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,695:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.641e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.890e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,695:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.077e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,695:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.620e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,695:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.062e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,696:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.610e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,696:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.014e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,696:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.038e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,696:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.003e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.419e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,696:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.031e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,697:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.999e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,697:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.983e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,697:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.855e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,697:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.909e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,697:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.729e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,697:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.895e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,697:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.716e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,697:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.838e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,698:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.715e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,698:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.837e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.431e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,698:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.602e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,698:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.653e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,699:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.648e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,699:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.534e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,699:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.603e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.182e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,699:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.287e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,699:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.594e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,699:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.115e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,699:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.502e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,700:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.095e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,700:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.464e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,700:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.702e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,700:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.400e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,700:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.689e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,700:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.374e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,701:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.357e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,701:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.564e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,701:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.187e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,701:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.434e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,701:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.400e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,701:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.938e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,701:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.369e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,703:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.925e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,703:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.156e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,703:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.054e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,704:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.818e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,704:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.807e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,704:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.951e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,705:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.930e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,705:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.769e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.047e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,705:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.678e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,706:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.512e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,706:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.707e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,706:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.205e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,706:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.696e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,707:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.049e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,707:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.661e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.247e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,707:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.907e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,707:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.621e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,707:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.647e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.135e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,707:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.561e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,708:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.546e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,708:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.643e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,708:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.301e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,708:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.597e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.970e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,709:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.051e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,709:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.522e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,709:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=9.519e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,709:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.522e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,709:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=8.338e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,709:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.518e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.095e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,709:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=6.042e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,710:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.937e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,710:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.469e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.262e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,710:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.335e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,710:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.440e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,710:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.211e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,711:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.403e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,711:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.879e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,711:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.387e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,711:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=4.838e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,711:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.317e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,712:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.136e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.385e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,713:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.051e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,713:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.128e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.369e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,713:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=2.113e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,713:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.075e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,713:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.253e-04, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,713:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.037e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,713:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.031e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,714:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.887e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,715:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.862e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,715:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.840e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,716:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.783e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,716:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.755e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,716:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.703e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,717:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.647e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,717:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.579e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,717:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.579e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,718:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.565e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,718:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.454e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,719:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.421e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.853e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,720:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.413e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,720:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.372e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,721:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.370e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,722:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.352e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,722:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.322e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,723:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.293e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,724:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.286e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,724:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.268e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,725:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.234e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.278e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,725:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.233e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,725:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.232e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,726:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.229e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.685e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,726:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.222e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,727:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.205e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,727:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.205e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.954e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,727:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.095e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.263e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,727:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.083e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,728:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.057e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,728:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.979e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,729:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.975e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,729:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.957e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,729:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.848e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,730:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.838e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,730:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.834e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,730:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.832e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,731:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.812e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,731:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.805e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,732:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.797e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,732:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.766e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,732:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.759e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,733:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.758e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,733:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.756e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.898e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,734:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.751e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,734:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.723e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,734:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.699e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,734:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.661e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.914e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,736:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.652e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.204e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,737:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.629e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,737:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.629e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,737:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.627e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.813e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,737:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.611e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.196e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,738:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.583e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.536e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,738:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.557e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,739:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.458e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,740:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.427e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.499e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,741:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.411e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,741:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.401e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,741:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.394e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,742:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.385e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,742:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.326e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,743:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.320e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,743:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.220e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,743:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.214e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,743:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.104e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,745:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.085e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.311e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,745:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.075e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,745:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.015e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,746:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.992e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,746:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.968e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,746:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.936e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.969e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,746:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.924e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,747:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.830e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,747:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.783e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,747:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.748e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.699e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,748:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.707e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.312e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,748:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.661e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.312e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,748:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.657e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.182e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,749:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.646e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,749:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.566e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,749:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.554e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,749:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.549e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.562e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,750:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.545e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,750:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.537e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,750:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.513e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,751:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.475e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,751:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.450e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,752:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.410e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,753:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.405e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,754:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.399e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,754:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.368e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,755:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.344e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,755:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.310e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,755:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.265e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,756:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.252e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,756:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.238e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:52,759:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=1.339e-01, with an active set of 134 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,163:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.457e+00, with an active set of 86 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.443e+00, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,167:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=1.441e+00, with an active set of 92 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,171:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=1.452e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,188:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=4.095e+00, with an active set of 115 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,191:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 148 iterations, i.e. alpha=4.091e+00, with an active set of 118 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.115e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.366e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.051e+01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,204:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=8.416e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.933e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.623e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=7.966e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=7.892e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,208:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=7.684e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.969e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=7.850e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=7.613e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,211:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=7.555e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=7.486e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=7.249e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,212:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=7.150e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.963e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.867e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,213:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.822e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.686e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,214:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.648e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.571e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.556e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,215:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.501e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=6.482e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.943e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.809e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 9.926e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,216:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.752e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.746e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.741e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,217:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.644e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.618e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.605e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.576e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,218:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.568e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,219:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.520e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,220:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.458e+00, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,767:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.733e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,772:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=7.527e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,777:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=7.322e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:54,791:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=1.524e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.269e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:52:56,923:INFO:Calculating mean and std
2023-06-14 12:52:56,923:INFO:Creating metrics dataframe
2023-06-14 12:52:57,388:INFO:Uploading results into container
2023-06-14 12:52:57,389:INFO:Uploading model into container now
2023-06-14 12:52:57,389:INFO:_master_model_container: 5
2023-06-14 12:52:57,389:INFO:_display_container: 2
2023-06-14 12:52:57,390:INFO:Lars(random_state=7203)
2023-06-14 12:52:57,390:INFO:create_model() successfully completed......................................
2023-06-14 12:52:57,449:INFO:SubProcess create_model() end ==================================
2023-06-14 12:52:57,449:INFO:Creating metrics dataframe
2023-06-14 12:52:57,454:INFO:Initializing Lasso Least Angle Regression
2023-06-14 12:52:57,454:INFO:Total runtime is 0.4510535438855489 minutes
2023-06-14 12:52:57,454:INFO:SubProcess create_model() called ==================================
2023-06-14 12:52:57,454:INFO:Initializing create_model()
2023-06-14 12:52:57,454:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:52:57,454:INFO:Checking exceptions
2023-06-14 12:52:57,454:INFO:Importing libraries
2023-06-14 12:52:57,454:INFO:Copying training dataset
2023-06-14 12:52:57,459:INFO:Defining folds
2023-06-14 12:52:57,459:INFO:Declaring metric variables
2023-06-14 12:52:57,459:INFO:Importing untrained model
2023-06-14 12:52:57,459:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 12:52:57,459:INFO:Starting cross validation
2023-06-14 12:52:57,461:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:00,985:INFO:Calculating mean and std
2023-06-14 12:53:00,986:INFO:Creating metrics dataframe
2023-06-14 12:53:01,436:INFO:Uploading results into container
2023-06-14 12:53:01,437:INFO:Uploading model into container now
2023-06-14 12:53:01,437:INFO:_master_model_container: 6
2023-06-14 12:53:01,438:INFO:_display_container: 2
2023-06-14 12:53:01,438:INFO:LassoLars(random_state=7203)
2023-06-14 12:53:01,438:INFO:create_model() successfully completed......................................
2023-06-14 12:53:01,499:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:01,499:INFO:Creating metrics dataframe
2023-06-14 12:53:01,503:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 12:53:01,503:INFO:Total runtime is 0.5185437997182211 minutes
2023-06-14 12:53:01,503:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:01,503:INFO:Initializing create_model()
2023-06-14 12:53:01,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:01,504:INFO:Checking exceptions
2023-06-14 12:53:01,504:INFO:Importing libraries
2023-06-14 12:53:01,504:INFO:Copying training dataset
2023-06-14 12:53:01,509:INFO:Defining folds
2023-06-14 12:53:01,509:INFO:Declaring metric variables
2023-06-14 12:53:01,510:INFO:Importing untrained model
2023-06-14 12:53:01,510:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 12:53:01,510:INFO:Starting cross validation
2023-06-14 12:53:01,512:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:05,026:INFO:Calculating mean and std
2023-06-14 12:53:05,027:INFO:Creating metrics dataframe
2023-06-14 12:53:05,537:INFO:Uploading results into container
2023-06-14 12:53:05,538:INFO:Uploading model into container now
2023-06-14 12:53:05,539:INFO:_master_model_container: 7
2023-06-14 12:53:05,539:INFO:_display_container: 2
2023-06-14 12:53:05,539:INFO:OrthogonalMatchingPursuit()
2023-06-14 12:53:05,539:INFO:create_model() successfully completed......................................
2023-06-14 12:53:05,601:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:05,601:INFO:Creating metrics dataframe
2023-06-14 12:53:05,605:INFO:Initializing Bayesian Ridge
2023-06-14 12:53:05,605:INFO:Total runtime is 0.5869095802307129 minutes
2023-06-14 12:53:05,605:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:05,605:INFO:Initializing create_model()
2023-06-14 12:53:05,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:05,605:INFO:Checking exceptions
2023-06-14 12:53:05,605:INFO:Importing libraries
2023-06-14 12:53:05,605:INFO:Copying training dataset
2023-06-14 12:53:05,611:INFO:Defining folds
2023-06-14 12:53:05,611:INFO:Declaring metric variables
2023-06-14 12:53:05,611:INFO:Importing untrained model
2023-06-14 12:53:05,612:INFO:Bayesian Ridge Imported successfully
2023-06-14 12:53:05,612:INFO:Starting cross validation
2023-06-14 12:53:05,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:09,128:INFO:Calculating mean and std
2023-06-14 12:53:09,129:INFO:Creating metrics dataframe
2023-06-14 12:53:09,604:INFO:Uploading results into container
2023-06-14 12:53:09,604:INFO:Uploading model into container now
2023-06-14 12:53:09,606:INFO:_master_model_container: 8
2023-06-14 12:53:09,606:INFO:_display_container: 2
2023-06-14 12:53:09,606:INFO:BayesianRidge()
2023-06-14 12:53:09,606:INFO:create_model() successfully completed......................................
2023-06-14 12:53:09,665:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:09,665:INFO:Creating metrics dataframe
2023-06-14 12:53:09,670:INFO:Initializing Passive Aggressive Regressor
2023-06-14 12:53:09,670:INFO:Total runtime is 0.6546502908070883 minutes
2023-06-14 12:53:09,670:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:09,671:INFO:Initializing create_model()
2023-06-14 12:53:09,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:09,671:INFO:Checking exceptions
2023-06-14 12:53:09,671:INFO:Importing libraries
2023-06-14 12:53:09,671:INFO:Copying training dataset
2023-06-14 12:53:09,676:INFO:Defining folds
2023-06-14 12:53:09,676:INFO:Declaring metric variables
2023-06-14 12:53:09,676:INFO:Importing untrained model
2023-06-14 12:53:09,677:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 12:53:09,677:INFO:Starting cross validation
2023-06-14 12:53:09,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:13,196:INFO:Calculating mean and std
2023-06-14 12:53:13,197:INFO:Creating metrics dataframe
2023-06-14 12:53:13,655:INFO:Uploading results into container
2023-06-14 12:53:13,656:INFO:Uploading model into container now
2023-06-14 12:53:13,656:INFO:_master_model_container: 9
2023-06-14 12:53:13,657:INFO:_display_container: 2
2023-06-14 12:53:13,657:INFO:PassiveAggressiveRegressor(random_state=7203)
2023-06-14 12:53:13,657:INFO:create_model() successfully completed......................................
2023-06-14 12:53:13,716:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:13,716:INFO:Creating metrics dataframe
2023-06-14 12:53:13,721:INFO:Initializing Huber Regressor
2023-06-14 12:53:13,722:INFO:Total runtime is 0.7221826831499736 minutes
2023-06-14 12:53:13,722:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:13,722:INFO:Initializing create_model()
2023-06-14 12:53:13,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:13,722:INFO:Checking exceptions
2023-06-14 12:53:13,722:INFO:Importing libraries
2023-06-14 12:53:13,722:INFO:Copying training dataset
2023-06-14 12:53:13,727:INFO:Defining folds
2023-06-14 12:53:13,727:INFO:Declaring metric variables
2023-06-14 12:53:13,728:INFO:Importing untrained model
2023-06-14 12:53:13,728:INFO:Huber Regressor Imported successfully
2023-06-14 12:53:13,728:INFO:Starting cross validation
2023-06-14 12:53:13,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:13,996:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:53:14,014:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:53:14,017:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:53:14,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:53:14,087:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:53:14,090:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:53:14,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:53:15,374:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:53:17,913:INFO:Calculating mean and std
2023-06-14 12:53:17,914:INFO:Creating metrics dataframe
2023-06-14 12:53:18,383:INFO:Uploading results into container
2023-06-14 12:53:18,384:INFO:Uploading model into container now
2023-06-14 12:53:18,384:INFO:_master_model_container: 10
2023-06-14 12:53:18,384:INFO:_display_container: 2
2023-06-14 12:53:18,385:INFO:HuberRegressor()
2023-06-14 12:53:18,385:INFO:create_model() successfully completed......................................
2023-06-14 12:53:18,444:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:18,444:INFO:Creating metrics dataframe
2023-06-14 12:53:18,448:INFO:Initializing K Neighbors Regressor
2023-06-14 12:53:18,448:INFO:Total runtime is 0.8009601593017579 minutes
2023-06-14 12:53:18,448:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:18,448:INFO:Initializing create_model()
2023-06-14 12:53:18,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:18,449:INFO:Checking exceptions
2023-06-14 12:53:18,449:INFO:Importing libraries
2023-06-14 12:53:18,449:INFO:Copying training dataset
2023-06-14 12:53:18,455:INFO:Defining folds
2023-06-14 12:53:18,455:INFO:Declaring metric variables
2023-06-14 12:53:18,455:INFO:Importing untrained model
2023-06-14 12:53:18,456:INFO:K Neighbors Regressor Imported successfully
2023-06-14 12:53:18,456:INFO:Starting cross validation
2023-06-14 12:53:18,457:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:22,190:INFO:Calculating mean and std
2023-06-14 12:53:22,190:INFO:Creating metrics dataframe
2023-06-14 12:53:22,658:INFO:Uploading results into container
2023-06-14 12:53:22,659:INFO:Uploading model into container now
2023-06-14 12:53:22,659:INFO:_master_model_container: 11
2023-06-14 12:53:22,659:INFO:_display_container: 2
2023-06-14 12:53:22,659:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 12:53:22,659:INFO:create_model() successfully completed......................................
2023-06-14 12:53:22,718:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:22,718:INFO:Creating metrics dataframe
2023-06-14 12:53:22,723:INFO:Initializing Decision Tree Regressor
2023-06-14 12:53:22,723:INFO:Total runtime is 0.872207510471344 minutes
2023-06-14 12:53:22,723:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:22,723:INFO:Initializing create_model()
2023-06-14 12:53:22,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:22,724:INFO:Checking exceptions
2023-06-14 12:53:22,724:INFO:Importing libraries
2023-06-14 12:53:22,724:INFO:Copying training dataset
2023-06-14 12:53:22,730:INFO:Defining folds
2023-06-14 12:53:22,730:INFO:Declaring metric variables
2023-06-14 12:53:22,731:INFO:Importing untrained model
2023-06-14 12:53:22,731:INFO:Decision Tree Regressor Imported successfully
2023-06-14 12:53:22,731:INFO:Starting cross validation
2023-06-14 12:53:22,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:26,272:INFO:Calculating mean and std
2023-06-14 12:53:26,272:INFO:Creating metrics dataframe
2023-06-14 12:53:26,736:INFO:Uploading results into container
2023-06-14 12:53:26,737:INFO:Uploading model into container now
2023-06-14 12:53:26,738:INFO:_master_model_container: 12
2023-06-14 12:53:26,738:INFO:_display_container: 2
2023-06-14 12:53:26,738:INFO:DecisionTreeRegressor(random_state=7203)
2023-06-14 12:53:26,739:INFO:create_model() successfully completed......................................
2023-06-14 12:53:26,796:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:26,797:INFO:Creating metrics dataframe
2023-06-14 12:53:26,800:INFO:Initializing Random Forest Regressor
2023-06-14 12:53:26,800:INFO:Total runtime is 0.9401554465293884 minutes
2023-06-14 12:53:26,802:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:26,802:INFO:Initializing create_model()
2023-06-14 12:53:26,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:26,802:INFO:Checking exceptions
2023-06-14 12:53:26,802:INFO:Importing libraries
2023-06-14 12:53:26,802:INFO:Copying training dataset
2023-06-14 12:53:26,807:INFO:Defining folds
2023-06-14 12:53:26,807:INFO:Declaring metric variables
2023-06-14 12:53:26,808:INFO:Importing untrained model
2023-06-14 12:53:26,808:INFO:Random Forest Regressor Imported successfully
2023-06-14 12:53:26,808:INFO:Starting cross validation
2023-06-14 12:53:26,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:28,187:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:53:28,209:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:53:32,128:INFO:Calculating mean and std
2023-06-14 12:53:32,128:INFO:Creating metrics dataframe
2023-06-14 12:53:32,597:INFO:Uploading results into container
2023-06-14 12:53:32,598:INFO:Uploading model into container now
2023-06-14 12:53:32,598:INFO:_master_model_container: 13
2023-06-14 12:53:32,598:INFO:_display_container: 2
2023-06-14 12:53:32,598:INFO:RandomForestRegressor(n_jobs=-1, random_state=7203)
2023-06-14 12:53:32,598:INFO:create_model() successfully completed......................................
2023-06-14 12:53:32,660:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:32,660:INFO:Creating metrics dataframe
2023-06-14 12:53:32,664:INFO:Initializing Extra Trees Regressor
2023-06-14 12:53:32,664:INFO:Total runtime is 1.0378888686498007 minutes
2023-06-14 12:53:32,664:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:32,665:INFO:Initializing create_model()
2023-06-14 12:53:32,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:32,665:INFO:Checking exceptions
2023-06-14 12:53:32,665:INFO:Importing libraries
2023-06-14 12:53:32,665:INFO:Copying training dataset
2023-06-14 12:53:32,670:INFO:Defining folds
2023-06-14 12:53:32,670:INFO:Declaring metric variables
2023-06-14 12:53:32,670:INFO:Importing untrained model
2023-06-14 12:53:32,671:INFO:Extra Trees Regressor Imported successfully
2023-06-14 12:53:32,671:INFO:Starting cross validation
2023-06-14 12:53:32,673:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:33,935:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:53:33,993:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:53:34,000:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:53:34,774:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-14 12:53:37,833:INFO:Calculating mean and std
2023-06-14 12:53:37,834:INFO:Creating metrics dataframe
2023-06-14 12:53:38,308:INFO:Uploading results into container
2023-06-14 12:53:38,308:INFO:Uploading model into container now
2023-06-14 12:53:38,309:INFO:_master_model_container: 14
2023-06-14 12:53:38,309:INFO:_display_container: 2
2023-06-14 12:53:38,309:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7203)
2023-06-14 12:53:38,309:INFO:create_model() successfully completed......................................
2023-06-14 12:53:38,368:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:38,368:INFO:Creating metrics dataframe
2023-06-14 12:53:38,373:INFO:Initializing AdaBoost Regressor
2023-06-14 12:53:38,373:INFO:Total runtime is 1.1330399552981059 minutes
2023-06-14 12:53:38,373:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:38,374:INFO:Initializing create_model()
2023-06-14 12:53:38,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:38,374:INFO:Checking exceptions
2023-06-14 12:53:38,374:INFO:Importing libraries
2023-06-14 12:53:38,374:INFO:Copying training dataset
2023-06-14 12:53:38,380:INFO:Defining folds
2023-06-14 12:53:38,380:INFO:Declaring metric variables
2023-06-14 12:53:38,380:INFO:Importing untrained model
2023-06-14 12:53:38,380:INFO:AdaBoost Regressor Imported successfully
2023-06-14 12:53:38,380:INFO:Starting cross validation
2023-06-14 12:53:38,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:42,818:INFO:Calculating mean and std
2023-06-14 12:53:42,819:INFO:Creating metrics dataframe
2023-06-14 12:53:43,294:INFO:Uploading results into container
2023-06-14 12:53:43,295:INFO:Uploading model into container now
2023-06-14 12:53:43,295:INFO:_master_model_container: 15
2023-06-14 12:53:43,295:INFO:_display_container: 2
2023-06-14 12:53:43,295:INFO:AdaBoostRegressor(random_state=7203)
2023-06-14 12:53:43,295:INFO:create_model() successfully completed......................................
2023-06-14 12:53:43,356:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:43,356:INFO:Creating metrics dataframe
2023-06-14 12:53:43,360:INFO:Initializing Gradient Boosting Regressor
2023-06-14 12:53:43,360:INFO:Total runtime is 1.2161550164222716 minutes
2023-06-14 12:53:43,360:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:43,360:INFO:Initializing create_model()
2023-06-14 12:53:43,360:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:43,361:INFO:Checking exceptions
2023-06-14 12:53:43,361:INFO:Importing libraries
2023-06-14 12:53:43,361:INFO:Copying training dataset
2023-06-14 12:53:43,365:INFO:Defining folds
2023-06-14 12:53:43,366:INFO:Declaring metric variables
2023-06-14 12:53:43,366:INFO:Importing untrained model
2023-06-14 12:53:43,366:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 12:53:43,366:INFO:Starting cross validation
2023-06-14 12:53:43,368:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:48,101:INFO:Calculating mean and std
2023-06-14 12:53:48,101:INFO:Creating metrics dataframe
2023-06-14 12:53:48,617:INFO:Uploading results into container
2023-06-14 12:53:48,618:INFO:Uploading model into container now
2023-06-14 12:53:48,618:INFO:_master_model_container: 16
2023-06-14 12:53:48,618:INFO:_display_container: 2
2023-06-14 12:53:48,618:INFO:GradientBoostingRegressor(random_state=7203)
2023-06-14 12:53:48,619:INFO:create_model() successfully completed......................................
2023-06-14 12:53:48,680:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:48,681:INFO:Creating metrics dataframe
2023-06-14 12:53:48,686:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 12:53:48,686:INFO:Total runtime is 1.3049219608306883 minutes
2023-06-14 12:53:48,686:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:48,687:INFO:Initializing create_model()
2023-06-14 12:53:48,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:48,687:INFO:Checking exceptions
2023-06-14 12:53:48,687:INFO:Importing libraries
2023-06-14 12:53:48,687:INFO:Copying training dataset
2023-06-14 12:53:48,692:INFO:Defining folds
2023-06-14 12:53:48,693:INFO:Declaring metric variables
2023-06-14 12:53:48,693:INFO:Importing untrained model
2023-06-14 12:53:48,693:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 12:53:48,693:INFO:Starting cross validation
2023-06-14 12:53:48,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:52,538:INFO:Calculating mean and std
2023-06-14 12:53:52,539:INFO:Creating metrics dataframe
2023-06-14 12:53:53,025:INFO:Uploading results into container
2023-06-14 12:53:53,025:INFO:Uploading model into container now
2023-06-14 12:53:53,025:INFO:_master_model_container: 17
2023-06-14 12:53:53,025:INFO:_display_container: 2
2023-06-14 12:53:53,027:INFO:LGBMRegressor(random_state=7203)
2023-06-14 12:53:53,027:INFO:create_model() successfully completed......................................
2023-06-14 12:53:53,085:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:53,085:INFO:Creating metrics dataframe
2023-06-14 12:53:53,090:INFO:Initializing Dummy Regressor
2023-06-14 12:53:53,090:INFO:Total runtime is 1.378321615854899 minutes
2023-06-14 12:53:53,091:INFO:SubProcess create_model() called ==================================
2023-06-14 12:53:53,091:INFO:Initializing create_model()
2023-06-14 12:53:53,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B387559090>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:53,091:INFO:Checking exceptions
2023-06-14 12:53:53,091:INFO:Importing libraries
2023-06-14 12:53:53,091:INFO:Copying training dataset
2023-06-14 12:53:53,095:INFO:Defining folds
2023-06-14 12:53:53,095:INFO:Declaring metric variables
2023-06-14 12:53:53,095:INFO:Importing untrained model
2023-06-14 12:53:53,095:INFO:Dummy Regressor Imported successfully
2023-06-14 12:53:53,097:INFO:Starting cross validation
2023-06-14 12:53:53,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:53:56,789:INFO:Calculating mean and std
2023-06-14 12:53:56,790:INFO:Creating metrics dataframe
2023-06-14 12:53:57,285:INFO:Uploading results into container
2023-06-14 12:53:57,286:INFO:Uploading model into container now
2023-06-14 12:53:57,286:INFO:_master_model_container: 18
2023-06-14 12:53:57,287:INFO:_display_container: 2
2023-06-14 12:53:57,287:INFO:DummyRegressor()
2023-06-14 12:53:57,287:INFO:create_model() successfully completed......................................
2023-06-14 12:53:57,347:INFO:SubProcess create_model() end ==================================
2023-06-14 12:53:57,347:INFO:Creating metrics dataframe
2023-06-14 12:53:57,353:INFO:Initializing create_model()
2023-06-14 12:53:57,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002B387426D40>, estimator=GradientBoostingRegressor(random_state=7203), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:53:57,353:INFO:Checking exceptions
2023-06-14 12:53:57,354:INFO:Importing libraries
2023-06-14 12:53:57,354:INFO:Copying training dataset
2023-06-14 12:53:57,359:INFO:Defining folds
2023-06-14 12:53:57,359:INFO:Declaring metric variables
2023-06-14 12:53:57,359:INFO:Importing untrained model
2023-06-14 12:53:57,359:INFO:Declaring custom model
2023-06-14 12:53:57,360:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 12:53:57,362:INFO:Cross validation set to False
2023-06-14 12:53:57,362:INFO:Fitting Model
2023-06-14 12:53:58,200:INFO:GradientBoostingRegressor(random_state=7203)
2023-06-14 12:53:58,200:INFO:create_model() successfully completed......................................
2023-06-14 12:53:58,276:INFO:_master_model_container: 18
2023-06-14 12:53:58,276:INFO:_display_container: 2
2023-06-14 12:53:58,277:INFO:GradientBoostingRegressor(random_state=7203)
2023-06-14 12:53:58,277:INFO:compare_models() successfully completed......................................
2023-06-14 12:58:56,537:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:58:56,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:58:56,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:58:56,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-14 12:58:57,079:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-14 12:58:58,051:INFO:PyCaret RegressionExperiment
2023-06-14 12:58:58,051:INFO:Logging name: reg-default-name
2023-06-14 12:58:58,051:INFO:ML Usecase: MLUsecase.REGRESSION
2023-06-14 12:58:58,051:INFO:version 3.0.2
2023-06-14 12:58:58,051:INFO:Initializing setup()
2023-06-14 12:58:58,051:INFO:self.USI: d8e1
2023-06-14 12:58:58,052:INFO:self._variable_keys: {'logging_param', 'log_plots_param', 'fold_shuffle_param', 'y', 'seed', 'USI', 'idx', 'fold_generator', 'X', 'n_jobs_param', '_ml_usecase', 'memory', 'y_train', 'exp_name_log', 'html_param', 'exp_id', 'target_param', 'gpu_n_jobs_param', 'X_train', 'fold_groups_param', 'gpu_param', 'X_test', 'data', '_available_plots', 'pipeline', 'y_test', 'transform_target_param'}
2023-06-14 12:58:58,052:INFO:Checking environment
2023-06-14 12:58:58,052:INFO:python_version: 3.10.11
2023-06-14 12:58:58,052:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2023-06-14 12:58:58,052:INFO:machine: AMD64
2023-06-14 12:58:58,064:INFO:platform: Windows-10-10.0.22621-SP0
2023-06-14 12:58:58,068:INFO:Memory: svmem(total=17013329920, available=3290251264, percent=80.7, used=13723078656, free=3290251264)
2023-06-14 12:58:58,069:INFO:Physical Core: 4
2023-06-14 12:58:58,069:INFO:Logical Core: 8
2023-06-14 12:58:58,069:INFO:Checking libraries
2023-06-14 12:58:58,069:INFO:System:
2023-06-14 12:58:58,069:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2023-06-14 12:58:58,069:INFO:executable: E:\Machine learning\mini\adam\Scripts\python.exe
2023-06-14 12:58:58,069:INFO:   machine: Windows-10-10.0.22621-SP0
2023-06-14 12:58:58,069:INFO:PyCaret required dependencies:
2023-06-14 12:58:58,069:INFO:                 pip: 23.0.1
2023-06-14 12:58:58,069:INFO:          setuptools: 65.5.0
2023-06-14 12:58:58,069:INFO:             pycaret: 3.0.2
2023-06-14 12:58:58,069:INFO:             IPython: 8.14.0
2023-06-14 12:58:58,069:INFO:          ipywidgets: 8.0.6
2023-06-14 12:58:58,069:INFO:                tqdm: 4.65.0
2023-06-14 12:58:58,069:INFO:               numpy: 1.23.5
2023-06-14 12:58:58,069:INFO:              pandas: 1.5.3
2023-06-14 12:58:58,069:INFO:              jinja2: 3.1.2
2023-06-14 12:58:58,069:INFO:               scipy: 1.10.1
2023-06-14 12:58:58,069:INFO:              joblib: 1.2.0
2023-06-14 12:58:58,069:INFO:             sklearn: 1.2.2
2023-06-14 12:58:58,069:INFO:                pyod: 1.0.9
2023-06-14 12:58:58,070:INFO:            imblearn: 0.10.1
2023-06-14 12:58:58,070:INFO:   category_encoders: 2.6.1
2023-06-14 12:58:58,070:INFO:            lightgbm: 3.3.5
2023-06-14 12:58:58,070:INFO:               numba: 0.57.0
2023-06-14 12:58:58,070:INFO:            requests: 2.31.0
2023-06-14 12:58:58,070:INFO:          matplotlib: 3.7.1
2023-06-14 12:58:58,070:INFO:          scikitplot: 0.3.7
2023-06-14 12:58:58,070:INFO:         yellowbrick: 1.5
2023-06-14 12:58:58,070:INFO:              plotly: 5.15.0
2023-06-14 12:58:58,070:INFO:             kaleido: 0.2.1
2023-06-14 12:58:58,070:INFO:         statsmodels: 0.14.0
2023-06-14 12:58:58,070:INFO:              sktime: 0.17.0
2023-06-14 12:58:58,070:INFO:               tbats: 1.1.3
2023-06-14 12:58:58,070:INFO:            pmdarima: 2.0.3
2023-06-14 12:58:58,070:INFO:              psutil: 5.9.5
2023-06-14 12:58:58,070:INFO:PyCaret optional dependencies:
2023-06-14 12:58:58,083:INFO:                shap: Not installed
2023-06-14 12:58:58,083:INFO:           interpret: Not installed
2023-06-14 12:58:58,083:INFO:                umap: Not installed
2023-06-14 12:58:58,083:INFO:    pandas_profiling: Not installed
2023-06-14 12:58:58,083:INFO:  explainerdashboard: Not installed
2023-06-14 12:58:58,083:INFO:             autoviz: Not installed
2023-06-14 12:58:58,083:INFO:           fairlearn: Not installed
2023-06-14 12:58:58,083:INFO:             xgboost: Not installed
2023-06-14 12:58:58,083:INFO:            catboost: Not installed
2023-06-14 12:58:58,084:INFO:              kmodes: Not installed
2023-06-14 12:58:58,084:INFO:             mlxtend: Not installed
2023-06-14 12:58:58,084:INFO:       statsforecast: Not installed
2023-06-14 12:58:58,084:INFO:        tune_sklearn: Not installed
2023-06-14 12:58:58,084:INFO:                 ray: Not installed
2023-06-14 12:58:58,084:INFO:            hyperopt: Not installed
2023-06-14 12:58:58,084:INFO:              optuna: Not installed
2023-06-14 12:58:58,084:INFO:               skopt: Not installed
2023-06-14 12:58:58,084:INFO:              mlflow: Not installed
2023-06-14 12:58:58,084:INFO:              gradio: Not installed
2023-06-14 12:58:58,084:INFO:             fastapi: Not installed
2023-06-14 12:58:58,084:INFO:             uvicorn: Not installed
2023-06-14 12:58:58,084:INFO:              m2cgen: Not installed
2023-06-14 12:58:58,084:INFO:           evidently: Not installed
2023-06-14 12:58:58,084:INFO:               fugue: Not installed
2023-06-14 12:58:58,084:INFO:           streamlit: Not installed
2023-06-14 12:58:58,084:INFO:             prophet: Not installed
2023-06-14 12:58:58,084:INFO:None
2023-06-14 12:58:58,084:INFO:Set up data.
2023-06-14 12:58:58,208:INFO:Set up train/test split.
2023-06-14 12:58:58,216:INFO:Set up index.
2023-06-14 12:58:58,216:INFO:Set up folding strategy.
2023-06-14 12:58:58,216:INFO:Assigning column types.
2023-06-14 12:58:58,220:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-14 12:58:58,220:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,224:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,229:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,289:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,339:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,355:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,360:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,364:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,460:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,461:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-06-14 12:58:58,465:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,529:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,590:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,594:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,723:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-06-14 12:58:58,736:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,851:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,906:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:58:58,982:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:58,986:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-06-14 12:58:59,087:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:58:59,136:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:58:59,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,137:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,206:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:58:59,252:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-14 12:58:59,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,255:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-14 12:58:59,318:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:58:59,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,441:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-06-14 12:58:59,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,484:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-06-14 12:58:59,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:58:59,813:INFO:Preparing preprocessing pipeline...
2023-06-14 12:58:59,814:INFO:Set up simple imputation.
2023-06-14 12:58:59,858:INFO:Finished creating preprocessing pipeline.
2023-06-14 12:58:59,866:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\adamr\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bid_amount', '0', '1', '2', '3',
                                             '4', '5', '6', '7', '8', '9', '10',
                                             '11', '12', '13', '14', '15', '16',
                                             '17', '18', '19', '20', '21', '22',
                                             '23', '24', '25', '26', '27', '28', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-06-14 12:58:59,866:INFO:Creating final display dataframe.
2023-06-14 12:59:00,083:INFO:Setup _display_container:                     Description             Value
0                    Session id              5043
1                        Target    combined_score
2                   Target type        Regression
3           Original data shape        (211, 597)
4        Transformed data shape        (211, 597)
5   Transformed train set shape        (147, 597)
6    Transformed test set shape         (64, 597)
7              Numeric features               596
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d8e1
2023-06-14 12:59:00,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:59:00,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:59:00,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:59:00,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-14 12:59:00,328:INFO:setup() successfully completed in 2.63s...............
2023-06-14 12:59:00,328:INFO:Initializing compare_models()
2023-06-14 12:59:00,329:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-06-14 12:59:00,329:INFO:Checking exceptions
2023-06-14 12:59:00,332:INFO:Preparing display monitor
2023-06-14 12:59:00,336:INFO:Initializing Linear Regression
2023-06-14 12:59:00,336:INFO:Total runtime is 0.0 minutes
2023-06-14 12:59:00,337:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:00,337:INFO:Initializing create_model()
2023-06-14 12:59:00,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:00,337:INFO:Checking exceptions
2023-06-14 12:59:00,337:INFO:Importing libraries
2023-06-14 12:59:00,337:INFO:Copying training dataset
2023-06-14 12:59:00,346:INFO:Defining folds
2023-06-14 12:59:00,346:INFO:Declaring metric variables
2023-06-14 12:59:00,346:INFO:Importing untrained model
2023-06-14 12:59:00,347:INFO:Linear Regression Imported successfully
2023-06-14 12:59:00,347:INFO:Starting cross validation
2023-06-14 12:59:00,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:10,440:INFO:Calculating mean and std
2023-06-14 12:59:10,441:INFO:Creating metrics dataframe
2023-06-14 12:59:10,950:INFO:Uploading results into container
2023-06-14 12:59:10,951:INFO:Uploading model into container now
2023-06-14 12:59:10,951:INFO:_master_model_container: 1
2023-06-14 12:59:10,951:INFO:_display_container: 2
2023-06-14 12:59:10,951:INFO:LinearRegression(n_jobs=-1)
2023-06-14 12:59:10,952:INFO:create_model() successfully completed......................................
2023-06-14 12:59:11,019:INFO:SubProcess create_model() end ==================================
2023-06-14 12:59:11,019:INFO:Creating metrics dataframe
2023-06-14 12:59:11,024:INFO:Initializing Lasso Regression
2023-06-14 12:59:11,024:INFO:Total runtime is 0.17813617785771688 minutes
2023-06-14 12:59:11,024:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:11,024:INFO:Initializing create_model()
2023-06-14 12:59:11,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:11,024:INFO:Checking exceptions
2023-06-14 12:59:11,024:INFO:Importing libraries
2023-06-14 12:59:11,024:INFO:Copying training dataset
2023-06-14 12:59:11,029:INFO:Defining folds
2023-06-14 12:59:11,030:INFO:Declaring metric variables
2023-06-14 12:59:11,030:INFO:Importing untrained model
2023-06-14 12:59:11,030:INFO:Lasso Regression Imported successfully
2023-06-14 12:59:11,030:INFO:Starting cross validation
2023-06-14 12:59:11,033:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:15,103:INFO:Calculating mean and std
2023-06-14 12:59:15,104:INFO:Creating metrics dataframe
2023-06-14 12:59:15,622:INFO:Uploading results into container
2023-06-14 12:59:15,623:INFO:Uploading model into container now
2023-06-14 12:59:15,623:INFO:_master_model_container: 2
2023-06-14 12:59:15,623:INFO:_display_container: 2
2023-06-14 12:59:15,623:INFO:Lasso(random_state=5043)
2023-06-14 12:59:15,623:INFO:create_model() successfully completed......................................
2023-06-14 12:59:15,685:INFO:SubProcess create_model() end ==================================
2023-06-14 12:59:15,686:INFO:Creating metrics dataframe
2023-06-14 12:59:15,690:INFO:Initializing Ridge Regression
2023-06-14 12:59:15,690:INFO:Total runtime is 0.25590968926747637 minutes
2023-06-14 12:59:15,690:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:15,691:INFO:Initializing create_model()
2023-06-14 12:59:15,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:15,691:INFO:Checking exceptions
2023-06-14 12:59:15,691:INFO:Importing libraries
2023-06-14 12:59:15,691:INFO:Copying training dataset
2023-06-14 12:59:15,695:INFO:Defining folds
2023-06-14 12:59:15,695:INFO:Declaring metric variables
2023-06-14 12:59:15,695:INFO:Importing untrained model
2023-06-14 12:59:15,696:INFO:Ridge Regression Imported successfully
2023-06-14 12:59:15,696:INFO:Starting cross validation
2023-06-14 12:59:15,699:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:19,676:INFO:Calculating mean and std
2023-06-14 12:59:19,676:INFO:Creating metrics dataframe
2023-06-14 12:59:20,167:INFO:Uploading results into container
2023-06-14 12:59:20,168:INFO:Uploading model into container now
2023-06-14 12:59:20,168:INFO:_master_model_container: 3
2023-06-14 12:59:20,168:INFO:_display_container: 2
2023-06-14 12:59:20,168:INFO:Ridge(random_state=5043)
2023-06-14 12:59:20,168:INFO:create_model() successfully completed......................................
2023-06-14 12:59:20,226:INFO:SubProcess create_model() end ==================================
2023-06-14 12:59:20,226:INFO:Creating metrics dataframe
2023-06-14 12:59:20,230:INFO:Initializing Elastic Net
2023-06-14 12:59:20,231:INFO:Total runtime is 0.3315955320994059 minutes
2023-06-14 12:59:20,231:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:20,231:INFO:Initializing create_model()
2023-06-14 12:59:20,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:20,231:INFO:Checking exceptions
2023-06-14 12:59:20,231:INFO:Importing libraries
2023-06-14 12:59:20,231:INFO:Copying training dataset
2023-06-14 12:59:20,237:INFO:Defining folds
2023-06-14 12:59:20,237:INFO:Declaring metric variables
2023-06-14 12:59:20,237:INFO:Importing untrained model
2023-06-14 12:59:20,237:INFO:Elastic Net Imported successfully
2023-06-14 12:59:20,238:INFO:Starting cross validation
2023-06-14 12:59:20,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:24,081:INFO:Calculating mean and std
2023-06-14 12:59:24,082:INFO:Creating metrics dataframe
2023-06-14 12:59:24,575:INFO:Uploading results into container
2023-06-14 12:59:24,575:INFO:Uploading model into container now
2023-06-14 12:59:24,575:INFO:_master_model_container: 4
2023-06-14 12:59:24,577:INFO:_display_container: 2
2023-06-14 12:59:24,577:INFO:ElasticNet(random_state=5043)
2023-06-14 12:59:24,577:INFO:create_model() successfully completed......................................
2023-06-14 12:59:24,634:INFO:SubProcess create_model() end ==================================
2023-06-14 12:59:24,635:INFO:Creating metrics dataframe
2023-06-14 12:59:24,639:INFO:Initializing Least Angle Regression
2023-06-14 12:59:24,639:INFO:Total runtime is 0.4050615032513936 minutes
2023-06-14 12:59:24,639:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:24,639:INFO:Initializing create_model()
2023-06-14 12:59:24,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:24,641:INFO:Checking exceptions
2023-06-14 12:59:24,641:INFO:Importing libraries
2023-06-14 12:59:24,641:INFO:Copying training dataset
2023-06-14 12:59:24,646:INFO:Defining folds
2023-06-14 12:59:24,646:INFO:Declaring metric variables
2023-06-14 12:59:24,646:INFO:Importing untrained model
2023-06-14 12:59:24,646:INFO:Least Angle Regression Imported successfully
2023-06-14 12:59:24,647:INFO:Starting cross validation
2023-06-14 12:59:24,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:24,777:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.097e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.094e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,778:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.076e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,781:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=9.722e-01, with an active set of 45 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,786:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=9.303e-01, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,806:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.040e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,820:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.326e+00, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,822:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=3.802e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,823:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.322e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,823:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.284e+00, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,824:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.302e+00, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,825:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.302e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,830:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=8.240e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,836:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.761e+00, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,838:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.800e+00, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,839:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.800e+00, with an active set of 103 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,840:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=7.454e-01, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,843:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.683e+00, with an active set of 59 regressors, and the smallest cholesky pivot element being 6.166e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,844:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=7.491e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,851:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=7.976e-01, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,854:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.642e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,858:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=2.027e+00, with an active set of 119 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,864:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=8.209e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,867:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=8.007e-01, with an active set of 110 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,868:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.931e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.914e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.595e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.907e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.485e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.563e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.414e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.266e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,869:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.164e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.900e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.768e-01, with an active set of 56 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.861e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.242e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.674e-01, with an active set of 56 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,870:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.858e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.278e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,872:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.829e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.263e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,872:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=5.171e-01, with an active set of 59 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,872:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.067e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,872:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.777e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,872:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.582e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,873:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=5.078e-01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-06-14 12:59:24,873:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.432e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,874:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.407e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,874:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.404e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,874:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.400e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,875:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.363e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.819e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.354e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.324e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=9.312e-01, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.196e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.137e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,876:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.063e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,877:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.056e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,877:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.991e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,878:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.991e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,878:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.989e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,879:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=3.269e+02, with an active set of 101 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,879:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.969e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,879:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=9.362e-01, with an active set of 125 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,879:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.965e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,879:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.894e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.563e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,880:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.010e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,880:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.886e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.936e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,880:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.010e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,881:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.866e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,882:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.827e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.088e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,882:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.826e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,882:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.791e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.889e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.779e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.843e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=9.353e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=9.353e-01, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,883:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.762e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.749e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.708e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.679e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.343e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.389e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.671e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.343e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.819e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,884:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.661e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,886:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=4.816e-01, with an active set of 82 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(


2023-06-14 12:59:24,886:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.654e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,887:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.626e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.767e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,887:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=3.052e-01, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,887:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.624e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.936e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,888:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.533e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,888:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.921e-01, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,888:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.530e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,889:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=3.269e+02, with an active set of 105 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,889:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.509e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,890:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.501e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,890:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.470e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,890:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=2.454e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,892:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.727e-01, with an active set of 89 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,892:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.393e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.795e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,892:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.341e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,893:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.340e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,893:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.309e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.726e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,893:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.292e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,894:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.346e-01, with an active set of 48 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,894:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.273e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,894:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.253e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.244e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.767e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.222e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.744e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,895:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.220e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.094e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,896:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=2.210e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.928e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,902:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=1.709e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,903:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.454e-01, with an active set of 60 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,906:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.722e+00, with an active set of 93 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,906:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=5.328e+02, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.634e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,907:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.716e+00, with an active set of 97 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,916:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=2.303e+00, with an active set of 110 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,917:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.602e+00, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,918:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=2.298e+00, with an active set of 112 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,919:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=1.590e+00, with an active set of 84 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,921:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.230e+00, with an active set of 123 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,923:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=1.230e+00, with an active set of 124 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,927:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=7.178e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,934:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=8.460e+01, with an active set of 122 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,939:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.831e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.656e+02, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=1.844e+00, with an active set of 112 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,944:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.656e+02, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.396e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,946:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.565e+02, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.990e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,948:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=1.843e+00, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,950:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.506e+02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,952:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.350e+02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,952:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.327e+02, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,952:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.223e+02, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.380e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,963:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.587e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,964:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.508e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,964:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.461e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,965:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.415e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,965:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.404e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,966:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.393e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,966:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.371e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,966:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.364e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,967:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.364e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,967:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.314e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,967:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.303e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,968:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.298e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.042e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,968:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.288e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,968:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.238e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,969:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.207e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,969:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.200e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,969:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.160e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,971:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.089e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,971:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.059e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,972:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.020e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,972:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.984e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,972:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.939e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,973:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.938e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.998e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,973:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.929e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,974:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.907e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,974:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.882e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,974:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.880e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,975:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.878e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.007e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,975:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.840e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,975:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.833e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,976:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.819e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,976:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.803e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,977:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.794e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,977:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.785e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,978:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.779e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,978:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.765e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.631e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,980:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.744e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,981:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.741e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,981:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.734e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,982:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.728e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,982:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.726e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,983:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.722e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,983:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.716e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.563e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.710e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.708e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.936e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.688e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.674e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.671e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,984:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.670e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,986:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.666e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,986:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.659e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,986:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.642e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,986:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.609e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,986:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.599e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,987:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.581e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,987:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.562e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,987:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.562e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,988:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.555e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,988:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.551e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,988:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.540e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,988:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.540e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,989:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.535e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,989:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.534e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,989:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.525e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,990:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.524e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,990:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.480e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,990:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.476e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,990:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.472e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,991:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.452e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,991:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.433e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,991:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.414e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,992:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.413e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,993:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.407e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,993:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.390e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,994:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.388e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,994:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.388e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,996:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.387e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,996:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.384e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,997:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.380e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,997:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.378e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,997:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.371e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:24,998:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.371e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.211e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,018:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.367e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,019:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.355e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,019:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.348e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,020:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.334e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,020:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.323e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,021:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.318e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,021:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.308e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,022:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.306e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,022:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.304e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,022:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.301e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,023:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.292e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,023:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.287e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,023:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.251e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.326e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,024:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.248e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,024:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.234e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,024:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.230e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,024:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.226e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,025:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.225e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,025:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.217e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.853e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,025:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.215e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,026:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.194e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,026:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.183e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,026:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.181e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,027:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.172e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,027:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.167e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,028:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.165e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,028:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.147e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,028:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.145e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,029:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.130e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,029:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.128e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,029:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.105e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,030:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.082e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,030:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.080e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,030:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.071e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,031:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.042e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,031:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.042e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,031:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.039e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,032:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.034e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.957e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,032:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.011e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,032:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.003e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.266e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,033:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.001e+00, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,033:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.985e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,033:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.954e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,034:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.942e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,034:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.827e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,035:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.788e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,035:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.648e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,036:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.541e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,036:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.513e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.499e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,036:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.392e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,037:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.328e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,037:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.271e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,037:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.242e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,037:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.012e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,038:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.832e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,038:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.802e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,038:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.690e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,039:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.578e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,039:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.574e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,039:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.473e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,040:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.457e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,040:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.345e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,040:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.327e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,041:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.288e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,041:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.249e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.166e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,041:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.195e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,042:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.172e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,043:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.093e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,044:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.011e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,046:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.977e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,046:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.817e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,047:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.751e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,048:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.681e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,050:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.480e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,051:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.480e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,052:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.144e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,052:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.093e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,052:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.070e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,053:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.006e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,053:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.997e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,054:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.949e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,054:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.894e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,054:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.709e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,054:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.679e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,056:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.665e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,057:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.489e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,057:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.240e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,059:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.230e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,059:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.228e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.699e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,059:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.194e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,060:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.094e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,060:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.986e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,061:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.932e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,061:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.845e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,062:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.819e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,062:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.788e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,063:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.593e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,063:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.555e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,064:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.383e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,064:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.369e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,064:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.357e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,065:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.317e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,065:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.310e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,066:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.234e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.742e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,066:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.194e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,066:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.136e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,066:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.104e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,066:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.012e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,067:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.998e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,068:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.985e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.660e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,068:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.984e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,068:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.927e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.140e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,069:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.864e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,069:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.775e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,069:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.554e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,069:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.503e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,069:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.500e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,071:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.495e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,071:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.489e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,071:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.415e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,071:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.392e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,072:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.312e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.385e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,073:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.267e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,074:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.152e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,075:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.118e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,075:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.039e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,075:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.003e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,076:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.984e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,076:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.969e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.499e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,076:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.961e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,076:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.960e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,077:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.944e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,077:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.908e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,077:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.839e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.813e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.006e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.742e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,079:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.706e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.385e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,080:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.681e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,080:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.675e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.396e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,080:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.610e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,081:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.529e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,081:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.489e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,082:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.475e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 8.737e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,082:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.446e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,083:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.341e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,083:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.200e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,083:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.200e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,084:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.184e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,084:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.135e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,084:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.102e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.087e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.488e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.078e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.540e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.994e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.969e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,087:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.903e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,088:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.858e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,089:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.852e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,089:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.562e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,089:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.549e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,090:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.447e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,090:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.414e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,091:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.401e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,097:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.360e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,097:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.357e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,098:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.230e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,098:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.207e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,099:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.198e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,099:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.191e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 5.890e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,100:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.072e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,100:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.031e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.385e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,101:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.014e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,101:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.868e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,101:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.834e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,101:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.798e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,103:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.793e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,103:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.784e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,103:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.778e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.561e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.376e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.278e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.204e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.267e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,105:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.249e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,105:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.237e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,105:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.190e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,106:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.179e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,106:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.067e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.536e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,106:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.033e-01, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,106:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.938e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,107:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.231e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,107:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=7.726e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,107:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=6.902e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.608e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,107:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.799e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,108:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.548e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,108:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.118e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,108:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=5.041e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 9.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,109:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.509e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,109:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.446e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,110:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.293e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.074e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,110:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.067e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,110:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.409e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,111:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.720e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,111:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.349e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,112:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.173e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,112:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.808e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,112:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.781e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,113:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.303e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,113:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.152e-02, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,113:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=9.192e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,114:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=8.515e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,114:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.634e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,114:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=3.542e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.861e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,114:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=2.046e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:25,116:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.809e-03, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,046:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:59:26,073:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:59:26,234:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 12:59:26,945:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.160e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,950:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.052e+00, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,958:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.050e+00, with an active set of 60 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,964:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.054e+00, with an active set of 70 regressors, and the smallest cholesky pivot element being 8.246e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,969:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.034e+00, with an active set of 78 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,971:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.036e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,971:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.031e+00, with an active set of 81 regressors, and the smallest cholesky pivot element being 3.094e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,972:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.031e+00, with an active set of 81 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,976:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.018e+00, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,979:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=1.010e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,982:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.007e+00, with an active set of 96 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,987:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=9.930e-01, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,992:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 139 iterations, i.e. alpha=1.439e+00, with an active set of 110 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:26,999:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.677e+00, with an active set of 122 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,007:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.018e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,009:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.318e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,009:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.003e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.998e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,010:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.003e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,010:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.988e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.970e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,010:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.955e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,011:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.871e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,011:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.846e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,012:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.813e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,012:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.775e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,013:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.773e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,013:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.768e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.623e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,013:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.759e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,014:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.718e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.233e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,014:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.714e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,014:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.630e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,014:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.601e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.879e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,015:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.595e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.706e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,015:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.541e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.634e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,016:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.539e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.949e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,016:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.535e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,017:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.497e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,017:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.455e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,017:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.450e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,018:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.436e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.683e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,018:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.432e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,019:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.431e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.796e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,019:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.425e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,019:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.415e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,020:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.414e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,020:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.413e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,021:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.409e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.115e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,021:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.403e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.819e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,021:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.396e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,022:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.372e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.435e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,022:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.358e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,022:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.347e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,023:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.342e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,023:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.340e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,023:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.334e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,024:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.320e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,024:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.315e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,024:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.300e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,024:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.299e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,024:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.299e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,025:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.287e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,025:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.280e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.998e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,025:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.276e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,026:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.274e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.956e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,026:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.274e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.849e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,027:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.239e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,027:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.237e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,028:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.234e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,028:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.220e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,028:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.200e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,029:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.196e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.205e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,029:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.188e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,029:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.185e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,030:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.185e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,030:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.165e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,030:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.157e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,031:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.150e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,031:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.141e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.247e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,032:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.115e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,032:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.112e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,032:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.111e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,033:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.108e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,033:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.104e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,033:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.085e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,034:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.084e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,034:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.083e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,034:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.080e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,035:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.080e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,036:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.076e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,036:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.070e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,037:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.051e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,037:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.050e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,037:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.045e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,038:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.040e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,042:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.037e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,042:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.035e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,043:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.032e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,043:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.032e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.628e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,044:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.023e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,044:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.022e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,044:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.022e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.443e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,044:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.021e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,044:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.013e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.269e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,046:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.011e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,046:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=1.011e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,046:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.975e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,046:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.930e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,047:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.925e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,047:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.914e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,048:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.888e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,048:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.881e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,049:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.880e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,049:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.870e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,049:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.842e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.376e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,049:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.839e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,050:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.831e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,050:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.684e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.969e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,050:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.683e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,050:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.623e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,051:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.566e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,051:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.557e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,051:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.474e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,051:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.402e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,052:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.332e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,052:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.326e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.570e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,052:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.138e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.030e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,052:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.060e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,054:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.028e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,054:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=9.008e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,054:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.871e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,054:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.858e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.847e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,055:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.727e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,055:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.712e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.623e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,055:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.707e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,056:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.669e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,056:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.667e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,056:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.638e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.853e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,057:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.582e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,057:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.557e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,057:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.470e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.431e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,058:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.462e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,058:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.459e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.330e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,058:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.395e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,059:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.351e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.117e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,059:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.339e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,059:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=8.249e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,060:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.999e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.115e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,060:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.987e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,060:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.967e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,061:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.954e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.752e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,061:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.925e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.396e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,062:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.918e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,062:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.837e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.972e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,063:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.736e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.296e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,064:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.733e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,064:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.723e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,065:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.693e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,065:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.689e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,066:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.667e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,066:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.634e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,066:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.486e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,067:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.396e-01, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.890e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,069:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.367e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.981e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,071:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.366e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.819e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,071:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.294e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,071:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.283e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,072:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.155e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,072:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.138e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,072:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.077e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,072:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.071e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,073:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.039e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,073:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.003e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.686e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,074:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.997e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,074:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.929e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,074:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.834e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.622e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,074:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.819e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,075:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.787e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,075:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.782e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,076:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.728e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,076:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.624e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,076:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.607e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,077:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.523e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,077:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.510e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,077:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.397e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.242e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 9.856e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.200e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.098e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,078:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.194e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.357e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,079:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.145e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,079:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.008e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,080:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.962e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.128e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,080:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.909e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,080:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.904e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,081:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.862e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.166e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,081:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.836e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,082:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.831e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,082:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.813e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.455e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,082:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.692e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,083:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.613e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,083:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.594e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.175e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,083:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.538e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.563e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,084:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.436e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.420e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,084:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.394e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,084:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.232e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.573e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,084:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.211e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,084:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.104e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.867e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.082e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.062e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.990e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.781e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.925e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,086:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.746e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,087:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.711e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,087:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.665e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,087:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.549e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.857e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,087:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.537e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.527e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,088:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.464e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.910e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,088:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.410e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,088:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.346e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.127e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,089:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.264e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.026e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,089:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.212e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.881e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,089:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.204e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,090:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.162e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.231e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,090:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.145e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.835e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,091:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.095e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,091:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.033e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,092:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.007e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,092:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.904e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 8.347e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,092:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.816e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.634e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,093:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.730e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.211e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,093:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.631e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,093:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.556e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,094:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.374e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,094:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.303e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,094:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.271e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,094:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.254e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,094:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.186e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,096:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.121e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.624e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,097:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.898e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,098:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.863e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,098:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.801e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.525e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,098:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.795e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,099:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.766e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,099:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.667e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,099:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.666e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,100:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.609e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.534e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,100:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.529e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.861e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,100:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.476e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,101:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.454e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,101:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.452e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,102:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.422e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,102:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.237e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,103:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.181e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,103:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.123e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.863e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.098e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.280e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.077e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.046e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.038e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.725e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,104:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.989e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,105:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.915e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,105:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.840e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,105:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.803e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,106:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.769e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.486e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,106:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.742e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.469e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,106:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.708e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,107:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.698e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,108:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.693e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,108:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.675e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.971e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,108:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.653e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.747e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,109:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.642e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.231e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,109:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.576e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,110:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.535e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,110:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.423e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,110:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.412e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.326e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,111:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.363e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.763e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,111:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.336e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.321e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,111:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.316e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,111:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.276e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.723e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,112:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.255e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,112:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.234e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,113:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.202e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,113:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.191e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,113:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.170e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,114:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.057e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,114:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.028e-01, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,118:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=1.147e-01, with an active set of 132 regressors, and the smallest cholesky pivot element being 5.819e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,338:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.047e-01, with an active set of 47 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,346:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=8.359e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,346:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=8.359e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.118e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,347:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=7.764e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,352:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=8.020e-01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,354:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=8.140e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,356:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=8.058e-01, with an active set of 74 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,356:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=8.058e-01, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,356:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=7.881e-01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,357:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=7.751e-01, with an active set of 80 regressors, and the smallest cholesky pivot element being 4.638e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,359:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=7.566e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,359:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=7.559e-01, with an active set of 86 regressors, and the smallest cholesky pivot element being 6.949e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,362:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=7.854e-01, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.933e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,368:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=6.167e+00, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,379:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.864e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,380:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.863e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.350e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,380:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.507e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,380:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.392e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 5.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,380:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.369e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,380:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.284e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 9.125e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,381:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.168e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,381:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=7.145e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.172e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,381:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.856e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,382:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.665e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,382:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.530e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,382:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.474e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,382:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.408e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,383:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.291e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 6.622e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,383:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.118e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.451e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,384:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=6.008e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,384:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.884e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.290e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,384:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.877e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 8.910e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,385:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.840e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.623e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,385:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.840e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,387:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.793e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,387:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.783e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.263e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,388:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.755e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,388:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.731e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.949e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,388:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.678e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,389:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.647e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,389:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.643e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,389:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.634e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.178e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,390:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.604e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.394e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,390:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.526e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,390:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.514e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,391:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.440e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,391:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.393e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,391:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.304e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.243e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,391:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.289e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,392:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.059e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,392:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=5.013e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,392:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.936e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.688e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,393:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.876e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,393:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.816e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,393:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.757e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.236e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,393:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.700e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,394:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.654e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,394:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.632e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.471e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,394:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.490e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.837e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,395:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.477e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.248e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,395:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.477e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,395:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.447e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,395:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.432e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,396:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.395e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,396:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.389e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,396:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.388e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,396:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.373e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,396:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.346e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,397:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.326e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,397:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.290e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,397:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.245e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,397:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.228e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.554e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,398:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.207e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.408e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,398:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.179e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,399:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.157e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.653e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,399:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.154e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,399:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.146e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.623e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,400:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.137e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,400:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.135e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,400:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.130e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,401:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.117e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,401:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=4.063e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,401:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.979e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.268e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,402:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.942e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.707e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,402:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.936e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,402:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.932e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,402:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.900e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.871e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,402:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.871e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,402:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.840e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,404:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.736e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.076e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,404:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.711e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.957e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,404:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.691e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,404:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.626e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.856e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,404:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.591e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 9.095e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,404:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.584e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 8.737e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,405:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.584e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.003e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,405:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.511e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.414e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,405:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.493e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.235e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,405:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.486e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.452e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,405:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.468e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.121e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,405:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.441e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.427e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.666e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.425e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.390e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.389e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.361e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.351e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.332e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.900e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.328e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 6.969e-09. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,406:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.316e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,407:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.313e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,407:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.299e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.716e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,408:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.275e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.612e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,408:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.272e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,408:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.216e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,408:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.198e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.012e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,408:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.152e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 7.607e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,408:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.111e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.886e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,409:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.079e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.762e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,409:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.077e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.040e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,409:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.075e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.098e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,409:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.058e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,409:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.058e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,409:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.033e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,410:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=3.026e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,410:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=3.021e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.725e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,410:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.991e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,410:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.947e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.978e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,410:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.940e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 4.148e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,411:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.926e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,411:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.905e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,411:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.895e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,411:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.874e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,411:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.856e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,412:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.834e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.625e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,412:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.829e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.108e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,412:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.774e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:27,412:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.768e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 6.622e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:29,992:INFO:Calculating mean and std
2023-06-14 12:59:29,992:INFO:Creating metrics dataframe
2023-06-14 12:59:30,500:INFO:Uploading results into container
2023-06-14 12:59:30,501:INFO:Uploading model into container now
2023-06-14 12:59:30,501:INFO:_master_model_container: 5
2023-06-14 12:59:30,501:INFO:_display_container: 2
2023-06-14 12:59:30,501:INFO:Lars(random_state=5043)
2023-06-14 12:59:30,502:INFO:create_model() successfully completed......................................
2023-06-14 12:59:30,567:INFO:SubProcess create_model() end ==================================
2023-06-14 12:59:30,567:INFO:Creating metrics dataframe
2023-06-14 12:59:30,573:INFO:Initializing Lasso Least Angle Regression
2023-06-14 12:59:30,573:INFO:Total runtime is 0.5039482434590657 minutes
2023-06-14 12:59:30,573:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:30,573:INFO:Initializing create_model()
2023-06-14 12:59:30,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:30,573:INFO:Checking exceptions
2023-06-14 12:59:30,574:INFO:Importing libraries
2023-06-14 12:59:30,574:INFO:Copying training dataset
2023-06-14 12:59:30,578:INFO:Defining folds
2023-06-14 12:59:30,578:INFO:Declaring metric variables
2023-06-14 12:59:30,578:INFO:Importing untrained model
2023-06-14 12:59:30,579:INFO:Lasso Least Angle Regression Imported successfully
2023-06-14 12:59:30,579:INFO:Starting cross validation
2023-06-14 12:59:30,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:30,769:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_least_angle.py:648: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.642e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 3.072e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-06-14 12:59:34,677:INFO:Calculating mean and std
2023-06-14 12:59:34,679:INFO:Creating metrics dataframe
2023-06-14 12:59:35,182:INFO:Uploading results into container
2023-06-14 12:59:35,183:INFO:Uploading model into container now
2023-06-14 12:59:35,183:INFO:_master_model_container: 6
2023-06-14 12:59:35,183:INFO:_display_container: 2
2023-06-14 12:59:35,184:INFO:LassoLars(random_state=5043)
2023-06-14 12:59:35,184:INFO:create_model() successfully completed......................................
2023-06-14 12:59:35,247:INFO:SubProcess create_model() end ==================================
2023-06-14 12:59:35,247:INFO:Creating metrics dataframe
2023-06-14 12:59:35,252:INFO:Initializing Orthogonal Matching Pursuit
2023-06-14 12:59:35,252:INFO:Total runtime is 0.5819416443506876 minutes
2023-06-14 12:59:35,253:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:35,253:INFO:Initializing create_model()
2023-06-14 12:59:35,253:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:35,253:INFO:Checking exceptions
2023-06-14 12:59:35,253:INFO:Importing libraries
2023-06-14 12:59:35,253:INFO:Copying training dataset
2023-06-14 12:59:35,258:INFO:Defining folds
2023-06-14 12:59:35,259:INFO:Declaring metric variables
2023-06-14 12:59:35,259:INFO:Importing untrained model
2023-06-14 12:59:35,259:INFO:Orthogonal Matching Pursuit Imported successfully
2023-06-14 12:59:35,260:INFO:Starting cross validation
2023-06-14 12:59:35,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:39,759:INFO:Calculating mean and std
2023-06-14 12:59:39,759:INFO:Creating metrics dataframe
2023-06-14 12:59:40,273:INFO:Uploading results into container
2023-06-14 12:59:40,273:INFO:Uploading model into container now
2023-06-14 12:59:40,274:INFO:_master_model_container: 7
2023-06-14 12:59:40,274:INFO:_display_container: 2
2023-06-14 12:59:40,274:INFO:OrthogonalMatchingPursuit()
2023-06-14 12:59:40,274:INFO:create_model() successfully completed......................................
2023-06-14 12:59:40,338:INFO:SubProcess create_model() end ==================================
2023-06-14 12:59:40,338:INFO:Creating metrics dataframe
2023-06-14 12:59:40,342:INFO:Initializing Bayesian Ridge
2023-06-14 12:59:40,342:INFO:Total runtime is 0.6667770663897196 minutes
2023-06-14 12:59:40,342:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:40,343:INFO:Initializing create_model()
2023-06-14 12:59:40,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:40,343:INFO:Checking exceptions
2023-06-14 12:59:40,343:INFO:Importing libraries
2023-06-14 12:59:40,343:INFO:Copying training dataset
2023-06-14 12:59:40,348:INFO:Defining folds
2023-06-14 12:59:40,348:INFO:Declaring metric variables
2023-06-14 12:59:40,348:INFO:Importing untrained model
2023-06-14 12:59:40,349:INFO:Bayesian Ridge Imported successfully
2023-06-14 12:59:40,349:INFO:Starting cross validation
2023-06-14 12:59:40,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:44,377:INFO:Calculating mean and std
2023-06-14 12:59:44,378:INFO:Creating metrics dataframe
2023-06-14 12:59:44,882:INFO:Uploading results into container
2023-06-14 12:59:44,882:INFO:Uploading model into container now
2023-06-14 12:59:44,883:INFO:_master_model_container: 8
2023-06-14 12:59:44,883:INFO:_display_container: 2
2023-06-14 12:59:44,883:INFO:BayesianRidge()
2023-06-14 12:59:44,883:INFO:create_model() successfully completed......................................
2023-06-14 12:59:44,946:INFO:SubProcess create_model() end ==================================
2023-06-14 12:59:44,946:INFO:Creating metrics dataframe
2023-06-14 12:59:44,950:INFO:Initializing Passive Aggressive Regressor
2023-06-14 12:59:44,950:INFO:Total runtime is 0.7435691197713216 minutes
2023-06-14 12:59:44,951:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:44,951:INFO:Initializing create_model()
2023-06-14 12:59:44,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:44,951:INFO:Checking exceptions
2023-06-14 12:59:44,951:INFO:Importing libraries
2023-06-14 12:59:44,951:INFO:Copying training dataset
2023-06-14 12:59:44,956:INFO:Defining folds
2023-06-14 12:59:44,956:INFO:Declaring metric variables
2023-06-14 12:59:44,956:INFO:Importing untrained model
2023-06-14 12:59:44,956:INFO:Passive Aggressive Regressor Imported successfully
2023-06-14 12:59:44,957:INFO:Starting cross validation
2023-06-14 12:59:44,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:49,173:INFO:Calculating mean and std
2023-06-14 12:59:49,174:INFO:Creating metrics dataframe
2023-06-14 12:59:49,709:INFO:Uploading results into container
2023-06-14 12:59:49,709:INFO:Uploading model into container now
2023-06-14 12:59:49,710:INFO:_master_model_container: 9
2023-06-14 12:59:49,710:INFO:_display_container: 2
2023-06-14 12:59:49,710:INFO:PassiveAggressiveRegressor(random_state=5043)
2023-06-14 12:59:49,711:INFO:create_model() successfully completed......................................
2023-06-14 12:59:49,792:INFO:SubProcess create_model() end ==================================
2023-06-14 12:59:49,792:INFO:Creating metrics dataframe
2023-06-14 12:59:49,797:INFO:Initializing Huber Regressor
2023-06-14 12:59:49,797:INFO:Total runtime is 0.824360696474711 minutes
2023-06-14 12:59:49,797:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:49,797:INFO:Initializing create_model()
2023-06-14 12:59:49,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:49,798:INFO:Checking exceptions
2023-06-14 12:59:49,798:INFO:Importing libraries
2023-06-14 12:59:49,798:INFO:Copying training dataset
2023-06-14 12:59:49,803:INFO:Defining folds
2023-06-14 12:59:49,803:INFO:Declaring metric variables
2023-06-14 12:59:49,803:INFO:Importing untrained model
2023-06-14 12:59:49,804:INFO:Huber Regressor Imported successfully
2023-06-14 12:59:49,804:INFO:Starting cross validation
2023-06-14 12:59:49,805:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:50,131:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:59:50,171:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:59:50,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:59:50,192:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:59:50,205:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:59:50,225:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:59:51,786:WARNING:E:\Machine learning\mini\adam\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-06-14 12:59:54,682:INFO:Calculating mean and std
2023-06-14 12:59:54,682:INFO:Creating metrics dataframe
2023-06-14 12:59:55,236:INFO:Uploading results into container
2023-06-14 12:59:55,236:INFO:Uploading model into container now
2023-06-14 12:59:55,237:INFO:_master_model_container: 10
2023-06-14 12:59:55,237:INFO:_display_container: 2
2023-06-14 12:59:55,237:INFO:HuberRegressor()
2023-06-14 12:59:55,237:INFO:create_model() successfully completed......................................
2023-06-14 12:59:55,296:INFO:SubProcess create_model() end ==================================
2023-06-14 12:59:55,296:INFO:Creating metrics dataframe
2023-06-14 12:59:55,301:INFO:Initializing K Neighbors Regressor
2023-06-14 12:59:55,301:INFO:Total runtime is 0.9160952925682067 minutes
2023-06-14 12:59:55,301:INFO:SubProcess create_model() called ==================================
2023-06-14 12:59:55,301:INFO:Initializing create_model()
2023-06-14 12:59:55,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 12:59:55,302:INFO:Checking exceptions
2023-06-14 12:59:55,302:INFO:Importing libraries
2023-06-14 12:59:55,302:INFO:Copying training dataset
2023-06-14 12:59:55,307:INFO:Defining folds
2023-06-14 12:59:55,307:INFO:Declaring metric variables
2023-06-14 12:59:55,307:INFO:Importing untrained model
2023-06-14 12:59:55,307:INFO:K Neighbors Regressor Imported successfully
2023-06-14 12:59:55,307:INFO:Starting cross validation
2023-06-14 12:59:55,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 12:59:59,951:INFO:Calculating mean and std
2023-06-14 12:59:59,952:INFO:Creating metrics dataframe
2023-06-14 13:00:00,556:INFO:Uploading results into container
2023-06-14 13:00:00,556:INFO:Uploading model into container now
2023-06-14 13:00:00,557:INFO:_master_model_container: 11
2023-06-14 13:00:00,557:INFO:_display_container: 2
2023-06-14 13:00:00,557:INFO:KNeighborsRegressor(n_jobs=-1)
2023-06-14 13:00:00,557:INFO:create_model() successfully completed......................................
2023-06-14 13:00:00,619:INFO:SubProcess create_model() end ==================================
2023-06-14 13:00:00,619:INFO:Creating metrics dataframe
2023-06-14 13:00:00,624:INFO:Initializing Decision Tree Regressor
2023-06-14 13:00:00,624:INFO:Total runtime is 1.004800510406494 minutes
2023-06-14 13:00:00,624:INFO:SubProcess create_model() called ==================================
2023-06-14 13:00:00,625:INFO:Initializing create_model()
2023-06-14 13:00:00,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 13:00:00,625:INFO:Checking exceptions
2023-06-14 13:00:00,625:INFO:Importing libraries
2023-06-14 13:00:00,625:INFO:Copying training dataset
2023-06-14 13:00:00,630:INFO:Defining folds
2023-06-14 13:00:00,630:INFO:Declaring metric variables
2023-06-14 13:00:00,631:INFO:Importing untrained model
2023-06-14 13:00:00,631:INFO:Decision Tree Regressor Imported successfully
2023-06-14 13:00:00,631:INFO:Starting cross validation
2023-06-14 13:00:00,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 13:00:04,946:INFO:Calculating mean and std
2023-06-14 13:00:04,946:INFO:Creating metrics dataframe
2023-06-14 13:00:05,482:INFO:Uploading results into container
2023-06-14 13:00:05,482:INFO:Uploading model into container now
2023-06-14 13:00:05,482:INFO:_master_model_container: 12
2023-06-14 13:00:05,483:INFO:_display_container: 2
2023-06-14 13:00:05,483:INFO:DecisionTreeRegressor(random_state=5043)
2023-06-14 13:00:05,483:INFO:create_model() successfully completed......................................
2023-06-14 13:00:05,560:INFO:SubProcess create_model() end ==================================
2023-06-14 13:00:05,560:INFO:Creating metrics dataframe
2023-06-14 13:00:05,566:INFO:Initializing Random Forest Regressor
2023-06-14 13:00:05,566:INFO:Total runtime is 1.0871755560239156 minutes
2023-06-14 13:00:05,566:INFO:SubProcess create_model() called ==================================
2023-06-14 13:00:05,566:INFO:Initializing create_model()
2023-06-14 13:00:05,566:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 13:00:05,566:INFO:Checking exceptions
2023-06-14 13:00:05,566:INFO:Importing libraries
2023-06-14 13:00:05,566:INFO:Copying training dataset
2023-06-14 13:00:05,573:INFO:Defining folds
2023-06-14 13:00:05,573:INFO:Declaring metric variables
2023-06-14 13:00:05,573:INFO:Importing untrained model
2023-06-14 13:00:05,574:INFO:Random Forest Regressor Imported successfully
2023-06-14 13:00:05,574:INFO:Starting cross validation
2023-06-14 13:00:05,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 13:00:07,182:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 13:00:07,193:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 13:00:07,193:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 13:00:11,743:INFO:Calculating mean and std
2023-06-14 13:00:11,743:INFO:Creating metrics dataframe
2023-06-14 13:00:12,304:INFO:Uploading results into container
2023-06-14 13:00:12,304:INFO:Uploading model into container now
2023-06-14 13:00:12,304:INFO:_master_model_container: 13
2023-06-14 13:00:12,304:INFO:_display_container: 2
2023-06-14 13:00:12,306:INFO:RandomForestRegressor(n_jobs=-1, random_state=5043)
2023-06-14 13:00:12,306:INFO:create_model() successfully completed......................................
2023-06-14 13:00:12,364:INFO:SubProcess create_model() end ==================================
2023-06-14 13:00:12,365:INFO:Creating metrics dataframe
2023-06-14 13:00:12,369:INFO:Initializing Extra Trees Regressor
2023-06-14 13:00:12,369:INFO:Total runtime is 1.2005531946818033 minutes
2023-06-14 13:00:12,370:INFO:SubProcess create_model() called ==================================
2023-06-14 13:00:12,370:INFO:Initializing create_model()
2023-06-14 13:00:12,370:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 13:00:12,370:INFO:Checking exceptions
2023-06-14 13:00:12,370:INFO:Importing libraries
2023-06-14 13:00:12,370:INFO:Copying training dataset
2023-06-14 13:00:12,375:INFO:Defining folds
2023-06-14 13:00:12,375:INFO:Declaring metric variables
2023-06-14 13:00:12,376:INFO:Importing untrained model
2023-06-14 13:00:12,376:INFO:Extra Trees Regressor Imported successfully
2023-06-14 13:00:12,376:INFO:Starting cross validation
2023-06-14 13:00:12,378:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 13:00:13,684:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 13:00:13,745:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 13:00:13,745:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 13:00:13,761:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 13:00:13,762:WARNING:E:\Machine learning\mini\adam\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-14 13:00:18,121:INFO:Calculating mean and std
2023-06-14 13:00:18,122:INFO:Creating metrics dataframe
2023-06-14 13:00:18,732:INFO:Uploading results into container
2023-06-14 13:00:18,733:INFO:Uploading model into container now
2023-06-14 13:00:18,733:INFO:_master_model_container: 14
2023-06-14 13:00:18,733:INFO:_display_container: 2
2023-06-14 13:00:18,733:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5043)
2023-06-14 13:00:18,733:INFO:create_model() successfully completed......................................
2023-06-14 13:00:18,793:INFO:SubProcess create_model() end ==================================
2023-06-14 13:00:18,793:INFO:Creating metrics dataframe
2023-06-14 13:00:18,798:INFO:Initializing AdaBoost Regressor
2023-06-14 13:00:18,798:INFO:Total runtime is 1.3077125151952107 minutes
2023-06-14 13:00:18,798:INFO:SubProcess create_model() called ==================================
2023-06-14 13:00:18,798:INFO:Initializing create_model()
2023-06-14 13:00:18,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 13:00:18,798:INFO:Checking exceptions
2023-06-14 13:00:18,799:INFO:Importing libraries
2023-06-14 13:00:18,799:INFO:Copying training dataset
2023-06-14 13:00:18,804:INFO:Defining folds
2023-06-14 13:00:18,804:INFO:Declaring metric variables
2023-06-14 13:00:18,804:INFO:Importing untrained model
2023-06-14 13:00:18,804:INFO:AdaBoost Regressor Imported successfully
2023-06-14 13:00:18,804:INFO:Starting cross validation
2023-06-14 13:00:18,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 13:00:23,760:INFO:Calculating mean and std
2023-06-14 13:00:23,761:INFO:Creating metrics dataframe
2023-06-14 13:00:24,299:INFO:Uploading results into container
2023-06-14 13:00:24,300:INFO:Uploading model into container now
2023-06-14 13:00:24,300:INFO:_master_model_container: 15
2023-06-14 13:00:24,300:INFO:_display_container: 2
2023-06-14 13:00:24,300:INFO:AdaBoostRegressor(random_state=5043)
2023-06-14 13:00:24,300:INFO:create_model() successfully completed......................................
2023-06-14 13:00:24,359:INFO:SubProcess create_model() end ==================================
2023-06-14 13:00:24,359:INFO:Creating metrics dataframe
2023-06-14 13:00:24,364:INFO:Initializing Gradient Boosting Regressor
2023-06-14 13:00:24,364:INFO:Total runtime is 1.4004690368970234 minutes
2023-06-14 13:00:24,364:INFO:SubProcess create_model() called ==================================
2023-06-14 13:00:24,364:INFO:Initializing create_model()
2023-06-14 13:00:24,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 13:00:24,364:INFO:Checking exceptions
2023-06-14 13:00:24,364:INFO:Importing libraries
2023-06-14 13:00:24,364:INFO:Copying training dataset
2023-06-14 13:00:24,369:INFO:Defining folds
2023-06-14 13:00:24,369:INFO:Declaring metric variables
2023-06-14 13:00:24,370:INFO:Importing untrained model
2023-06-14 13:00:24,370:INFO:Gradient Boosting Regressor Imported successfully
2023-06-14 13:00:24,370:INFO:Starting cross validation
2023-06-14 13:00:24,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 13:00:29,700:INFO:Calculating mean and std
2023-06-14 13:00:29,701:INFO:Creating metrics dataframe
2023-06-14 13:00:30,266:INFO:Uploading results into container
2023-06-14 13:00:30,266:INFO:Uploading model into container now
2023-06-14 13:00:30,268:INFO:_master_model_container: 16
2023-06-14 13:00:30,268:INFO:_display_container: 2
2023-06-14 13:00:30,268:INFO:GradientBoostingRegressor(random_state=5043)
2023-06-14 13:00:30,268:INFO:create_model() successfully completed......................................
2023-06-14 13:00:30,328:INFO:SubProcess create_model() end ==================================
2023-06-14 13:00:30,328:INFO:Creating metrics dataframe
2023-06-14 13:00:30,333:INFO:Initializing Light Gradient Boosting Machine
2023-06-14 13:00:30,333:INFO:Total runtime is 1.4999557932217915 minutes
2023-06-14 13:00:30,333:INFO:SubProcess create_model() called ==================================
2023-06-14 13:00:30,335:INFO:Initializing create_model()
2023-06-14 13:00:30,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 13:00:30,335:INFO:Checking exceptions
2023-06-14 13:00:30,335:INFO:Importing libraries
2023-06-14 13:00:30,335:INFO:Copying training dataset
2023-06-14 13:00:30,339:INFO:Defining folds
2023-06-14 13:00:30,339:INFO:Declaring metric variables
2023-06-14 13:00:30,340:INFO:Importing untrained model
2023-06-14 13:00:30,340:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-14 13:00:30,340:INFO:Starting cross validation
2023-06-14 13:00:30,342:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 13:00:34,876:INFO:Calculating mean and std
2023-06-14 13:00:34,876:INFO:Creating metrics dataframe
2023-06-14 13:00:35,430:INFO:Uploading results into container
2023-06-14 13:00:35,431:INFO:Uploading model into container now
2023-06-14 13:00:35,431:INFO:_master_model_container: 17
2023-06-14 13:00:35,431:INFO:_display_container: 2
2023-06-14 13:00:35,432:INFO:LGBMRegressor(random_state=5043)
2023-06-14 13:00:35,432:INFO:create_model() successfully completed......................................
2023-06-14 13:00:35,491:INFO:SubProcess create_model() end ==================================
2023-06-14 13:00:35,491:INFO:Creating metrics dataframe
2023-06-14 13:00:35,496:INFO:Initializing Dummy Regressor
2023-06-14 13:00:35,496:INFO:Total runtime is 1.5859986901283263 minutes
2023-06-14 13:00:35,496:INFO:SubProcess create_model() called ==================================
2023-06-14 13:00:35,496:INFO:Initializing create_model()
2023-06-14 13:00:35,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E652855150>, model_only=True, return_train_score=False, kwargs={})
2023-06-14 13:00:35,496:INFO:Checking exceptions
2023-06-14 13:00:35,496:INFO:Importing libraries
2023-06-14 13:00:35,496:INFO:Copying training dataset
2023-06-14 13:00:35,500:INFO:Defining folds
2023-06-14 13:00:35,501:INFO:Declaring metric variables
2023-06-14 13:00:35,501:INFO:Importing untrained model
2023-06-14 13:00:35,501:INFO:Dummy Regressor Imported successfully
2023-06-14 13:00:35,502:INFO:Starting cross validation
2023-06-14 13:00:35,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-14 13:00:40,174:INFO:Calculating mean and std
2023-06-14 13:00:40,174:INFO:Creating metrics dataframe
2023-06-14 13:00:40,795:INFO:Uploading results into container
2023-06-14 13:00:40,795:INFO:Uploading model into container now
2023-06-14 13:00:40,797:INFO:_master_model_container: 18
2023-06-14 13:00:40,797:INFO:_display_container: 2
2023-06-14 13:00:40,797:INFO:DummyRegressor()
2023-06-14 13:00:40,797:INFO:create_model() successfully completed......................................
2023-06-14 13:00:40,876:INFO:SubProcess create_model() end ==================================
2023-06-14 13:00:40,876:INFO:Creating metrics dataframe
2023-06-14 13:00:40,883:INFO:Initializing create_model()
2023-06-14 13:00:40,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E652526D70>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=5043), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-14 13:00:40,883:INFO:Checking exceptions
2023-06-14 13:00:40,884:INFO:Importing libraries
2023-06-14 13:00:40,884:INFO:Copying training dataset
2023-06-14 13:00:40,889:INFO:Defining folds
2023-06-14 13:00:40,889:INFO:Declaring metric variables
2023-06-14 13:00:40,889:INFO:Importing untrained model
2023-06-14 13:00:40,889:INFO:Declaring custom model
2023-06-14 13:00:40,890:INFO:Extra Trees Regressor Imported successfully
2023-06-14 13:00:40,891:INFO:Cross validation set to False
2023-06-14 13:00:40,891:INFO:Fitting Model
2023-06-14 13:00:41,796:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5043)
2023-06-14 13:00:41,796:INFO:create_model() successfully completed......................................
2023-06-14 13:00:41,899:INFO:_master_model_container: 18
2023-06-14 13:00:41,899:INFO:_display_container: 2
2023-06-14 13:00:41,900:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5043)
2023-06-14 13:00:41,900:INFO:compare_models() successfully completed......................................
